{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import autokeras as ak\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 files belonging to 4 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.2, 0.2, 0.4, 0.4, 0.1, 0.3, 0.2, 0.3, 0.3, 0.1, 0.2, 0.4, 0.4,\n",
       "       0.2, 0.4, 0.3, 0.3, 0.3, 0.2, 0.1, 0.1, 0.2, 0.2, 0.2, 0.4, 0.4,\n",
       "       0.3, 0.2, 0.3, 0.1, 0.1, 0.1])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import autokeras as ak\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "inputs1 = \"/Users/treasures_y/Documents/code/HG/AutoML/python/automl/autotrain/datasets/image-classification\"\n",
    "input2 = \"/Users/treasures_y/Documents/code/HG/AutoML/python/automl/autotrain/datasets/image-regression\"\n",
    "train_data = ak.image_dataset_from_directory(\n",
    "    directory=input2,\n",
    "    subset='training',\n",
    ")\n",
    "y_true_labels = np.asarray([float(label) for label in train_data.as_numpy_iterator().next()[1]])\n",
    "print(f\"y_true_labels: {y_true_labels}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'0.2', b'0.2', b'0.4', b'0.4', b'0.1', b'0.3', b'0.2', b'0.3',\n",
       "       b'0.3', b'0.1', b'0.2', b'0.4', b'0.4', b'0.2', b'0.4', b'0.3',\n",
       "       b'0.3', b'0.3', b'0.2', b'0.1', b'0.1', b'0.2', b'0.2', b'0.2',\n",
       "       b'0.4', b'0.4', b'0.3', b'0.2', b'0.3', b'0.1', b'0.1', b'0.1'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.as_numpy_iterator().next()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_y = pd.read_csv(os.path.join(os.path.pardir, 'autotrain', 'datasets', 'structured-data-classification.csv'))\n",
    "_, features_nums = X_y.shape\n",
    "X = X_y.iloc[:, 0:(features_nums - 1)].to_numpy()\n",
    "y = X_y.iloc[:, -1].to_numpy()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 01s]\n",
      "val_accuracy: 0.4375\n",
      "\n",
      "Best val_accuracy So Far: 0.4375\n",
      "Total elapsed time: 00h 00m 05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.1638 - accuracy: 0.3469 - val_loss: 1.0493 - val_accuracy: 0.5125\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1176 - accuracy: 0.3969 - val_loss: 1.0595 - val_accuracy: 0.4750\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0915 - accuracy: 0.4031 - val_loss: 1.0693 - val_accuracy: 0.4500\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0734 - accuracy: 0.4219 - val_loss: 1.0759 - val_accuracy: 0.4500\n",
      "Epoch 5/20\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 1.0451 - accuracy: 0.4375"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[187], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m clf \u001b[38;5;241m=\u001b[39m ak\u001b[38;5;241m.\u001b[39mStructuredDataClassifier(\n\u001b[1;32m      2\u001b[0m     max_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m      3\u001b[0m     overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      4\u001b[0m )\n\u001b[0;32m----> 6\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Miniconda3/envs/automl/lib/python3.9/site-packages/autokeras/tasks/structured_data.py:326\u001b[0m, in \u001b[0;36mStructuredDataClassifier.fit\u001b[0;34m(self, x, y, epochs, callbacks, validation_split, validation_data, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    281\u001b[0m     x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    288\u001b[0m ):\n\u001b[1;32m    289\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search for the best model and hyperparameters for the AutoModel.\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    # Arguments\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03m            validation loss values and validation metrics values (if applicable).\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m~/Miniconda3/envs/automl/lib/python3.9/site-packages/autokeras/tasks/structured_data.py:139\u001b[0m, in \u001b[0;36mBaseStructuredDataPipeline.fit\u001b[0;34m(self, x, y, epochs, callbacks, validation_split, validation_data, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m         validation_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_from_csv(x_val, y_val)\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_in_fit(x)\n\u001b[0;32m--> 139\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m~/Miniconda3/envs/automl/lib/python3.9/site-packages/autokeras/auto_model.py:292\u001b[0m, in \u001b[0;36mAutoModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, callbacks, validation_split, validation_data, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m validation_split:\n\u001b[1;32m    288\u001b[0m     dataset, validation_data \u001b[38;5;241m=\u001b[39m data_utils\u001b[38;5;241m.\u001b[39msplit_dataset(\n\u001b[1;32m    289\u001b[0m         dataset, validation_split\n\u001b[1;32m    290\u001b[0m     )\n\u001b[0;32m--> 292\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m~/Miniconda3/envs/automl/lib/python3.9/site-packages/autokeras/engine/tuner.py:220\u001b[0m, in \u001b[0;36mAutoTuner.search\u001b[0;34m(self, epochs, callbacks, validation_split, verbose, **fit_kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhypermodel\u001b[38;5;241m.\u001b[39mset_fit_args(\u001b[38;5;241m0\u001b[39m, epochs\u001b[38;5;241m=\u001b[39mcopied_fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    219\u001b[0m     copied_fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m verbose\n\u001b[0;32m--> 220\u001b[0m     pipeline, model, history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinal_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopied_fit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# TODO: Add return history functionality in Keras Tuner\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_best_models()[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Miniconda3/envs/automl/lib/python3.9/site-packages/autokeras/engine/tuner.py:270\u001b[0m, in \u001b[0;36mAutoTuner.final_fit\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_best_model()\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madapt(model, kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 270\u001b[0m model, history \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_with_adaptive_batch_size\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pipeline, model, history\n",
      "File \u001b[0;32m~/Miniconda3/envs/automl/lib/python3.9/site-packages/autokeras/utils/utils.py:88\u001b[0m, in \u001b[0;36mfit_with_adaptive_batch_size\u001b[0;34m(model, batch_size, **fit_kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_with_adaptive_batch_size\u001b[39m(model, batch_size, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m---> 88\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mrun_with_adaptive_batch_size\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model, history\n",
      "File \u001b[0;32m~/Miniconda3/envs/automl/lib/python3.9/site-packages/autokeras/utils/utils.py:101\u001b[0m, in \u001b[0;36mrun_with_adaptive_batch_size\u001b[0;34m(batch_size, func, **fit_kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m batch_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m         history \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m tf\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mResourceExhaustedError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Miniconda3/envs/automl/lib/python3.9/site-packages/autokeras/utils/utils.py:89\u001b[0m, in \u001b[0;36mfit_with_adaptive_batch_size.<locals>.<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_with_adaptive_batch_size\u001b[39m(model, batch_size, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m     88\u001b[0m     history \u001b[38;5;241m=\u001b[39m run_with_adaptive_batch_size(\n\u001b[0;32m---> 89\u001b[0m         batch_size, \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs\n\u001b[1;32m     90\u001b[0m     )\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model, history\n",
      "File \u001b[0;32m~/Miniconda3/envs/automl/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Miniconda3/envs/automl/lib/python3.9/site-packages/keras/src/engine/training.py:1856\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1840\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1841\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[1;32m   1842\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m   1843\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1854\u001b[0m         pss_evaluation_shards\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pss_evaluation_shards,\n\u001b[1;32m   1855\u001b[0m     )\n\u001b[0;32m-> 1856\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1858\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1859\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1867\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1868\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1869\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1870\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1871\u001b[0m }\n\u001b[1;32m   1872\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/Miniconda3/envs/automl/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Miniconda3/envs/automl/lib/python3.9/site-packages/keras/src/engine/training.py:2285\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautotune_steps_per_execution:\n\u001b[1;32m   2284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution_tuner\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m-> 2285\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (\n\u001b[1;32m   2286\u001b[0m     _,\n\u001b[1;32m   2287\u001b[0m     dataset_or_iterator,\n\u001b[1;32m   2288\u001b[0m ) \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39menumerate_epochs():  \u001b[38;5;66;03m# Single epoch.\u001b[39;00m\n\u001b[1;32m   2289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_metrics()\n\u001b[1;32m   2290\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n",
      "File \u001b[0;32m~/Miniconda3/envs/automl/lib/python3.9/site-packages/keras/src/engine/data_adapter.py:1341\u001b[0m, in \u001b[0;36mDataHandler.enumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[39;00m\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_truncate_execution_to_epoch():\n\u001b[0;32m-> 1341\u001b[0m     data_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1342\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epochs):\n\u001b[1;32m   1343\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n",
      "File \u001b[0;32m~/Miniconda3/envs/automl/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:500\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[1;32m    499\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[0;32m--> 500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOwnedIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    502\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    503\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration in eager mode or within tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Miniconda3/envs/automl/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:706\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    702\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    704\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    705\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 706\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_call_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/Miniconda3/envs/automl/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:745\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    742\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fulltype\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m    743\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types)\n\u001b[1;32m    744\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mexperimental_set_type(fulltype)\n\u001b[0;32m--> 745\u001b[0m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_variant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Miniconda3/envs/automl/lib/python3.9/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3421\u001b[0m, in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   3420\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3421\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3422\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMakeIterator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3424\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf = ak.StructuredDataClassifier(\n",
    "    max_trials=5,\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "history = clf.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    epochs=20,\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RestoredOptimizer` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RestoredOptimizer`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 895us/step - loss: 1.1165 - accuracy: 0.3600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 1.116540551185608, 'accuracy': 0.36000001430511475}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_result = clf.evaluate(x=x_test, y=y_test, return_dict=True)\n",
    "evaluate_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RestoredOptimizer` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RestoredOptimizer`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'history': {'loss': [1.1946697235107422,\n",
       "   1.193556547164917,\n",
       "   1.1247098445892334,\n",
       "   1.1246223449707031,\n",
       "   1.1130238771438599,\n",
       "   1.118772268295288,\n",
       "   1.0855599641799927,\n",
       "   1.0755631923675537,\n",
       "   1.0625776052474976,\n",
       "   1.0618162155151367,\n",
       "   1.0563427209854126,\n",
       "   1.0584437847137451,\n",
       "   1.0417732000350952,\n",
       "   1.0533931255340576,\n",
       "   1.03175687789917,\n",
       "   1.0308573246002197,\n",
       "   1.037511944770813,\n",
       "   1.0289287567138672,\n",
       "   1.0082523822784424,\n",
       "   1.0183348655700684],\n",
       "  'accuracy': [0.36250001192092896,\n",
       "   0.3343749940395355,\n",
       "   0.39375001192092896,\n",
       "   0.3656249940395355,\n",
       "   0.40312498807907104,\n",
       "   0.37187498807907104,\n",
       "   0.4468750059604645,\n",
       "   0.4625000059604645,\n",
       "   0.44999998807907104,\n",
       "   0.44999998807907104,\n",
       "   0.44999998807907104,\n",
       "   0.47187501192092896,\n",
       "   0.41874998807907104,\n",
       "   0.4375,\n",
       "   0.4625000059604645,\n",
       "   0.4375,\n",
       "   0.4468750059604645,\n",
       "   0.4749999940395355,\n",
       "   0.5093749761581421,\n",
       "   0.4749999940395355],\n",
       "  'val_loss': [1.147491455078125,\n",
       "   1.1444281339645386,\n",
       "   1.1441197395324707,\n",
       "   1.1433544158935547,\n",
       "   1.1414897441864014,\n",
       "   1.1375770568847656,\n",
       "   1.1358811855316162,\n",
       "   1.1335455179214478,\n",
       "   1.134362816810608,\n",
       "   1.1351215839385986,\n",
       "   1.1369577646255493,\n",
       "   1.1395543813705444,\n",
       "   1.14041268825531,\n",
       "   1.1409424543380737,\n",
       "   1.140250563621521,\n",
       "   1.1422635316848755,\n",
       "   1.144971251487732,\n",
       "   1.1466686725616455,\n",
       "   1.1467632055282593,\n",
       "   1.1459228992462158],\n",
       "  'val_accuracy': [0.2750000059604645,\n",
       "   0.30000001192092896,\n",
       "   0.32499998807907104,\n",
       "   0.3499999940395355,\n",
       "   0.3375000059604645,\n",
       "   0.3125,\n",
       "   0.3375000059604645,\n",
       "   0.32499998807907104,\n",
       "   0.32499998807907104,\n",
       "   0.32499998807907104,\n",
       "   0.32499998807907104,\n",
       "   0.3375000059604645,\n",
       "   0.3125,\n",
       "   0.3125,\n",
       "   0.3125,\n",
       "   0.32499998807907104,\n",
       "   0.3125,\n",
       "   0.32499998807907104,\n",
       "   0.3125,\n",
       "   0.32499998807907104]},\n",
       " 'hyperparameters': {'space': [{'class_name': 'Boolean',\n",
       "    'config': {'name': 'structured_data_block_1/normalize',\n",
       "     'default': False,\n",
       "     'conditions': []}},\n",
       "   {'class_name': 'Boolean',\n",
       "    'config': {'name': 'structured_data_block_1/dense_block_1/use_batchnorm',\n",
       "     'default': False,\n",
       "     'conditions': []}},\n",
       "   {'class_name': 'Choice',\n",
       "    'config': {'name': 'structured_data_block_1/dense_block_1/num_layers',\n",
       "     'default': 2,\n",
       "     'conditions': [],\n",
       "     'values': [1, 2, 3],\n",
       "     'ordered': True}},\n",
       "   {'class_name': 'Choice',\n",
       "    'config': {'name': 'structured_data_block_1/dense_block_1/units_0',\n",
       "     'default': 32,\n",
       "     'conditions': [],\n",
       "     'values': [16, 32, 64, 128, 256, 512, 1024],\n",
       "     'ordered': True}},\n",
       "   {'class_name': 'Choice',\n",
       "    'config': {'name': 'structured_data_block_1/dense_block_1/dropout',\n",
       "     'default': 0.0,\n",
       "     'conditions': [],\n",
       "     'values': [0.0, 0.25, 0.5],\n",
       "     'ordered': True}},\n",
       "   {'class_name': 'Choice',\n",
       "    'config': {'name': 'structured_data_block_1/dense_block_1/units_1',\n",
       "     'default': 32,\n",
       "     'conditions': [],\n",
       "     'values': [16, 32, 64, 128, 256, 512, 1024],\n",
       "     'ordered': True}},\n",
       "   {'class_name': 'Choice',\n",
       "    'config': {'name': 'classification_head_1/dropout',\n",
       "     'default': 0,\n",
       "     'conditions': [],\n",
       "     'values': [0.0, 0.25, 0.5],\n",
       "     'ordered': True}},\n",
       "   {'class_name': 'Choice',\n",
       "    'config': {'name': 'optimizer',\n",
       "     'default': 'adam',\n",
       "     'conditions': [],\n",
       "     'values': ['adam', 'sgd', 'adam_weight_decay'],\n",
       "     'ordered': False}},\n",
       "   {'class_name': 'Choice',\n",
       "    'config': {'name': 'learning_rate',\n",
       "     'default': 0.001,\n",
       "     'conditions': [],\n",
       "     'values': [0.1, 0.01, 0.001, 0.0001, 2e-05, 1e-05],\n",
       "     'ordered': True}}],\n",
       "  'values': {'structured_data_block_1/normalize': True,\n",
       "   'structured_data_block_1/dense_block_1/use_batchnorm': False,\n",
       "   'structured_data_block_1/dense_block_1/num_layers': 2,\n",
       "   'structured_data_block_1/dense_block_1/units_0': 32,\n",
       "   'structured_data_block_1/dense_block_1/dropout': 0,\n",
       "   'structured_data_block_1/dense_block_1/units_1': 32,\n",
       "   'classification_head_1/dropout': 0.5,\n",
       "   'optimizer': 'adam',\n",
       "   'learning_rate': 0.001}},\n",
       " 'model_graph_url': './structured_data_classifier/best_model/model.png'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Dict, List, Any, Optional\n",
    "# from pydantic import BaseModel\n",
    "from dataclasses import dataclass\n",
    "from keras.utils import plot_model\n",
    "\n",
    "best_keras_model = clf.tuner.get_best_model()\n",
    "try:\n",
    "    model_file_path = os.path.join(clf.tuner.best_model_path, 'model.png')\n",
    "    plot_model(best_keras_model, to_file=model_file_path, show_layer_activations=True, show_dtype=True, show_shapes=True, show_layer_names=False)\n",
    "except:\n",
    "    model_file_path = None\n",
    "\n",
    "@dataclass\n",
    "class BestModelTracker:\n",
    "    history: Dict[str, Any]\n",
    "    hyperparameters: Dict[str, Any]\n",
    "    model_graph_url: Optional[str]\n",
    "\n",
    "best_model_tracker = BestModelTracker(\n",
    "    history=history.history,\n",
    "    hyperparameters=clf.tuner.get_best_hyperparameters().pop().get_config(),\n",
    "    model_graph_url=model_file_path\n",
    ")\n",
    "best_model_tracker.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trial_id': '1',\n",
       " 'hyperparameters': {'space': [{'class_name': 'Boolean',\n",
       "    'config': {'name': 'structured_data_block_1/normalize',\n",
       "     'default': False,\n",
       "     'conditions': []}},\n",
       "   {'class_name': 'Boolean',\n",
       "    'config': {'name': 'structured_data_block_1/dense_block_1/use_batchnorm',\n",
       "     'default': False,\n",
       "     'conditions': []}},\n",
       "   {'class_name': 'Choice',\n",
       "    'config': {'name': 'structured_data_block_1/dense_block_1/num_layers',\n",
       "     'default': 2,\n",
       "     'conditions': [],\n",
       "     'values': [1, 2, 3],\n",
       "     'ordered': True}},\n",
       "   {'class_name': 'Choice',\n",
       "    'config': {'name': 'structured_data_block_1/dense_block_1/units_0',\n",
       "     'default': 32,\n",
       "     'conditions': [],\n",
       "     'values': [16, 32, 64, 128, 256, 512, 1024],\n",
       "     'ordered': True}},\n",
       "   {'class_name': 'Choice',\n",
       "    'config': {'name': 'structured_data_block_1/dense_block_1/dropout',\n",
       "     'default': 0.0,\n",
       "     'conditions': [],\n",
       "     'values': [0.0, 0.25, 0.5],\n",
       "     'ordered': True}},\n",
       "   {'class_name': 'Choice',\n",
       "    'config': {'name': 'structured_data_block_1/dense_block_1/units_1',\n",
       "     'default': 32,\n",
       "     'conditions': [],\n",
       "     'values': [16, 32, 64, 128, 256, 512, 1024],\n",
       "     'ordered': True}},\n",
       "   {'class_name': 'Choice',\n",
       "    'config': {'name': 'classification_head_1/dropout',\n",
       "     'default': 0,\n",
       "     'conditions': [],\n",
       "     'values': [0.0, 0.25, 0.5],\n",
       "     'ordered': True}},\n",
       "   {'class_name': 'Choice',\n",
       "    'config': {'name': 'optimizer',\n",
       "     'default': 'adam',\n",
       "     'conditions': [],\n",
       "     'values': ['adam', 'sgd', 'adam_weight_decay'],\n",
       "     'ordered': False}},\n",
       "   {'class_name': 'Choice',\n",
       "    'config': {'name': 'learning_rate',\n",
       "     'default': 0.001,\n",
       "     'conditions': [],\n",
       "     'values': [0.1, 0.01, 0.001, 0.0001, 2e-05, 1e-05],\n",
       "     'ordered': True}}],\n",
       "  'values': {'structured_data_block_1/normalize': True,\n",
       "   'structured_data_block_1/dense_block_1/use_batchnorm': False,\n",
       "   'structured_data_block_1/dense_block_1/num_layers': 2,\n",
       "   'structured_data_block_1/dense_block_1/units_0': 32,\n",
       "   'structured_data_block_1/dense_block_1/dropout': 0,\n",
       "   'structured_data_block_1/dense_block_1/units_1': 512,\n",
       "   'classification_head_1/dropout': 0.0,\n",
       "   'optimizer': 'adam',\n",
       "   'learning_rate': 0.001}},\n",
       " 'metrics': {'metrics': {'loss': {'direction': 'min',\n",
       "    'observations': [{'value': [0.9774014353752136], 'step': 3}]},\n",
       "   'accuracy': {'direction': 'max',\n",
       "    'observations': [{'value': [0.59375], 'step': 3}]},\n",
       "   'val_loss': {'direction': 'min',\n",
       "    'observations': [{'value': [1.1704667806625366], 'step': 3}]},\n",
       "   'val_accuracy': {'direction': 'max',\n",
       "    'observations': [{'value': [0.375], 'step': 3}]}}},\n",
       " 'score': 0.375,\n",
       " 'best_step': 3,\n",
       " 'status': 'COMPLETED',\n",
       " 'message': None}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.tuner.oracle.get_trial('1').get_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'trials': [Trial(trial_id='2', hyperparameters={'space': [{'class_name': 'Boolean', 'config': {'name': 'structured_data_block_1/normalize', 'default': False, 'conditions': []}}, {'class_name': 'Boolean', 'config': {'name': 'structured_data_block_1/dense_block_1/use_batchnorm', 'default': False, 'conditions': []}}, {'class_name': 'Choice', 'config': {'name': 'structured_data_block_1/dense_block_1/num_layers', 'default': 2, 'conditions': [], 'values': [1, 2, 3], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'structured_data_block_1/dense_block_1/units_0', 'default': 32, 'conditions': [], 'values': [16, 32, 64, 128, 256, 512, 1024], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'structured_data_block_1/dense_block_1/dropout', 'default': 0.0, 'conditions': [], 'values': [0.0, 0.25, 0.5], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'structured_data_block_1/dense_block_1/units_1', 'default': 32, 'conditions': [], 'values': [16, 32, 64, 128, 256, 512, 1024], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'classification_head_1/dropout', 'default': 0, 'conditions': [], 'values': [0.0, 0.25, 0.5], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'optimizer', 'default': 'adam', 'conditions': [], 'values': ['adam', 'sgd', 'adam_weight_decay'], 'ordered': False}}, {'class_name': 'Choice', 'config': {'name': 'learning_rate', 'default': 0.001, 'conditions': [], 'values': [0.1, 0.01, 0.001, 0.0001, 2e-05, 1e-05], 'ordered': True}}], 'values': {'structured_data_block_1/normalize': True, 'structured_data_block_1/dense_block_1/use_batchnorm': False, 'structured_data_block_1/dense_block_1/num_layers': 2, 'structured_data_block_1/dense_block_1/units_0': 32, 'structured_data_block_1/dense_block_1/dropout': 0, 'structured_data_block_1/dense_block_1/units_1': 32, 'classification_head_1/dropout': 0.5, 'optimizer': 'adam', 'learning_rate': 0.001}}, metrics={'metrics': {'loss': {'direction': 'min', 'observations': [{'value': [1.2761826515197754], 'step': 0}]}, 'accuracy': {'direction': 'max', 'observations': [{'value': [0.30937498807907104], 'step': 0}]}, 'val_loss': {'direction': 'min', 'observations': [{'value': [1.0889003276824951], 'step': 0}]}, 'val_accuracy': {'direction': 'max', 'observations': [{'value': [0.44999998807907104], 'step': 0}]}}}, score=0.44999998807907104, best_step=0, status='COMPLETED', model_graph_url='./structured_data_classifier/trial_2/model.png', message=None),\n",
       "  Trial(trial_id='0', hyperparameters={'space': [{'class_name': 'Boolean', 'config': {'name': 'structured_data_block_1/normalize', 'default': False, 'conditions': []}}, {'class_name': 'Boolean', 'config': {'name': 'structured_data_block_1/dense_block_1/use_batchnorm', 'default': False, 'conditions': []}}, {'class_name': 'Choice', 'config': {'name': 'structured_data_block_1/dense_block_1/num_layers', 'default': 2, 'conditions': [], 'values': [1, 2, 3], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'structured_data_block_1/dense_block_1/units_0', 'default': 32, 'conditions': [], 'values': [16, 32, 64, 128, 256, 512, 1024], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'structured_data_block_1/dense_block_1/dropout', 'default': 0.0, 'conditions': [], 'values': [0.0, 0.25, 0.5], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'structured_data_block_1/dense_block_1/units_1', 'default': 32, 'conditions': [], 'values': [16, 32, 64, 128, 256, 512, 1024], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'classification_head_1/dropout', 'default': 0, 'conditions': [], 'values': [0.0, 0.25, 0.5], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'optimizer', 'default': 'adam', 'conditions': [], 'values': ['adam', 'sgd', 'adam_weight_decay'], 'ordered': False}}, {'class_name': 'Choice', 'config': {'name': 'learning_rate', 'default': 0.001, 'conditions': [], 'values': [0.1, 0.01, 0.001, 0.0001, 2e-05, 1e-05], 'ordered': True}}], 'values': {'structured_data_block_1/normalize': True, 'structured_data_block_1/dense_block_1/num_layers': 2, 'structured_data_block_1/dense_block_1/use_batchnorm': False, 'structured_data_block_1/dense_block_1/dropout': 0, 'structured_data_block_1/dense_block_1/units_0': 32, 'structured_data_block_1/dense_block_1/units_1': 32, 'classification_head_1/dropout': 0.0, 'optimizer': 'adam', 'learning_rate': 0.001}}, metrics={'metrics': {'loss': {'direction': 'min', 'observations': [{'value': [0.9594701528549194], 'step': 13}]}, 'accuracy': {'direction': 'max', 'observations': [{'value': [0.565625011920929], 'step': 13}]}, 'val_loss': {'direction': 'min', 'observations': [{'value': [1.2083041667938232], 'step': 13}]}, 'val_accuracy': {'direction': 'max', 'observations': [{'value': [0.4124999940395355], 'step': 13}]}}}, score=0.4124999940395355, best_step=13, status='COMPLETED', model_graph_url='./structured_data_classifier/trial_0/model.png', message=None),\n",
       "  Trial(trial_id='3', hyperparameters={'space': [{'class_name': 'Boolean', 'config': {'name': 'structured_data_block_1/normalize', 'default': False, 'conditions': []}}, {'class_name': 'Boolean', 'config': {'name': 'structured_data_block_1/dense_block_1/use_batchnorm', 'default': False, 'conditions': []}}, {'class_name': 'Choice', 'config': {'name': 'structured_data_block_1/dense_block_1/num_layers', 'default': 2, 'conditions': [], 'values': [1, 2, 3], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'structured_data_block_1/dense_block_1/units_0', 'default': 32, 'conditions': [], 'values': [16, 32, 64, 128, 256, 512, 1024], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'structured_data_block_1/dense_block_1/dropout', 'default': 0.0, 'conditions': [], 'values': [0.0, 0.25, 0.5], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'structured_data_block_1/dense_block_1/units_1', 'default': 32, 'conditions': [], 'values': [16, 32, 64, 128, 256, 512, 1024], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'classification_head_1/dropout', 'default': 0, 'conditions': [], 'values': [0.0, 0.25, 0.5], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'optimizer', 'default': 'adam', 'conditions': [], 'values': ['adam', 'sgd', 'adam_weight_decay'], 'ordered': False}}, {'class_name': 'Choice', 'config': {'name': 'learning_rate', 'default': 0.001, 'conditions': [], 'values': [0.1, 0.01, 0.001, 0.0001, 2e-05, 1e-05], 'ordered': True}}], 'values': {'structured_data_block_1/normalize': True, 'structured_data_block_1/dense_block_1/use_batchnorm': False, 'structured_data_block_1/dense_block_1/num_layers': 2, 'structured_data_block_1/dense_block_1/units_0': 128, 'structured_data_block_1/dense_block_1/dropout': 0, 'structured_data_block_1/dense_block_1/units_1': 32, 'classification_head_1/dropout': 0.5, 'optimizer': 'adam', 'learning_rate': 0.001}}, metrics={'metrics': {'loss': {'direction': 'min', 'observations': [{'value': [1.0204753875732422], 'step': 6}]}, 'accuracy': {'direction': 'max', 'observations': [{'value': [0.4593749940395355], 'step': 6}]}, 'val_loss': {'direction': 'min', 'observations': [{'value': [1.1638829708099365], 'step': 6}]}, 'val_accuracy': {'direction': 'max', 'observations': [{'value': [0.38749998807907104], 'step': 6}]}}}, score=0.38749998807907104, best_step=6, status='COMPLETED', model_graph_url='./structured_data_classifier/trial_3/model.png', message=None),\n",
       "  Trial(trial_id='1', hyperparameters={'space': [{'class_name': 'Boolean', 'config': {'name': 'structured_data_block_1/normalize', 'default': False, 'conditions': []}}, {'class_name': 'Boolean', 'config': {'name': 'structured_data_block_1/dense_block_1/use_batchnorm', 'default': False, 'conditions': []}}, {'class_name': 'Choice', 'config': {'name': 'structured_data_block_1/dense_block_1/num_layers', 'default': 2, 'conditions': [], 'values': [1, 2, 3], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'structured_data_block_1/dense_block_1/units_0', 'default': 32, 'conditions': [], 'values': [16, 32, 64, 128, 256, 512, 1024], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'structured_data_block_1/dense_block_1/dropout', 'default': 0.0, 'conditions': [], 'values': [0.0, 0.25, 0.5], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'structured_data_block_1/dense_block_1/units_1', 'default': 32, 'conditions': [], 'values': [16, 32, 64, 128, 256, 512, 1024], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'classification_head_1/dropout', 'default': 0, 'conditions': [], 'values': [0.0, 0.25, 0.5], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'optimizer', 'default': 'adam', 'conditions': [], 'values': ['adam', 'sgd', 'adam_weight_decay'], 'ordered': False}}, {'class_name': 'Choice', 'config': {'name': 'learning_rate', 'default': 0.001, 'conditions': [], 'values': [0.1, 0.01, 0.001, 0.0001, 2e-05, 1e-05], 'ordered': True}}], 'values': {'structured_data_block_1/normalize': True, 'structured_data_block_1/dense_block_1/use_batchnorm': False, 'structured_data_block_1/dense_block_1/num_layers': 2, 'structured_data_block_1/dense_block_1/units_0': 32, 'structured_data_block_1/dense_block_1/dropout': 0, 'structured_data_block_1/dense_block_1/units_1': 512, 'classification_head_1/dropout': 0.0, 'optimizer': 'adam', 'learning_rate': 0.001}}, metrics={'metrics': {'loss': {'direction': 'min', 'observations': [{'value': [0.9774014353752136], 'step': 3}]}, 'accuracy': {'direction': 'max', 'observations': [{'value': [0.59375], 'step': 3}]}, 'val_loss': {'direction': 'min', 'observations': [{'value': [1.1704667806625366], 'step': 3}]}, 'val_accuracy': {'direction': 'max', 'observations': [{'value': [0.375], 'step': 3}]}}}, score=0.375, best_step=3, status='COMPLETED', model_graph_url='./structured_data_classifier/trial_1/model.png', message=None),\n",
       "  Trial(trial_id='4', hyperparameters={'space': [{'class_name': 'Boolean', 'config': {'name': 'structured_data_block_1/normalize', 'default': False, 'conditions': []}}, {'class_name': 'Boolean', 'config': {'name': 'structured_data_block_1/dense_block_1/use_batchnorm', 'default': False, 'conditions': []}}, {'class_name': 'Choice', 'config': {'name': 'structured_data_block_1/dense_block_1/num_layers', 'default': 2, 'conditions': [], 'values': [1, 2, 3], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'structured_data_block_1/dense_block_1/units_0', 'default': 32, 'conditions': [], 'values': [16, 32, 64, 128, 256, 512, 1024], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'structured_data_block_1/dense_block_1/dropout', 'default': 0.0, 'conditions': [], 'values': [0.0, 0.25, 0.5], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'structured_data_block_1/dense_block_1/units_1', 'default': 32, 'conditions': [], 'values': [16, 32, 64, 128, 256, 512, 1024], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'classification_head_1/dropout', 'default': 0, 'conditions': [], 'values': [0.0, 0.25, 0.5], 'ordered': True}}, {'class_name': 'Choice', 'config': {'name': 'optimizer', 'default': 'adam', 'conditions': [], 'values': ['adam', 'sgd', 'adam_weight_decay'], 'ordered': False}}, {'class_name': 'Choice', 'config': {'name': 'learning_rate', 'default': 0.001, 'conditions': [], 'values': [0.1, 0.01, 0.001, 0.0001, 2e-05, 1e-05], 'ordered': True}}], 'values': {'structured_data_block_1/normalize': True, 'structured_data_block_1/dense_block_1/use_batchnorm': False, 'structured_data_block_1/dense_block_1/num_layers': 2, 'structured_data_block_1/dense_block_1/units_0': 32, 'structured_data_block_1/dense_block_1/dropout': 0, 'structured_data_block_1/dense_block_1/units_1': 32, 'classification_head_1/dropout': 0.25, 'optimizer': 'adam', 'learning_rate': 0.001}}, metrics={'metrics': {'loss': {'direction': 'min', 'observations': [{'value': [1.1769381761550903], 'step': 0}]}, 'accuracy': {'direction': 'max', 'observations': [{'value': [0.3843750059604645], 'step': 0}]}, 'val_loss': {'direction': 'min', 'observations': [{'value': [1.1467822790145874], 'step': 0}]}, 'val_accuracy': {'direction': 'max', 'observations': [{'value': [0.32499998807907104], 'step': 0}]}}}, score=0.32499998807907104, best_step=0, status='COMPLETED', model_graph_url='./structured_data_classifier/trial_4/model.png', message=None)]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Any, Optional, List, Dict\n",
    "\n",
    "\n",
    "@dataclass \n",
    "class Trial:\n",
    "    trial_id: str\n",
    "    hyperparameters: Dict[str, Any]\n",
    "    metrics: Dict[str, Any]\n",
    "    score: float\n",
    "    best_step: int\n",
    "    status: str\n",
    "    model_graph_url: Optional[str]\n",
    "    message: Any\n",
    "\n",
    "@dataclass \n",
    "class TrialsTracker:\n",
    "    trials: List[Trial]\n",
    "\n",
    "max_trials = 5\n",
    "trials = []\n",
    "models = clf.tuner.get_best_models(max_trials)\n",
    "index = 0\n",
    "for trial in clf.tuner.oracle.get_best_trials(max_trials):\n",
    "    try:\n",
    "        model_file_path = os.path.join(clf.tuner.get_trial_dir(trial_id=trial.trial_id), 'model.png')\n",
    "        plot_model(model=models[index], to_file=model_file_path, show_layer_activations=True, show_dtype=True, show_shapes=True, show_layer_names=False)\n",
    "    except:\n",
    "        model_file_path = None\n",
    "    index += 1\n",
    "    trials.append(Trial(\n",
    "        **trial.get_state(),\n",
    "        model_graph_url=model_file_path\n",
    "    ))\n",
    "trials_tracker = TrialsTracker(trials=trials)\n",
    "trials_tracker.__dict__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       \n",
      "0      0    0\n",
      "1      1    1\n",
      "2      0    0\n",
      "3     -1   -1\n",
      "4     -1   -1\n",
      "..   ...  ...\n",
      "495   -1   -1\n",
      "496    0    0\n",
      "497    0    0\n",
      "498    1    1\n",
      "499    0    0\n",
      "\n",
      "[500 rows x 2 columns]\n",
      "../autotrain/datasets/extracted-structured-data-classification.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "inputs = os.path.join(os.path.pardir, 'autotrain', 'datasets', 'structured-data-classification.csv')\n",
    "\n",
    "datasets = pd.read_csv(inputs)\n",
    "best_feature_index = [-1]\n",
    "best_feature_index.append(-1)\n",
    "extracted_datasets = datasets.iloc[:, best_feature_index]\n",
    "print(extracted_datasets)\n",
    "\n",
    "extracted_file_name = '-'.join(['extracted', os.path.basename(inputs)])\n",
    "parent_dir = os.path.dirname(inputs)\n",
    "\n",
    "extracted_file_path = os.path.join(parent_dir, extracted_file_name)\n",
    "print(extracted_file_path)\n",
    "\n",
    "extracted_datasets.to_csv(extracted_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autokeras as ak\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "       '', '', '', '', '', ''], dtype=object)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test = \"/Users/treasures_y/Documents/code/HG/AutoML/python/automl/autotrain/datasets/structured-data-classification-2-test.csv\"\n",
    "X_y = pd.read_csv(test)\n",
    "_, features_nums = X_y.shape\n",
    "X = X_y.iloc[:, 0:(features_nums - 1)].to_numpy()\n",
    "y = X_y.iloc[:, -1].to_numpy()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted_labels: ['' '' '']\n",
      "label2ids: {'': 0, '': 1, '': 2}\n",
      "id2labels: {0: '', 1: '', 2: ''}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "sorted_labels = np.unique(y)\n",
    "print(f\"sorted_labels: {sorted_labels}\")\n",
    "\n",
    "label2ids = {label: index for index, label in enumerate(sorted_labels)}\n",
    "print(f\"label2ids: {label2ids}\")\n",
    "\n",
    "id2labels = {index: label for index, label in enumerate(sorted_labels)}\n",
    "print(f\"id2labels: {id2labels}\")\n",
    "\n",
    "y_ids = [sorted_labels.searchsorted(i) for i in y]\n",
    "y_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RestoredOptimizer` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RestoredOptimizer`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[8.9949211e-03, 4.6002939e-03, 9.8640478e-01],\n",
       "       [1.9668853e-02, 3.3479596e-03, 9.7698319e-01],\n",
       "       [1.2946640e-03, 5.6301341e-03, 9.9307525e-01],\n",
       "       ...,\n",
       "       [9.3998329e-04, 1.8063408e-03, 9.9725372e-01],\n",
       "       [4.5125093e-02, 5.5643381e-03, 9.4931060e-01],\n",
       "       [1.5015173e-03, 1.0395123e-03, 9.9745899e-01]], dtype=float32)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/structured-data-classification/best_model\"\n",
    "model = tf.keras.models.load_model(path)\n",
    "y_pred = model.predict_on_batch(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "y_pred = (model.predict(X)[:, 0] >= 0.75).astype(int)\n",
    "# \n",
    "# y_pred = model.predict(X).argmax(axis=1)\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/treasures_y/Miniconda3/envs/automl/lib/python3.9/site-packages/keras/src/engine/training.py\", line 2066, in test_function  *\n        return step_function(self, iterator)\n    File \"/Users/treasures_y/Miniconda3/envs/automl/lib/python3.9/site-packages/keras/src/engine/training.py\", line 2049, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/treasures_y/Miniconda3/envs/automl/lib/python3.9/site-packages/keras/src/engine/training.py\", line 2037, in run_step  **\n        outputs = model.test_step(data)\n    File \"/Users/treasures_y/Miniconda3/envs/automl/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1919, in test_step\n        self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/treasures_y/Miniconda3/envs/automl/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/treasures_y/Miniconda3/envs/automl/lib/python3.9/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/treasures_y/Miniconda3/envs/automl/lib/python3.9/site-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/treasures_y/Miniconda3/envs/automl/lib/python3.9/site-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/treasures_y/Miniconda3/envs/automl/lib/python3.9/site-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/Users/treasures_y/Miniconda3/envs/automl/lib/python3.9/site-packages/keras/src/backend.py\", line 5573, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 3) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[161], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Miniconda3/envs/automl/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/rm/h7scgyzs2qv_dnlfwtlpw8hw0000gn/T/__autograph_generated_filekbz51baz.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/treasures_y/Miniconda3/envs/automl/lib/python3.9/site-packages/keras/src/engine/training.py\", line 2066, in test_function  *\n        return step_function(self, iterator)\n    File \"/Users/treasures_y/Miniconda3/envs/automl/lib/python3.9/site-packages/keras/src/engine/training.py\", line 2049, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/treasures_y/Miniconda3/envs/automl/lib/python3.9/site-packages/keras/src/engine/training.py\", line 2037, in run_step  **\n        outputs = model.test_step(data)\n    File \"/Users/treasures_y/Miniconda3/envs/automl/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1919, in test_step\n        self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/treasures_y/Miniconda3/envs/automl/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/treasures_y/Miniconda3/envs/automl/lib/python3.9/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/treasures_y/Miniconda3/envs/automl/lib/python3.9/site-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/treasures_y/Miniconda3/envs/automl/lib/python3.9/site-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/treasures_y/Miniconda3/envs/automl/lib/python3.9/site-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/Users/treasures_y/Miniconda3/envs/automl/lib/python3.9/site-packages/keras/src/backend.py\", line 5573, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 3) are incompatible\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(X, y_pred, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autokeras as ak\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test = \"/Users/treasures_y/Documents/code/HG/AutoML/python/automl/autotrain/datasets/structured-data-regression.csv\"\n",
    "X_y = pd.read_csv(test)\n",
    "_, features_nums = X_y.shape\n",
    "X = X_y.iloc[:, 0:(features_nums - 1)].to_numpy()\n",
    "y = X_y.iloc[:, -1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.  , 0.11, 0.11, 0.11, 0.11, 1.  , 0.11, 1.  , 1.  , 0.11, 1.  ,\n",
       "       1.  , 0.11, 0.11, 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 0.11, 1.  ,\n",
       "       1.  , 0.11, 0.11, 0.11, 1.  , 0.11, 0.11, 0.11, 1.  , 0.11, 0.11,\n",
       "       1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 0.11, 0.11, 1.  , 0.11, 1.  ,\n",
       "       0.11, 1.  , 1.  , 0.11, 1.  , 0.11, 0.11, 1.  , 1.  , 0.11, 0.11,\n",
       "       1.  , 0.11, 0.11, 0.11, 0.11, 1.  , 0.11, 1.  , 0.11, 1.  , 1.  ,\n",
       "       1.  , 1.  , 0.11, 0.11, 0.11, 0.11, 0.11, 1.  , 1.  , 1.  , 0.11,\n",
       "       0.11, 1.  , 0.11, 1.  , 0.11, 0.11, 1.  , 0.11, 1.  , 0.11, 0.11,\n",
       "       1.  , 1.  , 1.  , 0.11, 0.11, 1.  , 0.11, 1.  , 1.  , 1.  , 1.  ,\n",
       "       1.  , 1.  , 0.11, 1.  , 1.  , 0.11, 0.11, 0.11, 0.11, 0.11, 0.11,\n",
       "       0.11, 1.  , 0.11, 0.11, 0.11, 1.  , 1.  , 1.  , 0.11, 1.  , 1.  ,\n",
       "       0.11, 1.  , 1.  , 1.  , 0.11, 0.11, 1.  , 0.11, 1.  , 0.11, 0.11,\n",
       "       1.  , 1.  , 0.11, 0.11, 0.11, 1.  , 0.11, 1.  , 0.11, 0.11, 1.  ,\n",
       "       1.  , 0.11, 0.11, 1.  , 0.11, 1.  , 0.11, 1.  , 1.  , 1.  , 0.11,\n",
       "       1.  , 0.11, 0.11, 0.11, 1.  , 1.  , 1.  , 1.  , 0.11, 0.11, 0.11,\n",
       "       0.11, 0.11, 0.11, 0.11, 0.11, 0.11, 1.  , 1.  , 1.  , 1.  , 1.  ,\n",
       "       1.  , 0.11, 0.11, 1.  , 0.11, 1.  , 1.  , 0.11, 1.  , 1.  , 0.11,\n",
       "       1.  , 0.11, 1.  , 0.11, 1.  , 0.11, 0.11, 0.11, 1.  , 1.  , 1.  ,\n",
       "       0.11, 0.11, 1.  , 1.  , 1.  , 0.11, 0.11, 1.  , 0.11, 0.11, 0.11,\n",
       "       0.11, 1.  , 0.11, 1.  , 0.11, 1.  , 0.11, 0.11, 0.11, 0.11, 1.  ,\n",
       "       1.  , 1.  , 1.  , 0.11, 0.11, 0.11, 1.  , 1.  , 1.  , 0.11, 0.11,\n",
       "       1.  , 1.  , 1.  , 1.  , 0.11, 1.  , 1.  , 1.  , 0.11, 1.  , 0.11,\n",
       "       1.  , 1.  , 0.11, 0.11, 0.11, 1.  , 1.  , 0.11, 0.11, 0.11, 0.11,\n",
       "       1.  , 0.11, 0.11, 0.11, 1.  , 0.11, 1.  , 0.11, 0.11, 0.11, 1.  ,\n",
       "       1.  , 0.11, 0.11, 1.  , 0.11, 1.  , 0.11, 0.11, 1.  , 0.11, 0.11,\n",
       "       0.11, 1.  , 0.11, 0.11, 0.11, 1.  , 0.11, 1.  , 1.  , 0.11, 0.11,\n",
       "       1.  , 0.11, 1.  , 0.11, 1.  , 0.11, 1.  , 0.11, 0.11, 0.11, 0.11,\n",
       "       0.11, 0.11, 1.  , 1.  , 0.11, 1.  , 0.11, 1.  , 1.  , 1.  , 1.  ,\n",
       "       1.  , 0.11, 1.  , 1.  , 0.11, 1.  , 1.  , 0.11, 1.  , 0.11, 0.11,\n",
       "       1.  , 0.11, 1.  , 1.  , 1.  , 1.  , 1.  , 0.11, 0.11, 0.11, 0.11,\n",
       "       1.  , 1.  , 0.11, 1.  , 0.11, 0.11, 1.  , 1.  , 0.11, 1.  , 1.  ,\n",
       "       0.11, 0.11, 1.  , 0.11, 1.  , 0.11, 0.11, 1.  , 0.11, 1.  , 0.11,\n",
       "       0.11, 0.11, 1.  , 1.  , 1.  , 1.  , 1.  , 0.11, 0.11, 1.  , 1.  ,\n",
       "       0.11, 0.11, 1.  , 1.  , 0.11, 1.  , 1.  , 1.  , 1.  , 1.  , 0.11,\n",
       "       1.  , 1.  , 0.11, 1.  , 0.11, 1.  , 1.  , 0.11, 1.  , 1.  , 0.11,\n",
       "       1.  , 1.  , 1.  , 0.11, 1.  , 1.  , 1.  , 0.11, 1.  , 1.  , 0.11,\n",
       "       1.  , 0.11, 0.11, 1.  , 1.  , 1.  , 0.11, 0.11, 1.  , 0.11, 0.11,\n",
       "       0.11, 1.  , 0.11, 0.11, 1.  , 0.11, 0.11, 0.11, 0.11, 1.  , 1.  ,\n",
       "       0.11, 1.  , 0.11, 0.11, 0.11, 1.  , 0.11, 0.11, 1.  , 1.  , 1.  ,\n",
       "       0.11, 1.  , 1.  , 0.11, 1.  , 1.  , 1.  , 0.11, 1.  , 0.11, 1.  ,\n",
       "       0.11, 1.  , 0.11, 0.11, 1.  , 0.11, 1.  , 1.  , 1.  , 0.11, 1.  ,\n",
       "       1.  , 0.11, 0.11, 1.  , 1.  , 0.11, 1.  , 0.11, 0.11, 0.11, 1.  ,\n",
       "       0.11, 0.11, 0.11, 0.11, 1.  , 1.  , 1.  , 0.11, 1.  , 0.11, 1.  ,\n",
       "       0.11, 0.11, 1.  , 0.11, 0.11, 1.  , 0.11, 1.  , 1.  , 1.  , 0.11,\n",
       "       1.  , 1.  , 1.  , 0.11, 1.  , 0.11, 1.  , 0.11, 1.  , 1.  , 1.  ,\n",
       "       1.  , 0.11, 0.11, 0.11, 1.  ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RestoredOptimizer` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RestoredOptimizer`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "path = \"/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/structured-data-regression/best_model\"\n",
    "model = tf.keras.models.load_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66740865],\n",
       "       [0.97054774],\n",
       "       [0.7546125 ],\n",
       "       [0.8254033 ],\n",
       "       [0.9099428 ],\n",
       "       [0.7949157 ],\n",
       "       [0.60437423],\n",
       "       [1.2551281 ],\n",
       "       [1.6263456 ],\n",
       "       [1.8818383 ],\n",
       "       [0.78752834],\n",
       "       [0.78311104],\n",
       "       [2.085313  ],\n",
       "       [0.85145384],\n",
       "       [0.6819579 ],\n",
       "       [0.6587313 ],\n",
       "       [2.2623446 ],\n",
       "       [1.0417931 ],\n",
       "       [0.6713205 ],\n",
       "       [0.88101715],\n",
       "       [0.8760753 ],\n",
       "       [0.9924274 ],\n",
       "       [2.2532098 ],\n",
       "       [0.68035823],\n",
       "       [0.8058303 ],\n",
       "       [0.8095357 ],\n",
       "       [0.9329179 ],\n",
       "       [0.9525412 ],\n",
       "       [0.7478599 ],\n",
       "       [1.2129331 ],\n",
       "       [1.0480697 ],\n",
       "       [1.1413639 ],\n",
       "       [0.7941133 ],\n",
       "       [0.75387055],\n",
       "       [0.8655425 ],\n",
       "       [0.7187312 ],\n",
       "       [1.1374109 ],\n",
       "       [0.7583714 ],\n",
       "       [0.9590135 ],\n",
       "       [0.5827537 ],\n",
       "       [0.83998436],\n",
       "       [1.2898216 ],\n",
       "       [0.78650314],\n",
       "       [0.8498476 ],\n",
       "       [0.90457743],\n",
       "       [1.2342916 ],\n",
       "       [0.75852543],\n",
       "       [0.84324795],\n",
       "       [0.8490687 ],\n",
       "       [0.88064855],\n",
       "       [0.6197861 ],\n",
       "       [0.8542591 ],\n",
       "       [0.67341334],\n",
       "       [0.77741915],\n",
       "       [0.9490157 ],\n",
       "       [1.1384976 ],\n",
       "       [0.71527356],\n",
       "       [0.72060305],\n",
       "       [0.5623737 ],\n",
       "       [1.3149071 ],\n",
       "       [0.89807945],\n",
       "       [0.8430529 ],\n",
       "       [0.7822599 ],\n",
       "       [0.94098836],\n",
       "       [1.5033724 ],\n",
       "       [0.83536667],\n",
       "       [0.9890302 ],\n",
       "       [0.7370228 ],\n",
       "       [0.6497131 ],\n",
       "       [1.2620883 ],\n",
       "       [1.8114376 ],\n",
       "       [0.6886352 ],\n",
       "       [0.93765074],\n",
       "       [0.7192707 ],\n",
       "       [0.81626695],\n",
       "       [0.9079321 ],\n",
       "       [1.3637972 ],\n",
       "       [0.79412556],\n",
       "       [0.95219797],\n",
       "       [1.9079225 ],\n",
       "       [0.7776597 ],\n",
       "       [0.7178107 ],\n",
       "       [0.86468846],\n",
       "       [0.82931167],\n",
       "       [2.055257  ],\n",
       "       [0.9515045 ],\n",
       "       [0.74211484],\n",
       "       [0.83151776],\n",
       "       [0.7490724 ],\n",
       "       [0.6087242 ],\n",
       "       [0.6510752 ],\n",
       "       [0.822519  ],\n",
       "       [1.9923241 ],\n",
       "       [0.9230743 ],\n",
       "       [0.86919886],\n",
       "       [0.7731761 ],\n",
       "       [0.8321758 ],\n",
       "       [0.7641323 ],\n",
       "       [1.1378348 ],\n",
       "       [0.85812765],\n",
       "       [0.90735596],\n",
       "       [0.7079368 ],\n",
       "       [1.0082083 ],\n",
       "       [0.90492207],\n",
       "       [1.9525096 ],\n",
       "       [0.57988244],\n",
       "       [0.63233787],\n",
       "       [0.9144457 ],\n",
       "       [0.849489  ],\n",
       "       [0.57472116],\n",
       "       [0.84708756],\n",
       "       [0.8802063 ],\n",
       "       [0.8744208 ],\n",
       "       [0.8256355 ],\n",
       "       [1.1793313 ],\n",
       "       [0.80491215],\n",
       "       [1.8139298 ],\n",
       "       [0.9411555 ],\n",
       "       [0.9964774 ],\n",
       "       [0.8318396 ],\n",
       "       [1.7441325 ],\n",
       "       [0.72318107],\n",
       "       [0.76499325],\n",
       "       [1.5182488 ],\n",
       "       [0.8686653 ],\n",
       "       [0.9454985 ],\n",
       "       [0.9520226 ],\n",
       "       [0.8156839 ],\n",
       "       [0.63045365],\n",
       "       [0.54261273],\n",
       "       [0.8296563 ],\n",
       "       [0.88538176],\n",
       "       [0.7516766 ],\n",
       "       [0.79622334],\n",
       "       [0.717475  ],\n",
       "       [0.79275995],\n",
       "       [0.73412853],\n",
       "       [0.87382025],\n",
       "       [1.6237869 ],\n",
       "       [1.5187049 ],\n",
       "       [2.6315432 ],\n",
       "       [0.8181272 ],\n",
       "       [0.62302333],\n",
       "       [1.015667  ],\n",
       "       [0.71706   ],\n",
       "       [0.83862525],\n",
       "       [0.9391418 ],\n",
       "       [1.0336659 ],\n",
       "       [0.83994824],\n",
       "       [0.90723425],\n",
       "       [0.9076691 ],\n",
       "       [0.9917775 ],\n",
       "       [1.6167662 ],\n",
       "       [0.7984819 ],\n",
       "       [0.8081351 ],\n",
       "       [0.95506245],\n",
       "       [0.7726782 ],\n",
       "       [0.8438218 ],\n",
       "       [0.7958942 ],\n",
       "       [0.95616513],\n",
       "       [0.95251924],\n",
       "       [0.61023575],\n",
       "       [1.388489  ],\n",
       "       [0.87425524],\n",
       "       [0.8516844 ],\n",
       "       [0.86815554],\n",
       "       [0.6665924 ],\n",
       "       [1.0548131 ],\n",
       "       [1.7541542 ],\n",
       "       [1.5703385 ],\n",
       "       [0.98569065],\n",
       "       [0.91666824],\n",
       "       [0.8629251 ],\n",
       "       [0.7573675 ],\n",
       "       [0.8762248 ],\n",
       "       [0.8860648 ],\n",
       "       [0.8973759 ],\n",
       "       [0.86042815],\n",
       "       [1.4874182 ],\n",
       "       [0.9275947 ],\n",
       "       [1.5764184 ],\n",
       "       [0.70807534],\n",
       "       [0.83844423],\n",
       "       [0.95684963],\n",
       "       [0.8540898 ],\n",
       "       [0.8002326 ],\n",
       "       [0.9897457 ],\n",
       "       [0.7974804 ],\n",
       "       [0.8192416 ],\n",
       "       [0.8561235 ],\n",
       "       [0.9662245 ],\n",
       "       [1.3606868 ],\n",
       "       [0.85877544],\n",
       "       [1.0043299 ],\n",
       "       [1.2690468 ],\n",
       "       [0.8308057 ],\n",
       "       [0.7742196 ],\n",
       "       [2.0407684 ],\n",
       "       [0.62694186],\n",
       "       [0.9198194 ],\n",
       "       [0.9421802 ],\n",
       "       [0.95351654],\n",
       "       [0.7968314 ],\n",
       "       [0.71865743],\n",
       "       [0.73768526],\n",
       "       [0.78495985],\n",
       "       [0.8765666 ],\n",
       "       [0.8418527 ],\n",
       "       [0.7291449 ],\n",
       "       [0.81072944],\n",
       "       [0.7750756 ],\n",
       "       [0.7632398 ],\n",
       "       [2.1258183 ],\n",
       "       [0.6671465 ],\n",
       "       [0.7121721 ],\n",
       "       [0.7584165 ],\n",
       "       [0.75172   ],\n",
       "       [0.9727493 ],\n",
       "       [0.81127316],\n",
       "       [0.7707514 ],\n",
       "       [0.6286085 ],\n",
       "       [0.9065197 ],\n",
       "       [0.9063719 ],\n",
       "       [0.942427  ],\n",
       "       [0.84578234],\n",
       "       [1.218554  ],\n",
       "       [0.63743705],\n",
       "       [0.90699464],\n",
       "       [0.88964206],\n",
       "       [0.68517   ],\n",
       "       [0.99539095],\n",
       "       [0.635958  ],\n",
       "       [0.73627716],\n",
       "       [0.59964186],\n",
       "       [0.88406235],\n",
       "       [0.9371944 ],\n",
       "       [0.9611266 ],\n",
       "       [0.7530146 ],\n",
       "       [1.7189353 ],\n",
       "       [0.7982536 ],\n",
       "       [0.8419576 ],\n",
       "       [0.87712985],\n",
       "       [0.9171317 ],\n",
       "       [2.201549  ],\n",
       "       [1.1780539 ],\n",
       "       [0.84267145],\n",
       "       [0.9395109 ],\n",
       "       [0.9762967 ],\n",
       "       [0.70244414],\n",
       "       [0.85376364],\n",
       "       [0.73933125],\n",
       "       [1.0406256 ],\n",
       "       [0.7497054 ],\n",
       "       [1.0603356 ],\n",
       "       [0.7498551 ],\n",
       "       [0.85021096],\n",
       "       [0.71040136],\n",
       "       [0.65867954],\n",
       "       [0.9580689 ],\n",
       "       [0.8733979 ],\n",
       "       [0.9968427 ],\n",
       "       [0.72671944],\n",
       "       [0.68943983],\n",
       "       [1.5934613 ],\n",
       "       [0.6676199 ],\n",
       "       [1.012409  ],\n",
       "       [0.9328583 ],\n",
       "       [0.9472018 ],\n",
       "       [0.8515642 ],\n",
       "       [0.75655514],\n",
       "       [0.76621825],\n",
       "       [1.2138107 ],\n",
       "       [1.2467926 ],\n",
       "       [0.95332056],\n",
       "       [0.7491999 ],\n",
       "       [0.7046295 ],\n",
       "       [0.8618646 ],\n",
       "       [1.2921085 ],\n",
       "       [0.8685737 ],\n",
       "       [0.7007399 ],\n",
       "       [0.6982184 ],\n",
       "       [0.6799312 ],\n",
       "       [0.8205449 ],\n",
       "       [1.5744405 ],\n",
       "       [0.7455581 ],\n",
       "       [0.92596346],\n",
       "       [0.9739781 ],\n",
       "       [2.1846569 ],\n",
       "       [1.0323238 ],\n",
       "       [1.4280791 ],\n",
       "       [0.784113  ],\n",
       "       [0.62041575],\n",
       "       [0.7317124 ],\n",
       "       [0.79193   ],\n",
       "       [0.8428994 ],\n",
       "       [0.83934647],\n",
       "       [0.97232944],\n",
       "       [0.8607859 ],\n",
       "       [0.89875895],\n",
       "       [1.0553443 ],\n",
       "       [0.8127225 ],\n",
       "       [1.415446  ],\n",
       "       [0.84943515],\n",
       "       [0.91409403],\n",
       "       [0.9457279 ],\n",
       "       [0.6445053 ],\n",
       "       [0.5913461 ],\n",
       "       [1.0229228 ],\n",
       "       [1.0401006 ],\n",
       "       [1.1646953 ],\n",
       "       [0.66144663],\n",
       "       [0.88460475],\n",
       "       [0.6108486 ],\n",
       "       [0.82062465],\n",
       "       [0.97726995],\n",
       "       [0.80943006],\n",
       "       [0.93469983],\n",
       "       [1.010284  ],\n",
       "       [0.69321305],\n",
       "       [0.6345983 ],\n",
       "       [0.7112414 ],\n",
       "       [0.9508074 ],\n",
       "       [0.874706  ],\n",
       "       [0.6474133 ],\n",
       "       [0.75550634],\n",
       "       [1.3854194 ],\n",
       "       [0.7730692 ],\n",
       "       [1.1380038 ],\n",
       "       [0.84258443],\n",
       "       [1.257092  ],\n",
       "       [0.63118106],\n",
       "       [0.62781984],\n",
       "       [0.81092566],\n",
       "       [0.71450955],\n",
       "       [1.0068884 ],\n",
       "       [1.1546221 ],\n",
       "       [0.670677  ],\n",
       "       [1.0245929 ],\n",
       "       [0.7693961 ],\n",
       "       [0.85420924],\n",
       "       [0.9664324 ],\n",
       "       [0.86525327],\n",
       "       [0.83472186],\n",
       "       [0.8294256 ],\n",
       "       [0.86643845],\n",
       "       [0.7082408 ],\n",
       "       [0.9656423 ],\n",
       "       [0.8054727 ],\n",
       "       [0.98951966],\n",
       "       [0.59247977],\n",
       "       [0.7036148 ],\n",
       "       [0.8305121 ],\n",
       "       [1.3925312 ],\n",
       "       [0.9415172 ],\n",
       "       [0.68068963],\n",
       "       [0.96959907],\n",
       "       [0.6692024 ],\n",
       "       [1.8747976 ],\n",
       "       [2.3825505 ],\n",
       "       [0.90666515],\n",
       "       [0.82440144],\n",
       "       [0.582028  ],\n",
       "       [0.9289823 ],\n",
       "       [0.5719312 ],\n",
       "       [0.98406273],\n",
       "       [0.8401409 ],\n",
       "       [0.7035716 ],\n",
       "       [0.7249978 ],\n",
       "       [0.6439145 ],\n",
       "       [0.7400108 ],\n",
       "       [0.78788596],\n",
       "       [0.7405005 ],\n",
       "       [0.7236654 ],\n",
       "       [0.79655313],\n",
       "       [0.92891496],\n",
       "       [0.9091156 ],\n",
       "       [1.1759434 ],\n",
       "       [0.8719455 ],\n",
       "       [0.7525831 ],\n",
       "       [2.0445592 ],\n",
       "       [2.2926085 ],\n",
       "       [0.975758  ],\n",
       "       [1.2213771 ],\n",
       "       [0.8221243 ],\n",
       "       [0.82189983],\n",
       "       [0.9649139 ],\n",
       "       [0.83748   ],\n",
       "       [0.72928554],\n",
       "       [1.0074944 ],\n",
       "       [1.4625726 ],\n",
       "       [0.9375289 ],\n",
       "       [0.9313784 ],\n",
       "       [0.8244005 ],\n",
       "       [0.64159876],\n",
       "       [0.84686774],\n",
       "       [1.9286802 ],\n",
       "       [0.8318844 ],\n",
       "       [1.3697026 ],\n",
       "       [2.3994834 ],\n",
       "       [0.9615875 ],\n",
       "       [0.6130126 ],\n",
       "       [1.0835195 ],\n",
       "       [0.95948726],\n",
       "       [1.0419874 ],\n",
       "       [0.8877085 ],\n",
       "       [0.8395496 ],\n",
       "       [1.1587605 ],\n",
       "       [0.953867  ],\n",
       "       [0.5946465 ],\n",
       "       [0.8679171 ],\n",
       "       [0.7671252 ],\n",
       "       [0.8741625 ],\n",
       "       [0.8932541 ],\n",
       "       [0.84608895],\n",
       "       [0.739636  ],\n",
       "       [1.0594752 ],\n",
       "       [1.764996  ],\n",
       "       [2.283072  ],\n",
       "       [0.73914295],\n",
       "       [1.3723843 ],\n",
       "       [1.008791  ],\n",
       "       [0.8509279 ],\n",
       "       [0.9543546 ],\n",
       "       [0.6670881 ],\n",
       "       [0.879443  ],\n",
       "       [0.8900855 ],\n",
       "       [0.7717137 ],\n",
       "       [0.8501913 ],\n",
       "       [0.63498193],\n",
       "       [0.92358357],\n",
       "       [1.6152885 ],\n",
       "       [1.8479488 ],\n",
       "       [0.7584618 ],\n",
       "       [0.6994546 ],\n",
       "       [0.7381144 ],\n",
       "       [0.92097086],\n",
       "       [0.7856776 ],\n",
       "       [0.7216001 ],\n",
       "       [0.91534144],\n",
       "       [0.6453703 ],\n",
       "       [0.8665603 ],\n",
       "       [0.9280837 ],\n",
       "       [0.89604884],\n",
       "       [0.88546544],\n",
       "       [0.9695063 ],\n",
       "       [1.8890846 ],\n",
       "       [0.7039183 ],\n",
       "       [2.359189  ],\n",
       "       [0.78379136],\n",
       "       [2.271169  ],\n",
       "       [0.875794  ],\n",
       "       [1.1191616 ],\n",
       "       [0.83361346],\n",
       "       [0.7658196 ],\n",
       "       [0.73781854],\n",
       "       [0.9704545 ],\n",
       "       [0.82858044],\n",
       "       [0.82974964],\n",
       "       [0.7986205 ],\n",
       "       [0.77447253],\n",
       "       [0.8616081 ],\n",
       "       [1.0145571 ],\n",
       "       [0.80057544],\n",
       "       [0.8997596 ],\n",
       "       [0.7979304 ],\n",
       "       [0.69599396],\n",
       "       [0.92230815],\n",
       "       [0.85359055],\n",
       "       [0.5756503 ],\n",
       "       [2.3094244 ],\n",
       "       [1.9690223 ],\n",
       "       [0.7724423 ],\n",
       "       [0.63192827],\n",
       "       [0.7345157 ],\n",
       "       [1.0149634 ],\n",
       "       [0.7894736 ],\n",
       "       [1.1802387 ],\n",
       "       [0.8851361 ],\n",
       "       [0.92170936],\n",
       "       [0.93076044],\n",
       "       [0.8797143 ],\n",
       "       [0.8245556 ],\n",
       "       [0.93892604],\n",
       "       [0.831794  ],\n",
       "       [1.0541482 ],\n",
       "       [0.7996329 ],\n",
       "       [0.7533911 ],\n",
       "       [1.5308964 ],\n",
       "       [0.81423885],\n",
       "       [0.69948536],\n",
       "       [0.7419357 ],\n",
       "       [0.815656  ],\n",
       "       [1.3380718 ],\n",
       "       [0.65543264],\n",
       "       [2.0517526 ],\n",
       "       [0.79427046],\n",
       "       [1.2292955 ],\n",
       "       [0.6434155 ],\n",
       "       [0.9287675 ],\n",
       "       [0.98832256]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_on_batch(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 572us/step - loss: 1.3151e-13 - mean_squared_error: 1.3151e-13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 1.3150724541451109e-13, 'mean_squared_error': 1.3150724541451109e-13}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X, y_pred, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autokeras as ak\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category: ['healthy', 'angular_leaf_spot', 'bean_rust']\n",
      "labels: ['healthy', 'healthy', 'healthy', 'healthy', 'healthy', 'healthy', 'healthy', 'healthy', 'healthy', 'healthy', 'healthy', 'angular_leaf_spot', 'angular_leaf_spot', 'angular_leaf_spot', 'angular_leaf_spot', 'angular_leaf_spot', 'angular_leaf_spot', 'angular_leaf_spot', 'angular_leaf_spot', 'angular_leaf_spot', 'angular_leaf_spot', 'angular_leaf_spot', 'bean_rust', 'bean_rust', 'bean_rust', 'bean_rust', 'bean_rust', 'bean_rust', 'bean_rust', 'bean_rust', 'bean_rust', 'bean_rust', 'bean_rust']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([b'healthy', b'healthy', b'healthy', b'healthy', b'healthy',\n",
       "       b'healthy', b'healthy', b'healthy', b'healthy', b'healthy',\n",
       "       b'healthy', b'angular_leaf_spot', b'angular_leaf_spot',\n",
       "       b'angular_leaf_spot', b'angular_leaf_spot', b'angular_leaf_spot',\n",
       "       b'angular_leaf_spot', b'angular_leaf_spot', b'angular_leaf_spot',\n",
       "       b'angular_leaf_spot', b'angular_leaf_spot', b'angular_leaf_spot',\n",
       "       b'bean_rust', b'bean_rust', b'bean_rust', b'bean_rust',\n",
       "       b'bean_rust', b'bean_rust', b'bean_rust', b'bean_rust',\n",
       "       b'bean_rust', b'bean_rust', b'bean_rust'], dtype=object)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "image_regression_train_dir = \"/Users/treasures_y/Documents/code/HG/AutoML/python/autotrain/autotrain/datasets/image-regression\"\n",
    "image_classification_train_dir = \"/Users/treasures_y/Documents/code/HG/AutoML/python/autotrain/autotrain/datasets/image-classification\"\n",
    "train_dir = image_classification_train_dir\n",
    "items = os.listdir(train_dir)\n",
    "print(f\"category: {items}\")\n",
    "\n",
    "# ''\n",
    "folder_names = [item for item in items if os.path.isdir(os.path.join(train_dir, item))]\n",
    "task_type = \"image-classification\"\n",
    "file_paths = []\n",
    "labels = []\n",
    "for folder_name in folder_names:\n",
    "    files = glob.glob(os.path.join(train_dir, folder_name, '*'))\n",
    "    file_paths.extend(files)\n",
    "    if task_type == \"image-classification\":\n",
    "        labels.extend([folder_name] * len(files))\n",
    "    elif task_type == \"image-regression\":\n",
    "        labels.extend([float(folder_name)] * len(files))\n",
    "print(f\"labels: {labels}\")\n",
    "dataset = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
    "\n",
    "def load_image(file_path, label):\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.image.decode_image(image, channels=3)\n",
    "    #  256x256\n",
    "    image = tf.image.resize_with_crop_or_pad(image, 256, 256)\n",
    "    return image, label\n",
    "\n",
    "dataset = dataset.map(load_image)\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "for x, y in dataset:\n",
    "    x_train.append(x)\n",
    "    y_train.append(y)\n",
    "# \n",
    "x_train = np.asarray(tf.stack(x_train))\n",
    "y_train = np.asarray(tf.stack(y_train))\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RestoredOptimizer` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RestoredOptimizer`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "image_classification_model_path = \"/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/image-classification/best_model\"\n",
    "image_regression_model_path = \"/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/resnet-image-regression/best_model\"\n",
    "path = image_classification_model_path\n",
    "model = tf.keras.models.load_model(path)\n",
    "y_pred = model.predict_on_batch(x_train).argmax(axis=1)\n",
    "print(f\"y_pred: {y_pred}\")\n",
    "# metrics = model.evaluate(x_train, y_pred, return_dict=True)\n",
    "# metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['angular_leaf_spot',\n",
       " 'angular_leaf_spot',\n",
       " 'angular_leaf_spot',\n",
       " 'angular_leaf_spot',\n",
       " 'angular_leaf_spot',\n",
       " 'angular_leaf_spot',\n",
       " 'angular_leaf_spot',\n",
       " 'angular_leaf_spot',\n",
       " 'angular_leaf_spot',\n",
       " 'angular_leaf_spot',\n",
       " 'angular_leaf_spot',\n",
       " 'angular_leaf_spot',\n",
       " 'angular_leaf_spot',\n",
       " 'angular_leaf_spot',\n",
       " 'angular_leaf_spot',\n",
       " 'angular_leaf_spot',\n",
       " 'angular_leaf_spot',\n",
       " 'angular_leaf_spot',\n",
       " 'angular_leaf_spot',\n",
       " 'angular_leaf_spot',\n",
       " 'angular_leaf_spot',\n",
       " 'angular_leaf_spot',\n",
       " 'angular_leaf_spot',\n",
       " 'angular_leaf_spot',\n",
       " 'angular_leaf_spot',\n",
       " 'angular_leaf_spot',\n",
       " 'angular_leaf_spot',\n",
       " 'angular_leaf_spot',\n",
       " 'angular_leaf_spot',\n",
       " 'angular_leaf_spot',\n",
       " 'angular_leaf_spot',\n",
       " 'angular_leaf_spot',\n",
       " 'angular_leaf_spot']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = [items[pred_class] for pred_class in y_pred]\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666667"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = tf.metrics.Accuracy()\n",
    "acc.update_state([1, 1, 1], [1, 1, 0])\n",
    "acc_result = acc.result().numpy()\n",
    "acc_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = tf.metrics.Precision()\n",
    "precision.update_state([1, 1, 1, 0, 0], [1, 1, 0, 1, 1])\n",
    "precision_result = precision.result().numpy()\n",
    "precision_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = tf.metrics.Recall()\n",
    "recall.update_state([1, 1, 1], [1, 1, 0])\n",
    "recall_res = recall.result().numpy()\n",
    "recall_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14459364"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss = tf.metrics.LogCoshError()\n",
    "log_loss.update_state([1, 1, 1], [1, 1, 0])\n",
    "log_loss_res = log_loss.result().numpy()\n",
    "log_loss_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.120000005"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = tf.metrics.MeanSquaredError()\n",
    "mse.update_state([1.1, 0.9, 0.5], [0.5, 0.9, 0.5])\n",
    "mse_res = mse.result().numpy()\n",
    "mse_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34641016"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = tf.metrics.RootMeanSquaredError()\n",
    "rmse.update_state([1.1, 0.9, 0.5], [0.5, 0.9, 0.5])\n",
    "rmse_res = rmse.result().numpy()\n",
    "rmse_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = tf.metrics.MeanAbsoluteError()\n",
    "mae.update_state([1.1, 0.9, 0.5], [0.5, 0.9, 0.5])\n",
    "mae_res = mae.result().numpy()\n",
    "mae_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.181818"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape = tf.metrics.MeanAbsolutePercentageError()\n",
    "mape.update_state([1.1, 0.9, 0.5], [0.5, 0.9, 0.5])\n",
    "mape_res = mape.result().numpy()\n",
    "mape_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root: /Users/treasures_y/Documents/code/HG/AutoML/python/automl/autotrain/datasets/image-classification\n",
      " dir: ['healthy', 'angular_leaf_spot', 'bean_rust']\n",
      " files: []\n",
      "root: /Users/treasures_y/Documents/code/HG/AutoML/python/automl/autotrain/datasets/image-classification/healthy\n",
      " dir: []\n",
      " files: ['healthy_val.6.jpg', 'healthy_val.7.jpg', 'healthy_val.5.jpg', 'healthy_val.4.jpg', 'healthy_val.0.jpg', 'healthy_val.1.jpg', 'healthy_val.3.jpg', 'healthy_val.2.jpg', 'healthy_val.10.jpg', 'healthy_val.9.jpg', 'healthy_val.8.jpg']\n",
      "root: /Users/treasures_y/Documents/code/HG/AutoML/python/automl/autotrain/datasets/image-classification/angular_leaf_spot\n",
      " dir: []\n",
      " files: ['angular_leaf_spot_val.1.jpg', 'angular_leaf_spot_val.0.jpg', 'angular_leaf_spot_val.2.jpg', 'angular_leaf_spot_val.3.jpg', 'angular_leaf_spot_val.7.jpg', 'angular_leaf_spot_val.6.jpg', 'angular_leaf_spot_val.4.jpg', 'angular_leaf_spot_val.5.jpg', 'angular_leaf_spot_val.8.jpg', 'angular_leaf_spot_val.9.jpg', 'angular_leaf_spot_val.10.jpg']\n",
      "root: /Users/treasures_y/Documents/code/HG/AutoML/python/automl/autotrain/datasets/image-classification/bean_rust\n",
      " dir: []\n",
      " files: ['bean_rust_val.10.jpg', 'bean_rust_val.8.jpg', 'bean_rust_val.9.jpg', 'bean_rust_val.7.jpg', 'bean_rust_val.6.jpg', 'bean_rust_val.4.jpg', 'bean_rust_val.5.jpg', 'bean_rust_val.1.jpg', 'bean_rust_val.0.jpg', 'bean_rust_val.2.jpg', 'bean_rust_val.3.jpg']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "FOLDER_PATH = \"/Users/treasures_y/Documents/code/HG/AutoML/python/automl/autotrain/datasets/image-classification\"\n",
    "for root, dirs, files in os.walk(FOLDER_PATH):\n",
    "    print(f\"root: {root}\\n dir: {dirs}\\n files: {files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "https://docs.ultralytics.com/guides/hyperparameter-tuning/#file-structure\n",
    "\n",
    "datasets: https://datasetsearch.research.google.com/\n",
    "    https://www.kaggle.com/datasets\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/treasures_y/Miniconda3/envs/automl/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-11-05 19:38:57,641\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-11-05 19:38:58,312\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTuner: \u001b[0mInitialized Tuner instance with 'tune_dir=runs/detect/tune'\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m Learn about tuning at https://docs.ultralytics.com/guides/hyperparameter-tuning\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 1/1 with hyperparameters: {'lr0': 0.01, 'lrf': 0.01, 'momentum': 0.937, 'weight_decay': 0.0005, 'warmup_epochs': 3.0, 'warmup_momentum': 0.8, 'box': 7.5, 'cls': 0.5, 'dfl': 1.5, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.1, 'scale': 0.5, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5, 'bgr': 0.0, 'mosaic': 1.0, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "New https://pypi.org/project/ultralytics/8.3.27 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.91  Python-3.9.18 torch-2.4.1 CPU (Apple M3 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/Users/treasures_y/Desktop/automl-yolo/yolov8n.pt, data=/Users/treasures_y/Desktop/automl-yolo/coco-config.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=False, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=False, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
      "Model summary: 225 layers, 3,157,200 parameters, 3,157,184 gradients, 8.9 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "WARNING  No labels found in /Users/treasures_y/Desktop/automl-yolo/train.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
      "WARNING  No labels found in /Users/treasures_y/Desktop/automl-yolo/val.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/treasures_y/Desktop/automl-yolo/train.cache... 0 images, 15 backgrounds, 0 corrupt: 100%|| 15/15 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/treasures_y/Desktop/automl-yolo/val.cache... 0 images, 15 backgrounds, 0 corrupt: 100%|| 15/15 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10         0G          0      453.6          0          0        640: 100%|| 1/1 [00:02<00:00,  2.88s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10         0G          0        131          0          0        640: 100%|| 1/1 [00:02<00:00,  2.42s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10         0G          0      20.87          0          0        640: 100%|| 1/1 [00:02<00:00,  2.34s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10         0G          0      5.516          0          0        640: 100%|| 1/1 [00:02<00:00,  2.23s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10         0G          0      2.285          0          0        640: 100%|| 1/1 [00:02<00:00,  2.20s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10         0G          0      1.319          0          0        640: 100%|| 1/1 [00:02<00:00,  2.23s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10         0G          0     0.6645          0          0        640: 100%|| 1/1 [00:02<00:00,  2.23s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10         0G          0     0.3874          0          0        640: 100%|| 1/1 [00:02<00:00,  2.26s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10         0G          0      0.234          0          0        640: 100%|| 1/1 [00:02<00:00,  2.32s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10         0G          0     0.1268          0          0        640: 100%|| 1/1 [00:02<00:00,  2.23s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:01<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         15          0          0          0          0          0\n",
      "WARNING  no labels found in detect set, can not compute metrics without labels\n",
      "\n",
      "10 epochs completed in 0.008 hours.\n",
      "Optimizer stripped from runs/detect/train/weights/last.pt, 6.5MB\n",
      "Optimizer stripped from runs/detect/train/weights/best.pt, 6.5MB\n",
      "\n",
      "Validating runs/detect/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.91  Python-3.9.18 torch-2.4.1 CPU (Apple M3 Pro)\n",
      "Model summary (fused): 168 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         15          0          0          0          0          0\n",
      "WARNING  no labels found in detect set, can not compute metrics without labels\n",
      "Speed: 0.9ms preprocess, 48.1ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      " Learn more at https://docs.ultralytics.com/modes/train\n",
      "Saved runs/detect/tune/tune_scatter_plots.png\n",
      "Saved runs/detect/tune/tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m1/1 iterations complete  (51.90s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns/detect/tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.0 observed at iteration 1\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.0, 'metrics/recall(B)': 0.0, 'metrics/mAP50(B)': 0.0, 'metrics/mAP50-95(B)': 0.0, 'val/box_loss': 0.0, 'val/cls_loss': 10.25279, 'val/dfl_loss': 0.0, 'fitness': 0.0}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs/detect/train\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns/detect/tune/best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.01\n",
      "lrf: 0.01\n",
      "momentum: 0.937\n",
      "weight_decay: 0.0005\n",
      "warmup_epochs: 3.0\n",
      "warmup_momentum: 0.8\n",
      "box: 7.5\n",
      "cls: 0.5\n",
      "dfl: 1.5\n",
      "hsv_h: 0.015\n",
      "hsv_s: 0.7\n",
      "hsv_v: 0.4\n",
      "degrees: 0.0\n",
      "translate: 0.1\n",
      "scale: 0.5\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.5\n",
      "bgr: 0.0\n",
      "mosaic: 1.0\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from ultralytics import YOLO\n",
    "root_path = \"/Users/treasures_y/Desktop/automl-yolo\"\n",
    "# Initialize the YOLO model\n",
    "model = YOLO(f\"{root_path}/yolov8n.pt\", task=\"segment\")\n",
    "\n",
    "from ray import tune\n",
    "default_space = {\n",
    "    # 'optimizer': tune.choice(['SGD', 'Adam', 'AdamW', 'NAdam', 'RAdam', 'RMSProp']),\n",
    "    \"lr0\": tune.uniform(1e-5, 1e-1),\n",
    "    \"lrf\": tune.uniform(0.01, 1.0),  # final OneCycleLR learning rate (lr0 * lrf)\n",
    "    \"momentum\": tune.uniform(0.6, 0.98),  # SGD momentum/Adam beta1\n",
    "    \"weight_decay\": tune.uniform(0.0, 0.001),  # optimizer weight decay 5e-4\n",
    "    \"warmup_epochs\": tune.uniform(0.0, 5.0),  # warmup epochs (fractions ok)\n",
    "    \"warmup_momentum\": tune.uniform(0.0, 0.95),  # warmup initial momentum\n",
    "    \"box\": tune.uniform(0.02, 0.2),  # box loss gain\n",
    "    \"cls\": tune.uniform(0.2, 4.0),  # cls loss gain (scale with pixels)\n",
    "    \"hsv_h\": tune.uniform(0.0, 0.1),  # image HSV-Hue augmentation (fraction)\n",
    "    \"hsv_s\": tune.uniform(0.0, 0.9),  # image HSV-Saturation augmentation (fraction)\n",
    "    \"hsv_v\": tune.uniform(0.0, 0.9),  # image HSV-Value augmentation (fraction)\n",
    "    \"degrees\": tune.uniform(0.0, 45.0),  # image rotation (+/- deg)\n",
    "    \"translate\": tune.uniform(0.0, 0.9),  # image translation (+/- fraction)\n",
    "    \"scale\": tune.uniform(0.0, 0.9),  # image scale (+/- gain)\n",
    "    \"shear\": tune.uniform(0.0, 10.0),  # image shear (+/- deg)\n",
    "    \"perspective\": tune.uniform(0.0, 0.001),  # image perspective (+/- fraction), range 0-0.001\n",
    "    \"flipud\": tune.uniform(0.0, 1.0),  # image flip up-down (probability)\n",
    "    \"fliplr\": tune.uniform(0.0, 1.0),  # image flip left-right (probability)\n",
    "    \"bgr\": tune.uniform(0.0, 1.0),  # image channel BGR (probability)\n",
    "    \"mosaic\": tune.uniform(0.0, 1.0),  # image mixup (probability)\n",
    "    \"mixup\": tune.uniform(0.0, 1.0),  # image mixup (probability)\n",
    "    \"copy_paste\": tune.uniform(0.0, 1.0),  # segment copy-paste (probability)\n",
    "}\n",
    "# Tune hyperparameters on COCO8 for 30 epochs\n",
    "results = model.tune(\n",
    "    data=f\"{root_path}/coco-config.yaml\", \n",
    "    epochs=10, iterations=1, optimizer=\"AdamW\", plots=False, save=False, val=False,\n",
    "    # space=default_space\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'76777_00000': {'metrics/precision(B)': 0.6267196962455869,\n",
       "  'metrics/recall(B)': 0.8333333333333334,\n",
       "  'metrics/mAP50(B)': 0.8767447429843425,\n",
       "  'metrics/mAP50-95(B)': 0.6315205111841419,\n",
       "  'fitness': 0.656042934364162,\n",
       "  'timestamp': 1725971461,\n",
       "  'checkpoint_dir_name': None,\n",
       "  'done': True,\n",
       "  'training_iteration': 12,\n",
       "  'trial_id': '76777_00000',\n",
       "  'date': '2024-09-10_20-31-01',\n",
       "  'time_this_iter_s': 0.5646321773529053,\n",
       "  'time_total_s': 31.557960987091064,\n",
       "  'pid': 65761,\n",
       "  'hostname': 'MacBook-Pro-2.local',\n",
       "  'node_ip': '127.0.0.1',\n",
       "  'config': {'lr0': 0.060043219787392986,\n",
       "   'lrf': 0.5928522138705853,\n",
       "   'momentum': 0.965852721539292,\n",
       "   'weight_decay': 1.6871673370039698e-05,\n",
       "   'warmup_epochs': 3.4824121535072505,\n",
       "   'warmup_momentum': 0.7729947172167703,\n",
       "   'box': 0.11176529539188516,\n",
       "   'cls': 1.4690665044678748,\n",
       "   'hsv_h': 0.0790840163227405,\n",
       "   'hsv_s': 0.08751863306918219,\n",
       "   'hsv_v': 0.39783207395693276,\n",
       "   'degrees': 23.39785685568772,\n",
       "   'translate': 0.6245607698410928,\n",
       "   'scale': 0.08179715882916852,\n",
       "   'shear': 2.2775950153786093,\n",
       "   'perspective': 0.00041030156269012563,\n",
       "   'flipud': 0.6232946730201306,\n",
       "   'fliplr': 0.8869607812174175,\n",
       "   'bgr': 0.6188261682413765,\n",
       "   'mosaic': 0.13346147093493443,\n",
       "   'mixup': 0.9805801327872824,\n",
       "   'copy_paste': 0.8717857347554929,\n",
       "   'data': 'coco8.yaml',\n",
       "   'epochs': 10},\n",
       "  'time_since_restore': 31.557960987091064,\n",
       "  'iterations_since_restore': 12,\n",
       "  'experiment_tag': '0_bgr=0.6188,box=0.1118,cls=1.4691,copy_paste=0.8718,degrees=23.3979,fliplr=0.8870,flipud=0.6233,hsv_h=0.0791,hsv_s=0.0875,hsv_v=0.3978,lr0=0.0600,lrf=0.5929,mixup=0.9806,momentum=0.9659,mosaic=0.1335,perspective=0.0004,scale=0.0818,shear=2.2776,translate=0.6246,warmup_epochs=3.4824,warmup_momentum=0.7730,weight_decay=0.0000'},\n",
       " '76777_00001': {'metrics/precision(B)': 0.6632474424637527,\n",
       "  'metrics/recall(B)': 0.8333333333333334,\n",
       "  'metrics/mAP50(B)': 0.8880589396172258,\n",
       "  'metrics/mAP50-95(B)': 0.6374851900889654,\n",
       "  'fitness': 0.6625425650417914,\n",
       "  'timestamp': 1725971493,\n",
       "  'checkpoint_dir_name': None,\n",
       "  'done': True,\n",
       "  'training_iteration': 12,\n",
       "  'trial_id': '76777_00001',\n",
       "  'date': '2024-09-10_20-31-33',\n",
       "  'time_this_iter_s': 0.5746691226959229,\n",
       "  'time_total_s': 30.80042862892151,\n",
       "  'pid': 65839,\n",
       "  'hostname': 'MacBook-Pro-2.local',\n",
       "  'node_ip': '127.0.0.1',\n",
       "  'config': {'lr0': 0.09223557469984534,\n",
       "   'lrf': 0.5459669858195644,\n",
       "   'momentum': 0.950856305797882,\n",
       "   'weight_decay': 0.0008298973686033432,\n",
       "   'warmup_epochs': 4.841432051471487,\n",
       "   'warmup_momentum': 0.8737936702392504,\n",
       "   'box': 0.026486087137142508,\n",
       "   'cls': 0.8641336158115718,\n",
       "   'hsv_h': 0.03891346771011858,\n",
       "   'hsv_s': 0.8569284275658787,\n",
       "   'hsv_v': 0.27002602752833665,\n",
       "   'degrees': 7.221043974942047,\n",
       "   'translate': 0.797674199477904,\n",
       "   'scale': 0.40175497393488263,\n",
       "   'shear': 9.07875594354326,\n",
       "   'perspective': 0.00016023046632014326,\n",
       "   'flipud': 0.6611175115080995,\n",
       "   'fliplr': 0.4402637528294918,\n",
       "   'bgr': 0.0764867690302854,\n",
       "   'mosaic': 0.6964631446525006,\n",
       "   'mixup': 0.2473987555391537,\n",
       "   'copy_paste': 0.039615522579517726,\n",
       "   'data': 'coco8.yaml',\n",
       "   'epochs': 10},\n",
       "  'time_since_restore': 30.80042862892151,\n",
       "  'iterations_since_restore': 12,\n",
       "  'experiment_tag': '1_bgr=0.0765,box=0.0265,cls=0.8641,copy_paste=0.0396,degrees=7.2210,fliplr=0.4403,flipud=0.6611,hsv_h=0.0389,hsv_s=0.8569,hsv_v=0.2700,lr0=0.0922,lrf=0.5460,mixup=0.2474,momentum=0.9509,mosaic=0.6965,perspective=0.0002,scale=0.4018,shear=9.0788,translate=0.7977,warmup_epochs=4.8414,warmup_momentum=0.8738,weight_decay=0.0008'}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results._experiment_analysis.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metrics/precision(B)</th>\n",
       "      <th>metrics/recall(B)</th>\n",
       "      <th>metrics/mAP50(B)</th>\n",
       "      <th>metrics/mAP50-95(B)</th>\n",
       "      <th>val/box_loss</th>\n",
       "      <th>val/cls_loss</th>\n",
       "      <th>val/dfl_loss</th>\n",
       "      <th>epoch</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>checkpoint_dir_name</th>\n",
       "      <th>...</th>\n",
       "      <th>config/perspective</th>\n",
       "      <th>config/flipud</th>\n",
       "      <th>config/fliplr</th>\n",
       "      <th>config/bgr</th>\n",
       "      <th>config/mosaic</th>\n",
       "      <th>config/mixup</th>\n",
       "      <th>config/copy_paste</th>\n",
       "      <th>config/data</th>\n",
       "      <th>config/epochs</th>\n",
       "      <th>fitness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.64445</td>\n",
       "      <td>0.852560</td>\n",
       "      <td>0.888470</td>\n",
       "      <td>0.624460</td>\n",
       "      <td>0.02082</td>\n",
       "      <td>3.84412</td>\n",
       "      <td>1.24888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1725971447</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00041</td>\n",
       "      <td>0.623295</td>\n",
       "      <td>0.886961</td>\n",
       "      <td>0.618826</td>\n",
       "      <td>0.133461</td>\n",
       "      <td>0.98058</td>\n",
       "      <td>0.871786</td>\n",
       "      <td>coco8.yaml</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.71180</td>\n",
       "      <td>0.827420</td>\n",
       "      <td>0.888570</td>\n",
       "      <td>0.611860</td>\n",
       "      <td>0.02106</td>\n",
       "      <td>3.85951</td>\n",
       "      <td>1.25063</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1725971448</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00041</td>\n",
       "      <td>0.623295</td>\n",
       "      <td>0.886961</td>\n",
       "      <td>0.618826</td>\n",
       "      <td>0.133461</td>\n",
       "      <td>0.98058</td>\n",
       "      <td>0.871786</td>\n",
       "      <td>coco8.yaml</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.81781</td>\n",
       "      <td>0.816670</td>\n",
       "      <td>0.887120</td>\n",
       "      <td>0.626660</td>\n",
       "      <td>0.02122</td>\n",
       "      <td>3.83398</td>\n",
       "      <td>1.25397</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1725971449</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00041</td>\n",
       "      <td>0.623295</td>\n",
       "      <td>0.886961</td>\n",
       "      <td>0.618826</td>\n",
       "      <td>0.133461</td>\n",
       "      <td>0.98058</td>\n",
       "      <td>0.871786</td>\n",
       "      <td>coco8.yaml</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.66675</td>\n",
       "      <td>0.816670</td>\n",
       "      <td>0.888680</td>\n",
       "      <td>0.630570</td>\n",
       "      <td>0.02121</td>\n",
       "      <td>3.86236</td>\n",
       "      <td>1.24877</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1725971450</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00041</td>\n",
       "      <td>0.623295</td>\n",
       "      <td>0.886961</td>\n",
       "      <td>0.618826</td>\n",
       "      <td>0.133461</td>\n",
       "      <td>0.98058</td>\n",
       "      <td>0.871786</td>\n",
       "      <td>coco8.yaml</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.62245</td>\n",
       "      <td>0.833330</td>\n",
       "      <td>0.890910</td>\n",
       "      <td>0.628810</td>\n",
       "      <td>0.02131</td>\n",
       "      <td>3.98945</td>\n",
       "      <td>1.25312</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1725971452</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00041</td>\n",
       "      <td>0.623295</td>\n",
       "      <td>0.886961</td>\n",
       "      <td>0.618826</td>\n",
       "      <td>0.133461</td>\n",
       "      <td>0.98058</td>\n",
       "      <td>0.871786</td>\n",
       "      <td>coco8.yaml</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.58544</td>\n",
       "      <td>0.833330</td>\n",
       "      <td>0.876270</td>\n",
       "      <td>0.635560</td>\n",
       "      <td>0.02136</td>\n",
       "      <td>4.03633</td>\n",
       "      <td>1.25661</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1725971453</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00041</td>\n",
       "      <td>0.623295</td>\n",
       "      <td>0.886961</td>\n",
       "      <td>0.618826</td>\n",
       "      <td>0.133461</td>\n",
       "      <td>0.98058</td>\n",
       "      <td>0.871786</td>\n",
       "      <td>coco8.yaml</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.66275</td>\n",
       "      <td>0.833330</td>\n",
       "      <td>0.875430</td>\n",
       "      <td>0.631520</td>\n",
       "      <td>0.02138</td>\n",
       "      <td>4.04555</td>\n",
       "      <td>1.25281</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1725971454</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00041</td>\n",
       "      <td>0.623295</td>\n",
       "      <td>0.886961</td>\n",
       "      <td>0.618826</td>\n",
       "      <td>0.133461</td>\n",
       "      <td>0.98058</td>\n",
       "      <td>0.871786</td>\n",
       "      <td>coco8.yaml</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.62962</td>\n",
       "      <td>0.833330</td>\n",
       "      <td>0.876130</td>\n",
       "      <td>0.647770</td>\n",
       "      <td>0.02140</td>\n",
       "      <td>4.14186</td>\n",
       "      <td>1.25803</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1725971455</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00041</td>\n",
       "      <td>0.623295</td>\n",
       "      <td>0.886961</td>\n",
       "      <td>0.618826</td>\n",
       "      <td>0.133461</td>\n",
       "      <td>0.98058</td>\n",
       "      <td>0.871786</td>\n",
       "      <td>coco8.yaml</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.60891</td>\n",
       "      <td>0.846330</td>\n",
       "      <td>0.807260</td>\n",
       "      <td>0.567790</td>\n",
       "      <td>0.02141</td>\n",
       "      <td>4.25386</td>\n",
       "      <td>1.26202</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1725971456</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00041</td>\n",
       "      <td>0.623295</td>\n",
       "      <td>0.886961</td>\n",
       "      <td>0.618826</td>\n",
       "      <td>0.133461</td>\n",
       "      <td>0.98058</td>\n",
       "      <td>0.871786</td>\n",
       "      <td>coco8.yaml</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.61743</td>\n",
       "      <td>0.766670</td>\n",
       "      <td>0.806380</td>\n",
       "      <td>0.571300</td>\n",
       "      <td>0.02158</td>\n",
       "      <td>4.34268</td>\n",
       "      <td>1.26646</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1725971457</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00041</td>\n",
       "      <td>0.623295</td>\n",
       "      <td>0.886961</td>\n",
       "      <td>0.618826</td>\n",
       "      <td>0.133461</td>\n",
       "      <td>0.98058</td>\n",
       "      <td>0.871786</td>\n",
       "      <td>coco8.yaml</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.62672</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.876745</td>\n",
       "      <td>0.631521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1725971460</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00041</td>\n",
       "      <td>0.623295</td>\n",
       "      <td>0.886961</td>\n",
       "      <td>0.618826</td>\n",
       "      <td>0.133461</td>\n",
       "      <td>0.98058</td>\n",
       "      <td>0.871786</td>\n",
       "      <td>coco8.yaml</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.62672</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.876745</td>\n",
       "      <td>0.631521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1725971461</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00041</td>\n",
       "      <td>0.623295</td>\n",
       "      <td>0.886961</td>\n",
       "      <td>0.618826</td>\n",
       "      <td>0.133461</td>\n",
       "      <td>0.98058</td>\n",
       "      <td>0.871786</td>\n",
       "      <td>coco8.yaml</td>\n",
       "      <td>10</td>\n",
       "      <td>0.656043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows  46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    metrics/precision(B)  metrics/recall(B)  metrics/mAP50(B)  \\\n",
       "0                0.64445           0.852560          0.888470   \n",
       "1                0.71180           0.827420          0.888570   \n",
       "2                0.81781           0.816670          0.887120   \n",
       "3                0.66675           0.816670          0.888680   \n",
       "4                0.62245           0.833330          0.890910   \n",
       "5                0.58544           0.833330          0.876270   \n",
       "6                0.66275           0.833330          0.875430   \n",
       "7                0.62962           0.833330          0.876130   \n",
       "8                0.60891           0.846330          0.807260   \n",
       "9                0.61743           0.766670          0.806380   \n",
       "10               0.62672           0.833333          0.876745   \n",
       "11               0.62672           0.833333          0.876745   \n",
       "\n",
       "    metrics/mAP50-95(B)  val/box_loss  val/cls_loss  val/dfl_loss  epoch  \\\n",
       "0              0.624460       0.02082       3.84412       1.24888    0.0   \n",
       "1              0.611860       0.02106       3.85951       1.25063    1.0   \n",
       "2              0.626660       0.02122       3.83398       1.25397    2.0   \n",
       "3              0.630570       0.02121       3.86236       1.24877    3.0   \n",
       "4              0.628810       0.02131       3.98945       1.25312    4.0   \n",
       "5              0.635560       0.02136       4.03633       1.25661    5.0   \n",
       "6              0.631520       0.02138       4.04555       1.25281    6.0   \n",
       "7              0.647770       0.02140       4.14186       1.25803    7.0   \n",
       "8              0.567790       0.02141       4.25386       1.26202    8.0   \n",
       "9              0.571300       0.02158       4.34268       1.26646    9.0   \n",
       "10             0.631521           NaN           NaN           NaN    9.0   \n",
       "11             0.631521           NaN           NaN           NaN    NaN   \n",
       "\n",
       "     timestamp checkpoint_dir_name  ...  config/perspective  config/flipud  \\\n",
       "0   1725971447                None  ...             0.00041       0.623295   \n",
       "1   1725971448                None  ...             0.00041       0.623295   \n",
       "2   1725971449                None  ...             0.00041       0.623295   \n",
       "3   1725971450                None  ...             0.00041       0.623295   \n",
       "4   1725971452                None  ...             0.00041       0.623295   \n",
       "5   1725971453                None  ...             0.00041       0.623295   \n",
       "6   1725971454                None  ...             0.00041       0.623295   \n",
       "7   1725971455                None  ...             0.00041       0.623295   \n",
       "8   1725971456                None  ...             0.00041       0.623295   \n",
       "9   1725971457                None  ...             0.00041       0.623295   \n",
       "10  1725971460                None  ...             0.00041       0.623295   \n",
       "11  1725971461                None  ...             0.00041       0.623295   \n",
       "\n",
       "   config/fliplr config/bgr  config/mosaic  config/mixup  config/copy_paste  \\\n",
       "0       0.886961   0.618826       0.133461       0.98058           0.871786   \n",
       "1       0.886961   0.618826       0.133461       0.98058           0.871786   \n",
       "2       0.886961   0.618826       0.133461       0.98058           0.871786   \n",
       "3       0.886961   0.618826       0.133461       0.98058           0.871786   \n",
       "4       0.886961   0.618826       0.133461       0.98058           0.871786   \n",
       "5       0.886961   0.618826       0.133461       0.98058           0.871786   \n",
       "6       0.886961   0.618826       0.133461       0.98058           0.871786   \n",
       "7       0.886961   0.618826       0.133461       0.98058           0.871786   \n",
       "8       0.886961   0.618826       0.133461       0.98058           0.871786   \n",
       "9       0.886961   0.618826       0.133461       0.98058           0.871786   \n",
       "10      0.886961   0.618826       0.133461       0.98058           0.871786   \n",
       "11      0.886961   0.618826       0.133461       0.98058           0.871786   \n",
       "\n",
       "   config/data config/epochs   fitness  \n",
       "0   coco8.yaml            10       NaN  \n",
       "1   coco8.yaml            10       NaN  \n",
       "2   coco8.yaml            10       NaN  \n",
       "3   coco8.yaml            10       NaN  \n",
       "4   coco8.yaml            10       NaN  \n",
       "5   coco8.yaml            10       NaN  \n",
       "6   coco8.yaml            10       NaN  \n",
       "7   coco8.yaml            10       NaN  \n",
       "8   coco8.yaml            10       NaN  \n",
       "9   coco8.yaml            10       NaN  \n",
       "10  coco8.yaml            10       NaN  \n",
       "11  coco8.yaml            10  0.656043  \n",
       "\n",
       "[12 rows x 46 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].metrics_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metrics/precision(B)</th>\n",
       "      <th>metrics/recall(B)</th>\n",
       "      <th>metrics/mAP50(B)</th>\n",
       "      <th>metrics/mAP50-95(B)</th>\n",
       "      <th>val/box_loss</th>\n",
       "      <th>val/cls_loss</th>\n",
       "      <th>val/dfl_loss</th>\n",
       "      <th>epoch</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>checkpoint_dir_name</th>\n",
       "      <th>...</th>\n",
       "      <th>config/flipud</th>\n",
       "      <th>config/fliplr</th>\n",
       "      <th>config/bgr</th>\n",
       "      <th>config/mosaic</th>\n",
       "      <th>config/mixup</th>\n",
       "      <th>config/copy_paste</th>\n",
       "      <th>config/data</th>\n",
       "      <th>config/epochs</th>\n",
       "      <th>fitness</th>\n",
       "      <th>logdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.626720</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.876745</td>\n",
       "      <td>0.631521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1725971461</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623295</td>\n",
       "      <td>0.886961</td>\n",
       "      <td>0.618826</td>\n",
       "      <td>0.133461</td>\n",
       "      <td>0.980580</td>\n",
       "      <td>0.871786</td>\n",
       "      <td>coco8.yaml</td>\n",
       "      <td>10</td>\n",
       "      <td>0.656043</td>\n",
       "      <td>76777_00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.663247</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.888059</td>\n",
       "      <td>0.637485</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1725971493</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661118</td>\n",
       "      <td>0.440264</td>\n",
       "      <td>0.076487</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.247399</td>\n",
       "      <td>0.039616</td>\n",
       "      <td>coco8.yaml</td>\n",
       "      <td>10</td>\n",
       "      <td>0.662543</td>\n",
       "      <td>76777_00001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   metrics/precision(B)  metrics/recall(B)  metrics/mAP50(B)  \\\n",
       "0              0.626720           0.833333          0.876745   \n",
       "1              0.663247           0.833333          0.888059   \n",
       "\n",
       "   metrics/mAP50-95(B)  val/box_loss  val/cls_loss  val/dfl_loss  epoch  \\\n",
       "0             0.631521           NaN           NaN           NaN    NaN   \n",
       "1             0.637485           NaN           NaN           NaN    NaN   \n",
       "\n",
       "    timestamp checkpoint_dir_name  ...  config/flipud  config/fliplr  \\\n",
       "0  1725971461                None  ...       0.623295       0.886961   \n",
       "1  1725971493                None  ...       0.661118       0.440264   \n",
       "\n",
       "  config/bgr config/mosaic  config/mixup  config/copy_paste  config/data  \\\n",
       "0   0.618826      0.133461      0.980580           0.871786   coco8.yaml   \n",
       "1   0.076487      0.696463      0.247399           0.039616   coco8.yaml   \n",
       "\n",
       "  config/epochs   fitness       logdir  \n",
       "0            10  0.656043  76777_00000  \n",
       "1            10  0.662543  76777_00001  \n",
       "\n",
       "[2 rows x 47 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.get_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.91  Python-3.9.18 torch-2.4.1 CPU (Apple M3 Pro)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/treasures_y/Desktop/automl-yolo/val.cache... 0 images, 15 backgrounds, 0 corrupt: 100%|| 15/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  No labels found in /Users/treasures_y/Desktop/automl-yolo/val.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 1/1 [00:00<00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         15          0          0          0          0          0\n",
      "WARNING  no labels found in detect set, can not compute metrics without labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 1.0ms preprocess, 54.7ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val4\u001b[0m\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DetMetrics' object has no attribute 'curves_results'. See valid attributes below.\n\n    Utility class for computing detection metrics such as precision, recall, and mean average precision (mAP) of an\n    object detection model.\n\n    Args:\n        save_dir (Path): A path to the directory where the output plots will be saved. Defaults to current directory.\n        plot (bool): A flag that indicates whether to plot precision-recall curves for each class. Defaults to False.\n        on_plot (func): An optional callback to pass plots path and data when they are rendered. Defaults to None.\n        names (dict of str): A dict of strings that represents the names of the classes. Defaults to an empty tuple.\n\n    Attributes:\n        save_dir (Path): A path to the directory where the output plots will be saved.\n        plot (bool): A flag that indicates whether to plot the precision-recall curves for each class.\n        on_plot (func): An optional callback to pass plots path and data when they are rendered.\n        names (dict of str): A dict of strings that represents the names of the classes.\n        box (Metric): An instance of the Metric class for storing the results of the detection metrics.\n        speed (dict): A dictionary for storing the execution time of different parts of the detection process.\n\n    Methods:\n        process(tp, conf, pred_cls, target_cls): Updates the metric results with the latest batch of predictions.\n        keys: Returns a list of keys for accessing the computed detection metrics.\n        mean_results: Returns a list of mean values for the computed detection metrics.\n        class_result(i): Returns a list of values for the computed detection metrics for a specific class.\n        maps: Returns a dictionary of mean average precision (mAP) values for different IoU thresholds.\n        fitness: Computes the fitness score based on the computed detection metrics.\n        ap_class_index: Returns a list of class indices sorted by their average precision (AP) values.\n        results_dict: Returns a dictionary that maps detection metric keys to their computed values.\n        curves: TODO\n        curves_results: TODO\n    ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/Miniconda3/envs/automl/lib/python3.9/site-packages/IPython/core/formatters.py:708\u001b[0m, in \u001b[0;36mPlainTextFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    701\u001b[0m stream \u001b[38;5;241m=\u001b[39m StringIO()\n\u001b[1;32m    702\u001b[0m printer \u001b[38;5;241m=\u001b[39m pretty\u001b[38;5;241m.\u001b[39mRepresentationPrinter(stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnewline,\n\u001b[1;32m    704\u001b[0m     max_seq_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_seq_length,\n\u001b[1;32m    705\u001b[0m     singleton_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingleton_printers,\n\u001b[1;32m    706\u001b[0m     type_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_printers,\n\u001b[1;32m    707\u001b[0m     deferred_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeferred_printers)\n\u001b[0;32m--> 708\u001b[0m \u001b[43mprinter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m printer\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stream\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m~/Miniconda3/envs/automl/lib/python3.9/site-packages/IPython/lib/pretty.py:410\u001b[0m, in \u001b[0;36mRepresentationPrinter.pretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    407\u001b[0m                         \u001b[38;5;28;01mreturn\u001b[39;00m meth(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[1;32m    408\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mobject\u001b[39m \\\n\u001b[1;32m    409\u001b[0m                         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__repr__\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m--> 410\u001b[0m                     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_repr_pprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_pprint(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/Miniconda3/envs/automl/lib/python3.9/site-packages/IPython/lib/pretty.py:778\u001b[0m, in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[39;00m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;66;03m# Find newlines and replace them with p.break_()\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m lines \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgroup():\n",
      "File \u001b[0;32m~/Miniconda3/envs/automl/lib/python3.9/site-packages/ultralytics/utils/__init__.py:212\u001b[0m, in \u001b[0;36mSimpleClass.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    211\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a machine-readable string representation of the object.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__str__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Miniconda3/envs/automl/lib/python3.9/site-packages/ultralytics/utils/__init__.py:200\u001b[0m, in \u001b[0;36mSimpleClass.__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m attr \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 200\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(v) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m a\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, SimpleClass):\n\u001b[1;32m    203\u001b[0m             \u001b[38;5;66;03m# Display only the module and class name for subclasses\u001b[39;00m\n",
      "File \u001b[0;32m~/Miniconda3/envs/automl/lib/python3.9/site-packages/ultralytics/utils/__init__.py:217\u001b[0m, in \u001b[0;36mSimpleClass.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Custom attribute access error message with helpful information.\"\"\"\u001b[39;00m\n\u001b[1;32m    216\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m--> 217\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. See valid attributes below.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DetMetrics' object has no attribute 'curves_results'. See valid attributes below.\n\n    Utility class for computing detection metrics such as precision, recall, and mean average precision (mAP) of an\n    object detection model.\n\n    Args:\n        save_dir (Path): A path to the directory where the output plots will be saved. Defaults to current directory.\n        plot (bool): A flag that indicates whether to plot precision-recall curves for each class. Defaults to False.\n        on_plot (func): An optional callback to pass plots path and data when they are rendered. Defaults to None.\n        names (dict of str): A dict of strings that represents the names of the classes. Defaults to an empty tuple.\n\n    Attributes:\n        save_dir (Path): A path to the directory where the output plots will be saved.\n        plot (bool): A flag that indicates whether to plot the precision-recall curves for each class.\n        on_plot (func): An optional callback to pass plots path and data when they are rendered.\n        names (dict of str): A dict of strings that represents the names of the classes.\n        box (Metric): An instance of the Metric class for storing the results of the detection metrics.\n        speed (dict): A dictionary for storing the execution time of different parts of the detection process.\n\n    Methods:\n        process(tp, conf, pred_cls, target_cls): Updates the metric results with the latest batch of predictions.\n        keys: Returns a list of keys for accessing the computed detection metrics.\n        mean_results: Returns a list of mean values for the computed detection metrics.\n        class_result(i): Returns a list of values for the computed detection metrics for a specific class.\n        maps: Returns a dictionary of mean average precision (mAP) values for different IoU thresholds.\n        fitness: Computes the fitness score based on the computed detection metrics.\n        ap_class_index: Returns a list of class indices sorted by their average precision (AP) values.\n        results_dict: Returns a dictionary that maps detection metric keys to their computed values.\n        curves: TODO\n        curves_results: TODO\n    "
     ]
    }
   ],
   "source": [
    "model.val(data=\"/Users/treasures_y/Desktop/automl-yolo/coco-config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8n summary: 225 layers, 3,157,200 parameters, 0 gradients, 8.9 GFLOPs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(225, 3157200, 0, 8.8575488)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/treasures_y/Desktop/automl-yolo/test/000000000139.jpg: 448x640 1 person, 5 chairs, 1 potted plant, 2 dining tables, 1 tv, 1 refrigerator, 1 clock, 1 vase, 62.6ms\n",
      "Speed: 0.7ms preprocess, 62.6ms inference, 0.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "{0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "results = model.predict(source=\"/Users/treasures_y/Desktop/automl-yolo/test/000000000139.jpg\")\n",
    "\n",
    "for r in results:\n",
    "    print(r.names)\n",
    "    print(r.probs)\n",
    "    # print(r.names[r.probs.top1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/treasures_y/Desktop/automl-yolo/test/000000000139.jpg: 448x640 1 person, 5 chairs, 1 potted plant, 2 dining tables, 1 tv, 1 refrigerator, 1 clock, 1 vase, 36.2ms\n",
      "Speed: 0.8ms preprocess, 36.2ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'tv',\n",
       "  'class': 62,\n",
       "  'confidence': 0.92739,\n",
       "  'box': {'x1': 6.22098, 'y1': 166.24802, 'x2': 154.4986, 'y2': 261.89581}},\n",
       " {'name': 'chair',\n",
       "  'class': 56,\n",
       "  'confidence': 0.85419,\n",
       "  'box': {'x1': 293.22168, 'y1': 217.48145, 'x2': 354.43518, 'y2': 314.87286}},\n",
       " {'name': 'person',\n",
       "  'class': 0,\n",
       "  'confidence': 0.71234,\n",
       "  'box': {'x1': 412.59195, 'y1': 156.95374, 'x2': 465.75076, 'y2': 298.94629}},\n",
       " {'name': 'chair',\n",
       "  'class': 56,\n",
       "  'confidence': 0.52321,\n",
       "  'box': {'x1': 361.80774, 'y1': 217.06703, 'x2': 443.78369, 'y2': 311.24622}},\n",
       " {'name': 'chair',\n",
       "  'class': 56,\n",
       "  'confidence': 0.50827,\n",
       "  'box': {'x1': 388.7355, 'y1': 217.88876, 'x2': 443.91757, 'y2': 309.79672}},\n",
       " {'name': 'chair',\n",
       "  'class': 56,\n",
       "  'confidence': 0.50562,\n",
       "  'box': {'x1': 361.22339, 'y1': 217.56537, 'x2': 419.0769, 'y2': 310.80817}},\n",
       " {'name': 'potted plant',\n",
       "  'class': 58,\n",
       "  'confidence': 0.42069,\n",
       "  'box': {'x1': 225.85852, 'y1': 177.44037, 'x2': 266.60431, 'y2': 213.05164}},\n",
       " {'name': 'vase',\n",
       "  'class': 75,\n",
       "  'confidence': 0.39168,\n",
       "  'box': {'x1': 548.8031, 'y1': 297.73428, 'x2': 587.87683, 'y2': 401.03629}},\n",
       " {'name': 'refrigerator',\n",
       "  'class': 72,\n",
       "  'confidence': 0.35642,\n",
       "  'box': {'x1': 443.66541, 'y1': 167.49591, 'x2': 508.67932, 'y2': 292.983}},\n",
       " {'name': 'dining table',\n",
       "  'class': 60,\n",
       "  'confidence': 0.2783,\n",
       "  'box': {'x1': 461.22885, 'y1': 357.47418, 'x2': 640.0, 'y2': 424.65533}},\n",
       " {'name': 'clock',\n",
       "  'class': 74,\n",
       "  'confidence': 0.27787,\n",
       "  'box': {'x1': 448.56158, 'y1': 121.15518, 'x2': 461.38312, 'y2': 141.39749}},\n",
       " {'name': 'dining table',\n",
       "  'class': 60,\n",
       "  'confidence': 0.26677,\n",
       "  'box': {'x1': 297.00882, 'y1': 215.92273, 'x2': 415.49576, 'y2': 311.7124}},\n",
       " {'name': 'chair',\n",
       "  'class': 56,\n",
       "  'confidence': 0.26586,\n",
       "  'box': {'x1': 403.7688, 'y1': 221.19742, 'x2': 445.11316, 'y2': 307.07242}}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = model.predict(source=\"/Users/treasures_y/Desktop/automl-yolo/test/000000000139.jpg\")[0].summary()\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "```\n",
    "https://docs.ultralytics.com/modes/train/#train-settings\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.91  Python-3.9.18 torch-2.4.1 CPU (Apple M3 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/cls/yolov8n-cls.pt, data=/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=True, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2/train\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification/train... found 33 images in 3 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m None...\n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification/test... found 33 images in 3 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/treasures_y/Miniconda3/envs/automl/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-09-23 09:48:54,029\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-09-23 09:48:54,771\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=1000 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    334083  ultralytics.nn.modules.head.Classify         [256, 3]                      \n",
      "YOLOv8n-cls summary: 99 layers, 1,442,131 parameters, 1,442,131 gradients, 3.4 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification/train... 33 images, 0 corrupt: 100%|| 33/33 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification/test... 33 images, 0 corrupt: 100%|| 33/33 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2/train\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10         0G      1.099          1        640: 100%|| 3/3 [00:05<00:00,  1.70s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|| 2/2 [00:02<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.303          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       2/10         0G      1.048          1        640: 100%|| 3/3 [00:04<00:00,  1.63s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|| 2/2 [00:02<00:00,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.303          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       3/10         0G      1.061          1        640: 100%|| 3/3 [00:04<00:00,  1.58s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|| 2/2 [00:02<00:00,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.424          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       4/10         0G      1.155          1        640: 100%|| 3/3 [00:04<00:00,  1.55s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|| 2/2 [00:02<00:00,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.515          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       5/10         0G      1.149          1        640: 100%|| 3/3 [00:04<00:00,  1.57s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|| 2/2 [00:02<00:00,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.485          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       6/10         0G      1.113          1        640: 100%|| 3/3 [00:04<00:00,  1.57s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|| 2/2 [00:02<00:00,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.485          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       7/10         0G      1.058          1        640: 100%|| 3/3 [00:04<00:00,  1.58s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|| 2/2 [00:02<00:00,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.545          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       8/10         0G      1.002          1        640: 100%|| 3/3 [00:04<00:00,  1.57s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|| 2/2 [00:02<00:00,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.545          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       9/10         0G      1.055          1        640: 100%|| 3/3 [00:04<00:00,  1.58s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|| 2/2 [00:02<00:00,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.576          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      10/10         0G      1.071          1        640: 100%|| 3/3 [00:04<00:00,  1.58s/it]\n",
      "               classes   top1_acc   top5_acc: 100%|| 2/2 [00:02<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.545          1\n",
      "\n",
      "10 epochs completed in 0.020 hours.\n",
      "Optimizer stripped from /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2/train/weights/last.pt, 3.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer stripped from /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2/train/weights/best.pt, 3.0MB\n",
      "\n",
      "Validating /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.91  Python-3.9.18 torch-2.4.1 CPU (Apple M3 Pro)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 1,438,723 parameters, 0 gradients, 3.3 GFLOPs\n",
      "WARNING  Dataset 'split=val' not found, using 'split=test' instead.\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification/train... found 33 images in 3 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m None...\n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification/test... found 33 images in 3 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|| 2/2 [00:02<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.576          1\n",
      "Speed: 0.0ms preprocess, 59.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1m/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2/train\u001b[0m\n",
      "Results saved to \u001b[1m/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2/train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# step1\n",
    "from ultralytics import YOLO\n",
    "model_path = \"/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/cls/yolov8n-cls.pt\"\n",
    "data_path = \"/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/cifar10\"\n",
    "data_path2 = \"/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification\"\n",
    "# Load a model\n",
    "# model = YOLO(\"yolov8n.yaml\")  # build a new model from YAML\n",
    "# model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
    "# model = YOLO(\"yolov8n.yaml\").load(\"yolov8n.pt\")  # build from YAML and transfer weights\n",
    "model = YOLO(model=model_path)\n",
    "\n",
    "# Train the model\n",
    "results = model.train(\n",
    "    # data=\"coco8.yaml\",\n",
    "    data=data_path2,\n",
    "    epochs=10, \n",
    "    imgsz=640, \n",
    "    project=\"/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2\", \n",
    "    plots=True,\n",
    "    save_json=True,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x33a8bf310>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.7878787815570831\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.5757575631141663, 'metrics/accuracy_top5': 1.0, 'fitness': 0.7878787815570831}\n",
       "save_dir: PosixPath('/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2/train')\n",
       "speed: {'preprocess': 0.0007297053481593276, 'inference': 59.68475341796875, 'loss': 9.392247055516098e-05, 'postprocess': 2.8899221709280304e-05}\n",
       "task: 'classify'\n",
       "top1: 0.5757575631141663\n",
       "top5: 1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-02-10 12:51:55</td></tr>\n",
       "<tr><td>Running for: </td><td>00:01:04.43        </td></tr>\n",
       "<tr><td>Memory:      </td><td>13.6/18.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 10.000: None<br>Logical resource usage: 8.0/11 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">     bgr</th><th style=\"text-align: right;\">     box</th><th style=\"text-align: right;\">     cls</th><th style=\"text-align: right;\">  copy_paste</th><th style=\"text-align: right;\">  degrees</th><th style=\"text-align: right;\">  fliplr</th><th style=\"text-align: right;\">  flipud</th><th style=\"text-align: right;\">     hsv_h</th><th style=\"text-align: right;\">   hsv_s</th><th style=\"text-align: right;\">    hsv_v</th><th style=\"text-align: right;\">      lr0</th><th style=\"text-align: right;\">     lrf</th><th style=\"text-align: right;\">    mixup</th><th style=\"text-align: right;\">  momentum</th><th style=\"text-align: right;\">   mosaic</th><th style=\"text-align: right;\">  perspective</th><th style=\"text-align: right;\">   scale</th><th style=\"text-align: right;\">   shear</th><th style=\"text-align: right;\">  translate</th><th style=\"text-align: right;\">  warmup_epochs</th><th style=\"text-align: right;\">  warmup_momentum</th><th style=\"text-align: right;\">  weight_decay</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         metrics/accuracy_top\n",
       "1</th><th style=\"text-align: right;\">  metrics/accuracy_top\n",
       "5</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>_tune_9a117_00000</td><td>TERMINATED</td><td>127.0.0.1:24864</td><td style=\"text-align: right;\">0.768868</td><td style=\"text-align: right;\">0.165372</td><td style=\"text-align: right;\">0.572171</td><td style=\"text-align: right;\">    0.650022</td><td style=\"text-align: right;\">  34.2116</td><td style=\"text-align: right;\">0.221198</td><td style=\"text-align: right;\">0.371387</td><td style=\"text-align: right;\">0.0202699 </td><td style=\"text-align: right;\">0.419294</td><td style=\"text-align: right;\">0.177013 </td><td style=\"text-align: right;\">0.0185015</td><td style=\"text-align: right;\">0.82518 </td><td style=\"text-align: right;\">0.75113  </td><td style=\"text-align: right;\">  0.775427</td><td style=\"text-align: right;\">0.0822486</td><td style=\"text-align: right;\">  0.000369173</td><td style=\"text-align: right;\">0.885806</td><td style=\"text-align: right;\">6.66348 </td><td style=\"text-align: right;\">   0.72612 </td><td style=\"text-align: right;\">        1.10111</td><td style=\"text-align: right;\">         0.280066</td><td style=\"text-align: right;\">   0.00027212 </td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         35.5282</td><td style=\"text-align: right;\">0.666667</td><td style=\"text-align: right;\">1</td></tr>\n",
       "<tr><td>_tune_9a117_00001</td><td>TERMINATED</td><td>127.0.0.1:24935</td><td style=\"text-align: right;\">0.252875</td><td style=\"text-align: right;\">0.112981</td><td style=\"text-align: right;\">3.05259 </td><td style=\"text-align: right;\">    0.870016</td><td style=\"text-align: right;\">  35.9546</td><td style=\"text-align: right;\">0.575888</td><td style=\"text-align: right;\">0.970947</td><td style=\"text-align: right;\">0.00990212</td><td style=\"text-align: right;\">0.151891</td><td style=\"text-align: right;\">0.0194375</td><td style=\"text-align: right;\">0.0971949</td><td style=\"text-align: right;\">0.562111</td><td style=\"text-align: right;\">0.0868339</td><td style=\"text-align: right;\">  0.876908</td><td style=\"text-align: right;\">0.588404 </td><td style=\"text-align: right;\">  0.000424651</td><td style=\"text-align: right;\">0.267718</td><td style=\"text-align: right;\">0.693707</td><td style=\"text-align: right;\">   0.252933</td><td style=\"text-align: right;\">        0.87811</td><td style=\"text-align: right;\">         0.42941 </td><td style=\"text-align: right;\">   0.000152891</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         25.8614</td><td style=\"text-align: right;\">0.5     </td><td style=\"text-align: right;\">1</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24864)\u001b[0m New https://pypi.org/project/ultralytics/8.3.74 available  Update with 'pip install -U ultralytics'\n",
      "\u001b[36m(_tune pid=24864)\u001b[0m Ultralytics YOLOv8.2.91  Python-3.9.18 torch-2.4.1 CPU (Apple M3 Pro)\n",
      "\u001b[36m(_tune pid=24864)\u001b[0m \u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/cls/yolov8n-cls.pt, data=/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification-less, epochs=10, time=None, patience=100, batch=4, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=True, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01850147545018136, lrf=0.8251802488970318, momentum=0.775427139612969, weight_decay=0.0002721204521369558, warmup_epochs=1.101111050086656, warmup_momentum=0.28006644282153786, warmup_bias_lr=0.1, box=0.1653721145528975, cls=0.5721705557359866, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.020269923048393035, hsv_s=0.4192936362452884, hsv_v=0.1770126184773629, degrees=34.21155591973569, translate=0.7261197618707514, scale=0.8858055713409293, shear=6.6634751097433975, perspective=0.0003691732288327356, flipud=0.37138699981296575, fliplr=0.2211979608530359, bgr=0.7688683538705049, mosaic=0.08224861160570573, mixup=0.7511297356242912, copy_paste=0.6500216309594431, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2/train\n",
      "\u001b[36m(_tune pid=24864)\u001b[0m \u001b[34m\u001b[1mtrain:\u001b[0m /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification-less/train... found 15 images in 3 classes  \n",
      "\u001b[36m(_tune pid=24864)\u001b[0m \u001b[34m\u001b[1mval:\u001b[0m None...\n",
      "\u001b[36m(_tune pid=24864)\u001b[0m \u001b[34m\u001b[1mtest:\u001b[0m /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification-less/test... found 6 images in 3 classes  \n",
      "\u001b[36m(_tune pid=24864)\u001b[0m Overriding model.yaml nc=1000 with nc=3\n",
      "\u001b[36m(_tune pid=24864)\u001b[0m \n",
      "\u001b[36m(_tune pid=24864)\u001b[0m                    from  n    params  module                                       arguments                     \n",
      "\u001b[36m(_tune pid=24864)\u001b[0m   0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "\u001b[36m(_tune pid=24864)\u001b[0m   1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "\u001b[36m(_tune pid=24864)\u001b[0m   2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "\u001b[36m(_tune pid=24864)\u001b[0m   3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "\u001b[36m(_tune pid=24864)\u001b[0m   4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "\u001b[36m(_tune pid=24864)\u001b[0m   5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "\u001b[36m(_tune pid=24864)\u001b[0m   6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "\u001b[36m(_tune pid=24864)\u001b[0m   7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "\u001b[36m(_tune pid=24864)\u001b[0m   8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "\u001b[36m(_tune pid=24864)\u001b[0m   9                  -1  1    334083  ultralytics.nn.modules.head.Classify         [256, 3]                      \n",
      "\u001b[36m(_tune pid=24864)\u001b[0m YOLOv8n-cls summary: 99 layers, 1,442,131 parameters, 1,442,131 gradients, 3.4 GFLOPs\n",
      "\u001b[36m(_tune pid=24864)\u001b[0m Transferred 156/158 items from pretrained weights\n",
      "\u001b[36m(_tune pid=24864)\u001b[0m \u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2/train', view at http://localhost:6006/\n",
      "\u001b[36m(_tune pid=24864)\u001b[0m \u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification-less/train.cache\n",
      "\u001b[36m(_tune pid=24864)\u001b[0m \u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification-less/test.cache\n",
      "\u001b[36m(_tune pid=24864)\u001b[0m \u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01850147545018136' and 'momentum=0.775427139612969' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[36m(_tune pid=24864)\u001b[0m \u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0002721204521369558), 27 bias(decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification-less/train... 15 images, 0 corrupt: 100%|| 15/15 [00:00<00:00, 2126.14it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification-less/test... 6 images, 0 corrupt: 100%|| 6/6 [00:00<00:00, 6097.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24864)\u001b[0m \u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "\u001b[36m(_tune pid=24864)\u001b[0m Image sizes 640 train, 640 val\n",
      "\u001b[36m(_tune pid=24864)\u001b[0m Using 0 dataloader workers\n",
      "\u001b[36m(_tune pid=24864)\u001b[0m Logging results to \u001b[1m/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2/train\u001b[0m\n",
      "\u001b[36m(_tune pid=24864)\u001b[0m Starting training for 10 epochs...\n",
      "\u001b[36m(_tune pid=24864)\u001b[0m \n",
      "\u001b[36m(_tune pid=24864)\u001b[0m       Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]\n",
      "       1/10         0G      1.032          4        640:  25%|       | 1/4 [00:00<00:01,  2.16it/s]\n",
      "       1/10         0G      1.037          4        640:  50%|     | 2/4 [00:00<00:00,  2.15it/s]\n",
      "       1/10         0G      1.088          4        640:  75%|  | 3/4 [00:01<00:00,  2.33it/s]\n",
      "       1/10         0G      1.125          3        640: 100%|| 4/4 [00:01<00:00,  2.49it/s]\n",
      "               classes   top1_acc   top5_acc:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|| 1/1 [00:00<00:00,  4.69it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24864)\u001b[0m                    all          0          1\n",
      "\u001b[36m(_tune pid=24864)\u001b[0m \n",
      "\u001b[36m(_tune pid=24864)\u001b[0m       Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10         0G      1.046          4        640:  25%|       | 1/4 [00:00<00:01,  2.33it/s]\n",
      "       2/10         0G      1.079          4        640:  50%|     | 2/4 [00:00<00:00,  2.39it/s]\n",
      "       2/10         0G       1.11          4        640:  75%|  | 3/4 [00:01<00:00,  2.30it/s]\n",
      "       2/10         0G      1.105          3        640: 100%|| 4/4 [00:01<00:00,  2.38it/s]\n",
      "               classes   top1_acc   top5_acc:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|| 1/1 [00:00<00:00,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24864)\u001b[0m                    all          0          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24864)\u001b[0m \n",
      "\u001b[36m(_tune pid=24864)\u001b[0m       Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10         0G      1.009          4        640:  25%|       | 1/4 [00:00<00:01,  2.50it/s]\n",
      "       3/10         0G      1.049          4        640:  50%|     | 2/4 [00:00<00:00,  2.48it/s]\n",
      "       3/10         0G      1.056          4        640:  75%|  | 3/4 [00:01<00:00,  2.54it/s]\n",
      "       3/10         0G      1.045          3        640: 100%|| 4/4 [00:01<00:00,  2.63it/s]\n",
      "               classes   top1_acc   top5_acc:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|| 1/1 [00:00<00:00,  4.78it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24864)\u001b[0m                    all      0.167          1\n",
      "\u001b[36m(_tune pid=24864)\u001b[0m \n",
      "\u001b[36m(_tune pid=24864)\u001b[0m       Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10         0G      1.161          4        640:  25%|       | 1/4 [00:00<00:01,  2.30it/s]\n",
      "       4/10         0G        1.1          4        640:  50%|     | 2/4 [00:00<00:00,  2.38it/s]\n",
      "       4/10         0G      1.066          4        640:  75%|  | 3/4 [00:01<00:00,  2.45it/s]\n",
      "       4/10         0G      1.053          3        640: 100%|| 4/4 [00:01<00:00,  2.62it/s]\n",
      "               classes   top1_acc   top5_acc:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|| 1/1 [00:00<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24864)\u001b[0m                    all        0.5          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24864)\u001b[0m \n",
      "\u001b[36m(_tune pid=24864)\u001b[0m       Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10         0G     0.9024          4        640:  25%|       | 1/4 [00:00<00:01,  2.20it/s]\n",
      "       5/10         0G     0.9948          4        640:  50%|     | 2/4 [00:00<00:00,  2.33it/s]\n",
      "       5/10         0G      1.028          4        640:  75%|  | 3/4 [00:01<00:00,  2.30it/s]\n",
      "       5/10         0G      1.055          3        640: 100%|| 4/4 [00:01<00:00,  2.40it/s]\n",
      "               classes   top1_acc   top5_acc:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|| 1/1 [00:00<00:00,  5.27it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24864)\u001b[0m                    all        0.5          1\n",
      "\u001b[36m(_tune pid=24864)\u001b[0m \n",
      "\u001b[36m(_tune pid=24864)\u001b[0m       Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10         0G      1.014          4        640:  25%|       | 1/4 [00:00<00:01,  2.58it/s]\n",
      "       6/10         0G      1.034          4        640:  50%|     | 2/4 [00:00<00:00,  2.22it/s]\n",
      "       6/10         0G     0.9972          4        640:  75%|  | 3/4 [00:01<00:00,  2.31it/s]\n",
      "       6/10         0G       1.02          3        640: 100%|| 4/4 [00:01<00:00,  2.44it/s]\n",
      "               classes   top1_acc   top5_acc:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|| 1/1 [00:00<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24864)\u001b[0m                    all        0.5          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24864)\u001b[0m \n",
      "\u001b[36m(_tune pid=24864)\u001b[0m       Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10         0G      1.049          4        640:  25%|       | 1/4 [00:00<00:01,  2.28it/s]\n",
      "       7/10         0G      1.129          4        640:  50%|     | 2/4 [00:00<00:00,  2.36it/s]\n",
      "       7/10         0G      1.096          4        640:  75%|  | 3/4 [00:01<00:00,  2.52it/s]\n",
      "       7/10         0G      1.084          3        640: 100%|| 4/4 [00:01<00:00,  2.67it/s]\n",
      "               classes   top1_acc   top5_acc:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|| 1/1 [00:00<00:00,  5.67it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24864)\u001b[0m                    all        0.5          1\n",
      "\u001b[36m(_tune pid=24864)\u001b[0m \n",
      "\u001b[36m(_tune pid=24864)\u001b[0m       Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10         0G      1.032          4        640:  25%|       | 1/4 [00:00<00:01,  2.38it/s]\n",
      "       8/10         0G      1.035          4        640:  50%|     | 2/4 [00:00<00:00,  2.70it/s]\n",
      "       8/10         0G      1.057          4        640:  75%|  | 3/4 [00:01<00:00,  2.73it/s]\n",
      "       8/10         0G      1.067          3        640: 100%|| 4/4 [00:01<00:00,  2.77it/s]\n",
      "               classes   top1_acc   top5_acc:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|| 1/1 [00:00<00:00,  5.80it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24864)\u001b[0m                    all        0.5          1\n",
      "\u001b[36m(_tune pid=24864)\u001b[0m \n",
      "\u001b[36m(_tune pid=24864)\u001b[0m       Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10         0G     0.9721          4        640:  25%|       | 1/4 [00:00<00:01,  2.81it/s]\n",
      "       9/10         0G      0.974          4        640:  50%|     | 2/4 [00:00<00:00,  2.76it/s]\n",
      "       9/10         0G     0.9786          4        640:  75%|  | 3/4 [00:01<00:00,  2.75it/s]\n",
      "       9/10         0G     0.9931          3        640: 100%|| 4/4 [00:01<00:00,  2.84it/s]\n",
      "               classes   top1_acc   top5_acc:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|| 1/1 [00:00<00:00,  4.99it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24864)\u001b[0m                    all      0.667          1\n",
      "\u001b[36m(_tune pid=24864)\u001b[0m \n",
      "\u001b[36m(_tune pid=24864)\u001b[0m       Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10         0G      1.082          4        640:  25%|       | 1/4 [00:00<00:01,  2.35it/s]\n",
      "      10/10         0G       1.07          4        640:  50%|     | 2/4 [00:00<00:00,  2.35it/s]\n",
      "      10/10         0G      1.021          4        640:  75%|  | 3/4 [00:01<00:00,  2.35it/s]\n",
      "      10/10         0G      1.021          3        640: 100%|| 4/4 [00:01<00:00,  2.52it/s]\n",
      "               classes   top1_acc   top5_acc:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|| 1/1 [00:00<00:00,  5.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24864)\u001b[0m                    all      0.667          1\n",
      "\u001b[36m(_tune pid=24864)\u001b[0m \n",
      "\u001b[36m(_tune pid=24864)\u001b[0m 10 epochs completed in 0.005 hours.\n",
      "\u001b[36m(_tune pid=24864)\u001b[0m Optimizer stripped from /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2/train/weights/last.pt, 3.0MB\n",
      "\u001b[36m(_tune pid=24864)\u001b[0m Optimizer stripped from /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2/train/weights/best.pt, 3.0MB\n",
      "\u001b[36m(_tune pid=24864)\u001b[0m \n",
      "\u001b[36m(_tune pid=24864)\u001b[0m Validating /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2/train/weights/best.pt...\n",
      "\u001b[36m(_tune pid=24864)\u001b[0m Ultralytics YOLOv8.2.91  Python-3.9.18 torch-2.4.1 CPU (Apple M3 Pro)\n",
      "\u001b[36m(_tune pid=24864)\u001b[0m YOLOv8n-cls summary (fused): 73 layers, 1,438,723 parameters, 0 gradients, 3.3 GFLOPs\n",
      "\u001b[36m(_tune pid=24864)\u001b[0m WARNING  Dataset 'split=val' not found, using 'split=test' instead.\n",
      "\u001b[36m(_tune pid=24864)\u001b[0m \u001b[34m\u001b[1mtrain:\u001b[0m /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification-less/train... found 15 images in 3 classes  \n",
      "\u001b[36m(_tune pid=24864)\u001b[0m \u001b[34m\u001b[1mval:\u001b[0m None...\n",
      "\u001b[36m(_tune pid=24864)\u001b[0m \u001b[34m\u001b[1mtest:\u001b[0m /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification-less/test... found 6 images in 3 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|| 1/1 [00:00<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24864)\u001b[0m                    all      0.667          1\n",
      "\u001b[36m(_tune pid=24864)\u001b[0m Speed: 0.0ms preprocess, 23.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "\u001b[36m(_tune pid=24864)\u001b[0m Results saved to \u001b[1m/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2/train\u001b[0m\n",
      "\u001b[36m(_tune pid=24864)\u001b[0m Results saved to \u001b[1m/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24864)\u001b[0m /Users/treasures_y/Miniconda3/envs/automl/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[36m(_tune pid=24864)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24935)\u001b[0m New https://pypi.org/project/ultralytics/8.3.74 available  Update with 'pip install -U ultralytics'\n",
      "\u001b[36m(_tune pid=24935)\u001b[0m Ultralytics YOLOv8.2.91  Python-3.9.18 torch-2.4.1 CPU (Apple M3 Pro)\n",
      "\u001b[36m(_tune pid=24935)\u001b[0m \u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/cls/yolov8n-cls.pt, data=/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification-less, epochs=10, time=None, patience=100, batch=4, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=True, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.09719488164356783, lrf=0.5621105121891253, momentum=0.8769083178177588, weight_decay=0.00015289100974974346, warmup_epochs=0.8781104583095806, warmup_momentum=0.4294101433190956, warmup_bias_lr=0.1, box=0.11298069474513774, cls=3.052589723089571, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.009902120693930616, hsv_s=0.15189071299660004, hsv_v=0.019437537474316893, degrees=35.95461297415651, translate=0.25293323945893065, scale=0.2677176680037348, shear=0.6937068330304885, perspective=0.00042465137873064484, flipud=0.9709467935079632, fliplr=0.5758882988592979, bgr=0.25287468729376905, mosaic=0.5884035804659671, mixup=0.08683394310112946, copy_paste=0.8700164563624349, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2/train2\n",
      "\u001b[36m(_tune pid=24935)\u001b[0m \u001b[34m\u001b[1mtrain:\u001b[0m /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification-less/train... found 15 images in 3 classes  \n",
      "\u001b[36m(_tune pid=24935)\u001b[0m \u001b[34m\u001b[1mval:\u001b[0m None...\n",
      "\u001b[36m(_tune pid=24935)\u001b[0m \u001b[34m\u001b[1mtest:\u001b[0m /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification-less/test... found 6 images in 3 classes  \n",
      "\u001b[36m(_tune pid=24935)\u001b[0m Overriding model.yaml nc=1000 with nc=3\n",
      "\u001b[36m(_tune pid=24935)\u001b[0m \n",
      "\u001b[36m(_tune pid=24935)\u001b[0m                    from  n    params  module                                       arguments                     \n",
      "\u001b[36m(_tune pid=24935)\u001b[0m   0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "\u001b[36m(_tune pid=24935)\u001b[0m   1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "\u001b[36m(_tune pid=24935)\u001b[0m   2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "\u001b[36m(_tune pid=24935)\u001b[0m   3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "\u001b[36m(_tune pid=24935)\u001b[0m   4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "\u001b[36m(_tune pid=24935)\u001b[0m   5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "\u001b[36m(_tune pid=24935)\u001b[0m   6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "\u001b[36m(_tune pid=24935)\u001b[0m   7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "\u001b[36m(_tune pid=24935)\u001b[0m   8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "\u001b[36m(_tune pid=24935)\u001b[0m   9                  -1  1    334083  ultralytics.nn.modules.head.Classify         [256, 3]                      \n",
      "\u001b[36m(_tune pid=24935)\u001b[0m YOLOv8n-cls summary: 99 layers, 1,442,131 parameters, 1,442,131 gradients, 3.4 GFLOPs\n",
      "\u001b[36m(_tune pid=24935)\u001b[0m Transferred 156/158 items from pretrained weights\n",
      "\u001b[36m(_tune pid=24935)\u001b[0m \u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2/train2', view at http://localhost:6006/\n",
      "\u001b[36m(_tune pid=24935)\u001b[0m \u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.09719488164356783' and 'momentum=0.8769083178177588' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[36m(_tune pid=24935)\u001b[0m \u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.00015289100974974346), 27 bias(decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification-less/train... 15 images, 0 corrupt: 100%|| 15/15 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification-less/test... 6 images, 0 corrupt: 100%|| 6/6 [00:00<?, ?it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24935)\u001b[0m \u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "\u001b[36m(_tune pid=24935)\u001b[0m Image sizes 640 train, 640 val\n",
      "\u001b[36m(_tune pid=24935)\u001b[0m Using 0 dataloader workers\n",
      "\u001b[36m(_tune pid=24935)\u001b[0m Logging results to \u001b[1m/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2/train2\u001b[0m\n",
      "\u001b[36m(_tune pid=24935)\u001b[0m Starting training for 10 epochs...\n",
      "\u001b[36m(_tune pid=24935)\u001b[0m \n",
      "\u001b[36m(_tune pid=24935)\u001b[0m       Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10         0G      1.069          4        640:  25%|       | 1/4 [00:00<00:01,  2.36it/s]\n",
      "       1/10         0G      1.109          4        640:  50%|     | 2/4 [00:00<00:00,  2.16it/s]\n",
      "       1/10         0G      1.121          4        640:  75%|  | 3/4 [00:01<00:00,  2.29it/s]\n",
      "       1/10         0G       1.14          3        640: 100%|| 4/4 [00:01<00:00,  2.45it/s]\n",
      "               classes   top1_acc   top5_acc:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|| 1/1 [00:00<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24935)\u001b[0m                    all          0          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24935)\u001b[0m \n",
      "\u001b[36m(_tune pid=24935)\u001b[0m       Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10         0G      1.101          4        640:  25%|       | 1/4 [00:00<00:01,  2.69it/s]\n",
      "       2/10         0G      1.149          4        640:  50%|     | 2/4 [00:00<00:00,  2.57it/s]\n",
      "       2/10         0G      1.133          4        640:  75%|  | 3/4 [00:01<00:00,  2.55it/s]\n",
      "       2/10         0G      1.128          3        640: 100%|| 4/4 [00:01<00:00,  2.67it/s]\n",
      "               classes   top1_acc   top5_acc:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|| 1/1 [00:00<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24935)\u001b[0m                    all          0          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24935)\u001b[0m \n",
      "\u001b[36m(_tune pid=24935)\u001b[0m       Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10         0G      1.032          4        640:  25%|       | 1/4 [00:00<00:01,  2.15it/s]\n",
      "       3/10         0G      1.109          4        640:  50%|     | 2/4 [00:00<00:00,  2.14it/s]\n",
      "       3/10         0G      1.105          4        640:  75%|  | 3/4 [00:01<00:00,  2.17it/s]\n",
      "       3/10         0G      1.117          3        640: 100%|| 4/4 [00:01<00:00,  2.34it/s]\n",
      "               classes   top1_acc   top5_acc:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|| 1/1 [00:00<00:00,  5.21it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24935)\u001b[0m                    all          0          1\n",
      "\u001b[36m(_tune pid=24935)\u001b[0m \n",
      "\u001b[36m(_tune pid=24935)\u001b[0m       Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10         0G      1.245          4        640:  25%|       | 1/4 [00:00<00:01,  2.40it/s]\n",
      "       4/10         0G      1.216          4        640:  50%|     | 2/4 [00:00<00:00,  2.52it/s]\n",
      "       4/10         0G      1.131          4        640:  75%|  | 3/4 [00:01<00:00,  2.45it/s]\n",
      "       4/10         0G      1.122          3        640: 100%|| 4/4 [00:01<00:00,  2.50it/s]\n",
      "               classes   top1_acc   top5_acc:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|| 1/1 [00:00<00:00,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24935)\u001b[0m                    all        0.5          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24935)\u001b[0m \n",
      "\u001b[36m(_tune pid=24935)\u001b[0m       Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10         0G      1.052          4        640:  25%|       | 1/4 [00:00<00:01,  2.32it/s]\n",
      "       5/10         0G      1.032          4        640:  50%|     | 2/4 [00:00<00:00,  2.32it/s]\n",
      "       5/10         0G      1.049          4        640:  75%|  | 3/4 [00:01<00:00,  2.40it/s]\n",
      "       5/10         0G      1.043          3        640: 100%|| 4/4 [00:01<00:00,  2.49it/s]\n",
      "               classes   top1_acc   top5_acc:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|| 1/1 [00:00<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24935)\u001b[0m                    all        0.5          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24935)\u001b[0m \n",
      "\u001b[36m(_tune pid=24935)\u001b[0m       Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10         0G      1.124          4        640:  25%|       | 1/4 [00:00<00:01,  2.34it/s]\n",
      "       6/10         0G      1.063          4        640:  50%|     | 2/4 [00:00<00:00,  2.36it/s]\n",
      "       6/10         0G      1.085          4        640:  75%|  | 3/4 [00:01<00:00,  2.41it/s]\n",
      "       6/10         0G      1.097          3        640: 100%|| 4/4 [00:01<00:00,  2.54it/s]\n",
      "               classes   top1_acc   top5_acc:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|| 1/1 [00:00<00:00,  5.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24935)\u001b[0m                    all        0.5          1\n",
      "\u001b[36m(_tune pid=24935)\u001b[0m \n",
      "\u001b[36m(_tune pid=24935)\u001b[0m       Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]\n",
      "       7/10         0G      1.053          4        640:  25%|       | 1/4 [00:00<00:01,  2.68it/s]\n",
      "       7/10         0G      1.046          4        640:  50%|     | 2/4 [00:00<00:00,  2.62it/s]\n",
      "       7/10         0G      1.042          4        640:  75%|  | 3/4 [00:01<00:00,  2.70it/s]\n",
      "       7/10         0G      1.051          3        640: 100%|| 4/4 [00:01<00:00,  2.79it/s]\n",
      "               classes   top1_acc   top5_acc:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|| 1/1 [00:00<00:00,  5.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24935)\u001b[0m                    all        0.5          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24935)\u001b[0m \n",
      "\u001b[36m(_tune pid=24935)\u001b[0m       Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10         0G      1.045          4        640:  25%|       | 1/4 [00:00<00:01,  2.25it/s]\n",
      "       8/10         0G      1.048          4        640:  50%|     | 2/4 [00:00<00:00,  2.56it/s]\n",
      "       8/10         0G      1.051          4        640:  75%|  | 3/4 [00:01<00:00,  2.65it/s]\n",
      "       8/10         0G      1.059          3        640: 100%|| 4/4 [00:01<00:00,  2.78it/s]\n",
      "               classes   top1_acc   top5_acc:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|| 1/1 [00:00<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24935)\u001b[0m                    all        0.5          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24935)\u001b[0m \n",
      "\u001b[36m(_tune pid=24935)\u001b[0m       Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10         0G     0.9616          4        640:  25%|       | 1/4 [00:00<00:01,  2.33it/s]\n",
      "       9/10         0G      1.007          4        640:  50%|     | 2/4 [00:00<00:00,  2.49it/s]\n",
      "       9/10         0G     0.9958          4        640:  75%|  | 3/4 [00:01<00:00,  2.50it/s]\n",
      "       9/10         0G      1.025          3        640: 100%|| 4/4 [00:01<00:00,  2.62it/s]\n",
      "               classes   top1_acc   top5_acc:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|| 1/1 [00:00<00:00,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24935)\u001b[0m                    all        0.5          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24935)\u001b[0m \n",
      "\u001b[36m(_tune pid=24935)\u001b[0m       Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10         0G      1.147          4        640:  25%|       | 1/4 [00:00<00:01,  2.47it/s]\n",
      "      10/10         0G        1.1          4        640:  50%|     | 2/4 [00:00<00:00,  2.43it/s]\n",
      "      10/10         0G      1.029          4        640:  75%|  | 3/4 [00:01<00:00,  2.51it/s]\n",
      "      10/10         0G      1.006          3        640: 100%|| 4/4 [00:01<00:00,  2.64it/s]\n",
      "               classes   top1_acc   top5_acc:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|| 1/1 [00:00<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24935)\u001b[0m                    all        0.5          1\n",
      "\u001b[36m(_tune pid=24935)\u001b[0m \n",
      "\u001b[36m(_tune pid=24935)\u001b[0m 10 epochs completed in 0.005 hours.\n",
      "\u001b[36m(_tune pid=24935)\u001b[0m Optimizer stripped from /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2/train2/weights/last.pt, 3.0MB\n",
      "\u001b[36m(_tune pid=24935)\u001b[0m Optimizer stripped from /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2/train2/weights/best.pt, 3.0MB\n",
      "\u001b[36m(_tune pid=24935)\u001b[0m \n",
      "\u001b[36m(_tune pid=24935)\u001b[0m Validating /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2/train2/weights/best.pt...\n",
      "\u001b[36m(_tune pid=24935)\u001b[0m Ultralytics YOLOv8.2.91  Python-3.9.18 torch-2.4.1 CPU (Apple M3 Pro)\n",
      "\u001b[36m(_tune pid=24935)\u001b[0m YOLOv8n-cls summary (fused): 73 layers, 1,438,723 parameters, 0 gradients, 3.3 GFLOPs\n",
      "\u001b[36m(_tune pid=24935)\u001b[0m WARNING  Dataset 'split=val' not found, using 'split=test' instead.\n",
      "\u001b[36m(_tune pid=24935)\u001b[0m \u001b[34m\u001b[1mtrain:\u001b[0m /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification-less/train... found 15 images in 3 classes  \n",
      "\u001b[36m(_tune pid=24935)\u001b[0m \u001b[34m\u001b[1mval:\u001b[0m None...\n",
      "\u001b[36m(_tune pid=24935)\u001b[0m \u001b[34m\u001b[1mtest:\u001b[0m /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification-less/test... found 6 images in 3 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|| 1/1 [00:00<00:00,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=24935)\u001b[0m                    all        0.5          1\n",
      "\u001b[36m(_tune pid=24935)\u001b[0m Speed: 0.0ms preprocess, 23.6ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "\u001b[36m(_tune pid=24935)\u001b[0m Results saved to \u001b[1m/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2/train2\u001b[0m\n",
      "\u001b[36m(_tune pid=24935)\u001b[0m Results saved to \u001b[1m/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2/train2\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 12:51:55,356\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/runs/detect/tune/_tune_2025-02-10_12-50-50' in 0.0033s.\n",
      "2025-02-10 12:51:55,359\tINFO tune.py:1041 -- Total run time: 64.45 seconds (64.42 seconds for the tuning loop).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResultGrid<[\n",
       "  Result(\n",
       "    metrics={'metrics/accuracy_top1': 0.6666666865348816, 'metrics/accuracy_top5': 1.0, 'fitness': 0.8333333432674408},\n",
       "    path='/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/runs/detect/tune/_tune_2025-02-10_12-50-50/_tune_9a117_00000_0_bgr=0.7689,box=0.1654,cls=0.5722,copy_paste=0.6500,degrees=34.2116,fliplr=0.2212,flipud=0.3714,hsv_h=0.0203,hs_2025-02-10_12-50-50',\n",
       "    filesystem='local',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={'metrics/accuracy_top1': 0.5, 'metrics/accuracy_top5': 1.0, 'fitness': 0.75},\n",
       "    path='/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/runs/detect/tune/_tune_2025-02-10_12-50-50/_tune_9a117_00001_1_bgr=0.2529,box=0.1130,cls=3.0526,copy_paste=0.8700,degrees=35.9546,fliplr=0.5759,flipud=0.9709,hsv_h=0.0099,hs_2025-02-10_12-50-50',\n",
       "    filesystem='local',\n",
       "    checkpoint=None\n",
       "  )\n",
       "]>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step1\n",
    "from ultralytics import YOLO\n",
    "model_path = \"/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/cls/yolov8n-cls.pt\"\n",
    "data_path = \"/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/cifar10\"\n",
    "data_path2 = \"/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification-less\"\n",
    "# Load a model\n",
    "# model = YOLO(\"yolov8n.yaml\")  # build a new model from YAML\n",
    "# model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
    "# model = YOLO(\"yolov8n.yaml\").load(\"yolov8n.pt\")  # build from YAML and transfer weights\n",
    "model = YOLO(model=model_path)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "results = model.tune(\n",
    "    # data=\"coco8.yaml\",\n",
    "    use_ray=True,\n",
    "    data=data_path2,\n",
    "    iterations=2,\n",
    "    batch=4,\n",
    "    epochs=10, \n",
    "    imgsz=640, \n",
    "    project=\"/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2\",\n",
    "    plots=True,\n",
    "    save_json=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(\n",
       "  metrics={'metrics/accuracy_top1': 0.6666666865348816, 'metrics/accuracy_top5': 1.0, 'fitness': 0.8333333432674408},\n",
       "  path='/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/runs/detect/tune/_tune_2025-02-10_12-50-50/_tune_9a117_00000_0_bgr=0.7689,box=0.1654,cls=0.5722,copy_paste=0.6500,degrees=34.2116,fliplr=0.2212,flipud=0.3714,hsv_h=0.0203,hs_2025-02-10_12-50-50',\n",
       "  filesystem='local',\n",
       "  checkpoint=None\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.get_best_result(metric=\"metrics/accuracy_top1\", mode=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metrics/accuracy_top1': 0.5757575631141663,\n",
       " 'metrics/accuracy_top5': 1.0,\n",
       " 'fitness': 0.7878787815570831,\n",
       " 'timestamp': 1727057730,\n",
       " 'checkpoint_dir_name': None,\n",
       " 'done': True,\n",
       " 'training_iteration': 12,\n",
       " 'trial_id': '83e4f_00000',\n",
       " 'date': '2024-09-23_10-15-30',\n",
       " 'time_this_iter_s': 0.33268213272094727,\n",
       " 'time_total_s': 81.27842378616333,\n",
       " 'pid': 3575,\n",
       " 'hostname': 'MacBook-Pro-2.local',\n",
       " 'node_ip': '127.0.0.1',\n",
       " 'config': {'lr0': 0.07805511233688268,\n",
       "  'lrf': 0.1270916816102439,\n",
       "  'momentum': 0.843169988104459,\n",
       "  'weight_decay': 0.0001433532874090464,\n",
       "  'warmup_epochs': 4.7233445852479194,\n",
       "  'warmup_momentum': 0.49575590566256805,\n",
       "  'box': 0.09463914919829426,\n",
       "  'cls': 1.2053113259975823,\n",
       "  'hsv_h': 0.07742336894342167,\n",
       "  'hsv_s': 0.4105352989948937,\n",
       "  'hsv_v': 0.5115905539817837,\n",
       "  'degrees': 0.8455410196359814,\n",
       "  'translate': 0.5558719473682894,\n",
       "  'scale': 0.5508861504501793,\n",
       "  'shear': 6.169339968747569,\n",
       "  'perspective': 0.0009437480785146242,\n",
       "  'flipud': 0.6818202991034834,\n",
       "  'fliplr': 0.359507900573786,\n",
       "  'bgr': 0.43703195379934145,\n",
       "  'mosaic': 0.6976311959272649,\n",
       "  'mixup': 0.06022547162926983,\n",
       "  'copy_paste': 0.6667667154456677,\n",
       "  'data': '/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification',\n",
       "  'epochs': 10,\n",
       "  'imgsz': 640,\n",
       "  'project': '/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2',\n",
       "  'plots': True,\n",
       "  'save_json': True,\n",
       "  'verbose': True},\n",
       " 'time_since_restore': 81.27842378616333,\n",
       " 'iterations_since_restore': 12,\n",
       " 'experiment_tag': '0_bgr=0.4370,box=0.0946,cls=1.2053,copy_paste=0.6668,degrees=0.8455,fliplr=0.3595,flipud=0.6818,hsv_h=0.0774,hsv_s=0.4105,hsv_v=0.5116,lr0=0.0781,lrf=0.1271,mixup=0.0602,momentum=0.8432,mosaic=0.6976,perspective=0.0009,scale=0.5509,shear=6.1693,translate=0.5559,warmup_epochs=4.7233,warmup_momentum=0.4958,weight_decay=0.0001'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.get_best_result(metric=\"metrics/accuracy_top1\", mode=\"max\").metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x370dc3e20>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results._experiment_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'83e4f_00000': {'metrics/accuracy_top1': 0.5757575631141663,\n",
       "  'metrics/accuracy_top5': 1.0,\n",
       "  'fitness': 0.7878787815570831,\n",
       "  'timestamp': 1727057730,\n",
       "  'checkpoint_dir_name': None,\n",
       "  'done': True,\n",
       "  'training_iteration': 12,\n",
       "  'trial_id': '83e4f_00000',\n",
       "  'date': '2024-09-23_10-15-30',\n",
       "  'time_this_iter_s': 0.33268213272094727,\n",
       "  'time_total_s': 81.27842378616333,\n",
       "  'pid': 3575,\n",
       "  'hostname': 'MacBook-Pro-2.local',\n",
       "  'node_ip': '127.0.0.1',\n",
       "  'config': {'lr0': 0.07805511233688268,\n",
       "   'lrf': 0.1270916816102439,\n",
       "   'momentum': 0.843169988104459,\n",
       "   'weight_decay': 0.0001433532874090464,\n",
       "   'warmup_epochs': 4.7233445852479194,\n",
       "   'warmup_momentum': 0.49575590566256805,\n",
       "   'box': 0.09463914919829426,\n",
       "   'cls': 1.2053113259975823,\n",
       "   'hsv_h': 0.07742336894342167,\n",
       "   'hsv_s': 0.4105352989948937,\n",
       "   'hsv_v': 0.5115905539817837,\n",
       "   'degrees': 0.8455410196359814,\n",
       "   'translate': 0.5558719473682894,\n",
       "   'scale': 0.5508861504501793,\n",
       "   'shear': 6.169339968747569,\n",
       "   'perspective': 0.0009437480785146242,\n",
       "   'flipud': 0.6818202991034834,\n",
       "   'fliplr': 0.359507900573786,\n",
       "   'bgr': 0.43703195379934145,\n",
       "   'mosaic': 0.6976311959272649,\n",
       "   'mixup': 0.06022547162926983,\n",
       "   'copy_paste': 0.6667667154456677,\n",
       "   'data': '/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification',\n",
       "   'epochs': 10,\n",
       "   'imgsz': 640,\n",
       "   'project': '/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2',\n",
       "   'plots': True,\n",
       "   'save_json': True,\n",
       "   'verbose': True},\n",
       "  'time_since_restore': 81.27842378616333,\n",
       "  'iterations_since_restore': 12,\n",
       "  'experiment_tag': '0_bgr=0.4370,box=0.0946,cls=1.2053,copy_paste=0.6668,degrees=0.8455,fliplr=0.3595,flipud=0.6818,hsv_h=0.0774,hsv_s=0.4105,hsv_v=0.5116,lr0=0.0781,lrf=0.1271,mixup=0.0602,momentum=0.8432,mosaic=0.6976,perspective=0.0009,scale=0.5509,shear=6.1693,translate=0.5559,warmup_epochs=4.7233,warmup_momentum=0.4958,weight_decay=0.0001'},\n",
       " '83e4f_00001': {'metrics/accuracy_top1': 0.5757575631141663,\n",
       "  'metrics/accuracy_top5': 1.0,\n",
       "  'fitness': 0.7878787815570831,\n",
       "  'timestamp': 1727057815,\n",
       "  'checkpoint_dir_name': None,\n",
       "  'done': True,\n",
       "  'training_iteration': 12,\n",
       "  'trial_id': '83e4f_00001',\n",
       "  'date': '2024-09-23_10-16-55',\n",
       "  'time_this_iter_s': 0.3234848976135254,\n",
       "  'time_total_s': 82.58119988441467,\n",
       "  'pid': 3714,\n",
       "  'hostname': 'MacBook-Pro-2.local',\n",
       "  'node_ip': '127.0.0.1',\n",
       "  'config': {'lr0': 0.021046152281773353,\n",
       "   'lrf': 0.1376370346783048,\n",
       "   'momentum': 0.7198627733511899,\n",
       "   'weight_decay': 0.0003637107709426226,\n",
       "   'warmup_epochs': 2.8509838520893984,\n",
       "   'warmup_momentum': 0.4166714377892043,\n",
       "   'box': 0.19790729085066072,\n",
       "   'cls': 0.5877702808425067,\n",
       "   'hsv_h': 0.020887675609483472,\n",
       "   'hsv_s': 0.14517856609649663,\n",
       "   'hsv_v': 0.5877974929188586,\n",
       "   'degrees': 11.398122114290196,\n",
       "   'translate': 0.4196796955706757,\n",
       "   'scale': 0.21998303280144246,\n",
       "   'shear': 1.5896958364551972,\n",
       "   'perspective': 0.00011037514116430514,\n",
       "   'flipud': 0.6563295894652734,\n",
       "   'fliplr': 0.1381829513486138,\n",
       "   'bgr': 0.1965823616800535,\n",
       "   'mosaic': 0.3687251706609641,\n",
       "   'mixup': 0.8209932298479351,\n",
       "   'copy_paste': 0.09710127579306127,\n",
       "   'data': '/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification',\n",
       "   'epochs': 10,\n",
       "   'imgsz': 640,\n",
       "   'project': '/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2',\n",
       "   'plots': True,\n",
       "   'save_json': True,\n",
       "   'verbose': True},\n",
       "  'time_since_restore': 82.58119988441467,\n",
       "  'iterations_since_restore': 12,\n",
       "  'experiment_tag': '1_bgr=0.1966,box=0.1979,cls=0.5878,copy_paste=0.0971,degrees=11.3981,fliplr=0.1382,flipud=0.6563,hsv_h=0.0209,hsv_s=0.1452,hsv_v=0.5878,lr0=0.0210,lrf=0.1376,mixup=0.8210,momentum=0.7199,mosaic=0.3687,perspective=0.0001,scale=0.2200,shear=1.5897,translate=0.4197,warmup_epochs=2.8510,warmup_momentum=0.4167,weight_decay=0.0004'}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results._experiment_analysis.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metrics/accuracy_top1': {'max': 0.57576,\n",
       "  'min': 0.27273,\n",
       "  'avg': 0.4797979271856943,\n",
       "  'last': 0.5757575631141663,\n",
       "  'last-5-avg': 0.5636350252456666,\n",
       "  'last-10-avg': 0.5181815126228332},\n",
       " 'metrics/accuracy_top5': {'max': 1.0,\n",
       "  'min': 1.0,\n",
       "  'avg': 1.0,\n",
       "  'last': 1.0,\n",
       "  'last-5-avg': 1.0,\n",
       "  'last-10-avg': 1.0},\n",
       " 'val/loss': {'max': 1.149,\n",
       "  'min': 1.05169,\n",
       "  'avg': 1.0845169999999997,\n",
       "  'last': 1.05233,\n",
       "  'last-5-avg': 1.081578,\n",
       "  'last-10-avg': 1.084517},\n",
       " 'epoch': {'max': 9,\n",
       "  'min': 0,\n",
       "  'avg': 4.909090909090909,\n",
       "  'last': 9,\n",
       "  'last-5-avg': 7.8,\n",
       "  'last-10-avg': 5.4},\n",
       " 'done': {'max': False,\n",
       "  'min': False,\n",
       "  'avg': 0.0,\n",
       "  'last': False,\n",
       "  'last-5-avg': 0.0,\n",
       "  'last-10-avg': 0.0},\n",
       " 'training_iteration': {'max': 12,\n",
       "  'min': 1,\n",
       "  'avg': 6.5,\n",
       "  'last': 12,\n",
       "  'last-5-avg': 10.0,\n",
       "  'last-10-avg': 7.5},\n",
       " 'time_this_iter_s': {'max': 13.324280023574829,\n",
       "  'min': 0.33268213272094727,\n",
       "  'avg': 6.773201982180277,\n",
       "  'last': 0.33268213272094727,\n",
       "  'last-5-avg': 5.002428197860718,\n",
       "  'last-10-avg': 6.053290796279907},\n",
       " 'time_total_s': {'max': 81.27842378616333,\n",
       "  'min': 13.324280023574829,\n",
       "  'avg': 51.506813168525696,\n",
       "  'last': 81.27842378616333,\n",
       "  'last-5-avg': 74.71489915847778,\n",
       "  'last-10-avg': 58.40119621753693},\n",
       " 'time_since_restore': {'max': 81.27842378616333,\n",
       "  'min': 13.324280023574829,\n",
       "  'avg': 51.506813168525696,\n",
       "  'last': 81.27842378616333,\n",
       "  'last-5-avg': 74.71489915847778,\n",
       "  'last-10-avg': 58.40119621753693},\n",
       " 'iterations_since_restore': {'max': 12,\n",
       "  'min': 1,\n",
       "  'avg': 6.5,\n",
       "  'last': 12,\n",
       "  'last-5-avg': 10.0,\n",
       "  'last-10-avg': 7.5},\n",
       " 'fitness': {'max': 0.7878787815570831,\n",
       "  'min': 0.7878787815570831,\n",
       "  'avg': 0.7878787815570831,\n",
       "  'last': 0.7878787815570831,\n",
       "  'last-5-avg': 0.7878787815570831,\n",
       "  'last-10-avg': 0.7878787815570831}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results._experiment_analysis.get_best_trial(metric=\"metrics/accuracy_top1\", mode=\"max\").run_metadata.metric_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('{\\n  \"stub\": false,\\n  \"trainable_name\": \"_tune\",\\n  \"trial_id\": \"83e4f_00000\",\\n  \"storage\": {\\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n    \"value\": \"80059570030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c195f74756e655f323032342d30392d32335f31302d31342d3038948c0e747269616c5f6469725f6e616d65948c965f74756e655f38336534665f30303030305f305f6267723d302e343337302c626f783d302e303934362c636c733d312e323035332c636f70795f70617374653d302e363636382c646567726565733d302e383435352c666c69706c723d302e333539352c666c697075643d302e363831382c6873765f683d302e303737342c6873765f323032342d30392d32335f31302d31342d3038948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c512f55736572732f7472656173757265735f792f446f63756d656e74732f636f64652f48472f4175746f4d4c2f707974686f6e2f6175746f6d6c2f74657374732f72756e732f6465746563742f74756e653294681768008c115f46696c6573797374656d53796e6365729493942981947d94286819681f68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30392d32335f31302d31342d30389475622e\"\\n  },\\n  \"config\": {\\n    \"lr0\": 0.07805511233688268,\\n    \"lrf\": 0.1270916816102439,\\n    \"momentum\": 0.843169988104459,\\n    \"weight_decay\": 0.0001433532874090464,\\n    \"warmup_epochs\": 4.7233445852479194,\\n    \"warmup_momentum\": 0.49575590566256805,\\n    \"box\": 0.09463914919829426,\\n    \"cls\": 1.2053113259975823,\\n    \"hsv_h\": 0.07742336894342167,\\n    \"hsv_s\": 0.4105352989948937,\\n    \"hsv_v\": 0.5115905539817837,\\n    \"degrees\": 0.8455410196359814,\\n    \"translate\": 0.5558719473682894,\\n    \"scale\": 0.5508861504501793,\\n    \"shear\": 6.169339968747569,\\n    \"perspective\": 0.0009437480785146242,\\n    \"flipud\": 0.6818202991034834,\\n    \"fliplr\": 0.359507900573786,\\n    \"bgr\": 0.43703195379934145,\\n    \"mosaic\": 0.6976311959272649,\\n    \"mixup\": 0.06022547162926983,\\n    \"copy_paste\": 0.6667667154456677,\\n    \"data\": \"/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification\"\\n  },\\n  \"_Trial__unresolved_config\": {\\n    \"lr0\": 0.07805511233688268,\\n    \"lrf\": 0.1270916816102439,\\n    \"momentum\": 0.843169988104459,\\n    \"weight_decay\": 0.0001433532874090464,\\n    \"warmup_epochs\": 4.7233445852479194,\\n    \"warmup_momentum\": 0.49575590566256805,\\n    \"box\": 0.09463914919829426,\\n    \"cls\": 1.2053113259975823,\\n    \"hsv_h\": 0.07742336894342167,\\n    \"hsv_s\": 0.4105352989948937,\\n    \"hsv_v\": 0.5115905539817837,\\n    \"degrees\": 0.8455410196359814,\\n    \"translate\": 0.5558719473682894,\\n    \"scale\": 0.5508861504501793,\\n    \"shear\": 6.169339968747569,\\n    \"perspective\": 0.0009437480785146242,\\n    \"flipud\": 0.6818202991034834,\\n    \"fliplr\": 0.359507900573786,\\n    \"bgr\": 0.43703195379934145,\\n    \"mosaic\": 0.6976311959272649,\\n    \"mixup\": 0.06022547162926983,\\n    \"copy_paste\": 0.6667667154456677,\\n    \"data\": \"/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification\"\\n  },\\n  \"evaluated_params\": {\\n    \"lr0\": 0.07805511233688268,\\n    \"lrf\": 0.1270916816102439,\\n    \"momentum\": 0.843169988104459,\\n    \"weight_decay\": 0.0001433532874090464,\\n    \"warmup_epochs\": 4.7233445852479194,\\n    \"warmup_momentum\": 0.49575590566256805,\\n    \"box\": 0.09463914919829426,\\n    \"cls\": 1.2053113259975823,\\n    \"hsv_h\": 0.07742336894342167,\\n    \"hsv_s\": 0.4105352989948937,\\n    \"hsv_v\": 0.5115905539817837,\\n    \"degrees\": 0.8455410196359814,\\n    \"translate\": 0.5558719473682894,\\n    \"scale\": 0.5508861504501793,\\n    \"shear\": 6.169339968747569,\\n    \"perspective\": 0.0009437480785146242,\\n    \"flipud\": 0.6818202991034834,\\n    \"fliplr\": 0.359507900573786,\\n    \"bgr\": 0.43703195379934145,\\n    \"mosaic\": 0.6976311959272649,\\n    \"mixup\": 0.06022547162926983,\\n    \"copy_paste\": 0.6667667154456677\\n  },\\n  \"experiment_tag\": \"0_bgr=0.4370,box=0.0946,cls=1.2053,copy_paste=0.6668,degrees=0.8455,fliplr=0.3595,flipud=0.6818,hsv_h=0.0774,hsv_s=0.4105,hsv_v=0.5116,lr0=0.0781,lrf=0.1271,mixup=0.0602,momentum=0.8432,mosaic=0.6976,perspective=0.0009,scale=0.5509,shear=6.1693,translate=0.5559,warmup_epochs=4.7233,warmup_momentum=0.4958,weight_decay=0.0001\",\\n  \"stopping_criterion\": {},\\n  \"_setup_default_resource\": true,\\n  \"_default_placement_group_factory\": \"80054e2e\",\\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c034350559447402000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\\n  \"log_to_file\": [\\n    null,\\n    null\\n  ],\\n  \"max_failures\": 0,\\n  \"_default_result_or_future\": null,\\n  \"export_formats\": [],\\n  \"status\": \"TERMINATED\",\\n  \"relative_logdir\": \"_tune_83e4f_00000_0_bgr=0.4370,box=0.0946,cls=1.2053,copy_paste=0.6668,degrees=0.8455,fliplr=0.3595,flipud=0.6818,hsv_h=0.0774,hsv_2024-09-23_10-14-08\",\\n  \"trial_name_creator\": null,\\n  \"trial_dirname_creator\": null,\\n  \"custom_trial_name\": null,\\n  \"custom_dirname\": null,\\n  \"restore_path\": null,\\n  \"_restore_checkpoint_result\": null,\\n  \"_state_json\": null,\\n  \"results\": \"80054e2e\",\\n  \"extra_arg\": \"80054e2e\",\\n  \"_resources\": \"80054e2e\"\\n}',\n",
       " '{\\n  \"start_time\": 1727057649.292568,\\n  \"num_failures\": 0,\\n  \"num_failures_after_restore\": 0,\\n  \"error_filename\": null,\\n  \"pickled_error_filename\": null,\\n  \"last_result\": {\\n    \"metrics/accuracy_top1\": 0.5757575631141663,\\n    \"metrics/accuracy_top5\": 1.0,\\n    \"fitness\": 0.7878787815570831,\\n    \"timestamp\": 1727057730,\\n    \"checkpoint_dir_name\": null,\\n    \"done\": true,\\n    \"training_iteration\": 12,\\n    \"trial_id\": \"83e4f_00000\",\\n    \"date\": \"2024-09-23_10-15-30\",\\n    \"time_this_iter_s\": 0.33268213272094727,\\n    \"time_total_s\": 81.27842378616333,\\n    \"pid\": 3575,\\n    \"hostname\": \"MacBook-Pro-2.local\",\\n    \"node_ip\": \"127.0.0.1\",\\n    \"config\": {\\n      \"lr0\": 0.07805511233688268,\\n      \"lrf\": 0.1270916816102439,\\n      \"momentum\": 0.843169988104459,\\n      \"weight_decay\": 0.0001433532874090464,\\n      \"warmup_epochs\": 4.7233445852479194,\\n      \"warmup_momentum\": 0.49575590566256805,\\n      \"box\": 0.09463914919829426,\\n      \"cls\": 1.2053113259975823,\\n      \"hsv_h\": 0.07742336894342167,\\n      \"hsv_s\": 0.4105352989948937,\\n      \"hsv_v\": 0.5115905539817837,\\n      \"degrees\": 0.8455410196359814,\\n      \"translate\": 0.5558719473682894,\\n      \"scale\": 0.5508861504501793,\\n      \"shear\": 6.169339968747569,\\n      \"perspective\": 0.0009437480785146242,\\n      \"flipud\": 0.6818202991034834,\\n      \"fliplr\": 0.359507900573786,\\n      \"bgr\": 0.43703195379934145,\\n      \"mosaic\": 0.6976311959272649,\\n      \"mixup\": 0.06022547162926983,\\n      \"copy_paste\": 0.6667667154456677,\\n      \"data\": \"/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification\",\\n      \"epochs\": 10,\\n      \"imgsz\": 640,\\n      \"project\": \"/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2\",\\n      \"plots\": true,\\n      \"save_json\": true,\\n      \"verbose\": true\\n    },\\n    \"time_since_restore\": 81.27842378616333,\\n    \"iterations_since_restore\": 12,\\n    \"experiment_tag\": \"0_bgr=0.4370,box=0.0946,cls=1.2053,copy_paste=0.6668,degrees=0.8455,fliplr=0.3595,flipud=0.6818,hsv_h=0.0774,hsv_s=0.4105,hsv_v=0.5116,lr0=0.0781,lrf=0.1271,mixup=0.0602,momentum=0.8432,mosaic=0.6976,perspective=0.0009,scale=0.5509,shear=6.1693,translate=0.5559,warmup_epochs=4.7233,warmup_momentum=0.4958,weight_decay=0.0001\"\\n  },\\n  \"last_result_time\": 1727057730.593405,\\n  \"metric_analysis\": {\\n    \"metrics/accuracy_top1\": {\\n      \"max\": 0.57576,\\n      \"min\": 0.27273,\\n      \"avg\": 0.4797979271856943,\\n      \"last\": 0.5757575631141663,\\n      \"last-5-avg\": 0.5636350252456666,\\n      \"last-10-avg\": 0.5181815126228332\\n    },\\n    \"metrics/accuracy_top5\": {\\n      \"max\": 1.0,\\n      \"min\": 1.0,\\n      \"avg\": 1.0,\\n      \"last\": 1.0,\\n      \"last-5-avg\": 1.0,\\n      \"last-10-avg\": 1.0\\n    },\\n    \"val/loss\": {\\n      \"max\": 1.149,\\n      \"min\": 1.05169,\\n      \"avg\": 1.0845169999999997,\\n      \"last\": 1.05233,\\n      \"last-5-avg\": 1.081578,\\n      \"last-10-avg\": 1.084517\\n    },\\n    \"epoch\": {\\n      \"max\": 9,\\n      \"min\": 0,\\n      \"avg\": 4.909090909090909,\\n      \"last\": 9,\\n      \"last-5-avg\": 7.8,\\n      \"last-10-avg\": 5.4\\n    },\\n    \"done\": {\\n      \"max\": false,\\n      \"min\": false,\\n      \"avg\": 0.0,\\n      \"last\": false,\\n      \"last-5-avg\": 0.0,\\n      \"last-10-avg\": 0.0\\n    },\\n    \"training_iteration\": {\\n      \"max\": 12,\\n      \"min\": 1,\\n      \"avg\": 6.5,\\n      \"last\": 12,\\n      \"last-5-avg\": 10.0,\\n      \"last-10-avg\": 7.5\\n    },\\n    \"time_this_iter_s\": {\\n      \"max\": 13.324280023574829,\\n      \"min\": 0.33268213272094727,\\n      \"avg\": 6.773201982180277,\\n      \"last\": 0.33268213272094727,\\n      \"last-5-avg\": 5.002428197860718,\\n      \"last-10-avg\": 6.053290796279907\\n    },\\n    \"time_total_s\": {\\n      \"max\": 81.27842378616333,\\n      \"min\": 13.324280023574829,\\n      \"avg\": 51.506813168525696,\\n      \"last\": 81.27842378616333,\\n      \"last-5-avg\": 74.71489915847778,\\n      \"last-10-avg\": 58.40119621753693\\n    },\\n    \"time_since_restore\": {\\n      \"max\": 81.27842378616333,\\n      \"min\": 13.324280023574829,\\n      \"avg\": 51.506813168525696,\\n      \"last\": 81.27842378616333,\\n      \"last-5-avg\": 74.71489915847778,\\n      \"last-10-avg\": 58.40119621753693\\n    },\\n    \"iterations_since_restore\": {\\n      \"max\": 12,\\n      \"min\": 1,\\n      \"avg\": 6.5,\\n      \"last\": 12,\\n      \"last-5-avg\": 10.0,\\n      \"last-10-avg\": 7.5\\n    },\\n    \"fitness\": {\\n      \"max\": 0.7878787815570831,\\n      \"min\": 0.7878787815570831,\\n      \"avg\": 0.7878787815570831,\\n      \"last\": 0.7878787815570831,\\n      \"last-5-avg\": 0.7878787815570831,\\n      \"last-10-avg\": 0.7878787815570831\\n    }\\n  },\\n  \"_n_steps\": [\\n    5,\\n    10\\n  ],\\n  \"metric_n_steps\": {\\n    \"metrics/accuracy_top1\": {\\n      \"5\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe174538ef34d6a473fe174538ef34d6a473fe26ca03c4b09ea473fe26c9b20000000473fe26c9b20000000652e\"\\n      },\\n      \"10\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd936501e2584f5473fdd1758e219652c473fdf07c84b5dcc64473fdf07c84b5dcc64473fe174538ef34d6a473fe174538ef34d6a473fe174538ef34d6a473fe26ca03c4b09ea473fe26c9b20000000473fe26c9b20000000652e\"\\n      }\\n    },\\n    \"metrics/accuracy_top5\": {\\n      \"5\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473ff0000000000000473ff0000000000000473ff0000000000000473ff0000000000000473ff0000000000000652e\"\\n      },\\n      \"10\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff0000000000000473ff0000000000000473ff0000000000000473ff0000000000000473ff0000000000000473ff0000000000000473ff0000000000000473ff0000000000000473ff0000000000000473ff0000000000000652e\"\\n      }\\n    },\\n    \"val/loss\": {\\n      \"5\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473ff14692f6e8294a473ff18a32f4491299473ff1abc947064ecf473ff133d07c84b5dd473ff0d657fb69984a652e\"\\n      },\\n      \"10\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff0d3b8e4b87bdd473ff2624dd2f1a9fc473ff149c4da9003ef473ff16a550870110a473ff114f8b588e369473ff14692f6e8294a473ff18a32f4491299473ff1abc947064ecf473ff133d07c84b5dd473ff0d657fb69984a652e\"\\n      }\\n    },\\n    \"epoch\": {\\n      \"5\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b064b074b084b094b09652e\"\\n      },\\n      \"10\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b084b094b09652e\"\\n      }\\n    },\\n    \"done\": {\\n      \"5\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\\n      },\\n      \"10\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\\n      }\\n    },\\n    \"training_iteration\": {\\n      \"5\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b084b094b0a4b0b4b0c652e\"\\n      },\\n      \"10\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b034b044b054b064b074b084b094b0a4b0b4b0c652e\"\\n      }\\n    },\\n    \"time_this_iter_s\": {\\n      \"5\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847401c6b7bf000000047401c655d2000000047401c2789a000000047400b7ec2c0000000473fd54aaa00000000652e\"\\n      },\\n      \"10\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847401caa34d000000047401c50ba6000000047401c44370000000047401c9e386000000047401c37e56000000047401c6b7bf000000047401c655d2000000047401c2789a000000047400b7ec2c0000000473fd54aaa00000000652e\"\\n      }\\n    },\\n    \"time_total_s\": {\\n      \"5\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404faf850c0000004740519e18580000004740536090f20000004740543c870800000047405451d1b2000000652e\"\\n      },\\n      \"10\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403be967540000004740417ecaf60000004740450751d60000004740489b18e200000047404c22158e00000047404faf850c0000004740519e18580000004740536090f20000004740543c870800000047405451d1b2000000652e\"\\n      }\\n    },\\n    \"time_since_restore\": {\\n      \"5\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404faf850c0000004740519e18580000004740536090f20000004740543c870800000047405451d1b2000000652e\"\\n      },\\n      \"10\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403be967540000004740417ecaf60000004740450751d60000004740489b18e200000047404c22158e00000047404faf850c0000004740519e18580000004740536090f20000004740543c870800000047405451d1b2000000652e\"\\n      }\\n    },\\n    \"iterations_since_restore\": {\\n      \"5\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b084b094b0a4b0b4b0c652e\"\\n      },\\n      \"10\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b034b044b054b064b074b084b094b0a4b0b4b0c652e\"\\n      }\\n    },\\n    \"fitness\": {\\n      \"5\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fe9364d90000000612e\"\\n      },\\n      \"10\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fe9364d90000000612e\"\\n      }\\n    }\\n  },\\n  \"checkpoint_manager\": {\\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\\n  }\\n}')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results._experiment_analysis.get_best_trial(metric=\"metrics/accuracy_top1\", mode=\"max\").get_json_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metrics/accuracy_top1': {'5': deque([0.54545,\n",
       "         0.54545,\n",
       "         0.57576,\n",
       "         0.5757575631141663,\n",
       "         0.5757575631141663],\n",
       "        maxlen=5),\n",
       "  '10': deque([0.39394,\n",
       "         0.45455,\n",
       "         0.48485,\n",
       "         0.48485,\n",
       "         0.54545,\n",
       "         0.54545,\n",
       "         0.54545,\n",
       "         0.57576,\n",
       "         0.5757575631141663,\n",
       "         0.5757575631141663],\n",
       "        maxlen=10)},\n",
       " 'metrics/accuracy_top5': {'5': deque([1.0, 1.0, 1.0, 1.0, 1.0], maxlen=5),\n",
       "  '10': deque([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], maxlen=10)},\n",
       " 'val/loss': {'5': deque([1.07973, 1.09624, 1.10444, 1.07515, 1.05233],\n",
       "        maxlen=5),\n",
       "  '10': deque([1.05169,\n",
       "         1.149,\n",
       "         1.08051,\n",
       "         1.08846,\n",
       "         1.06762,\n",
       "         1.07973,\n",
       "         1.09624,\n",
       "         1.10444,\n",
       "         1.07515,\n",
       "         1.05233],\n",
       "        maxlen=10)},\n",
       " 'epoch': {'5': deque([6, 7, 8, 9, 9], maxlen=5),\n",
       "  '10': deque([1, 2, 3, 4, 5, 6, 7, 8, 9, 9], maxlen=10)},\n",
       " 'done': {'5': deque([False, False, False, False, False], maxlen=5),\n",
       "  '10': deque([False,\n",
       "         False,\n",
       "         False,\n",
       "         False,\n",
       "         False,\n",
       "         False,\n",
       "         False,\n",
       "         False,\n",
       "         False,\n",
       "         False],\n",
       "        maxlen=10)},\n",
       " 'training_iteration': {'5': deque([8, 9, 10, 11, 12], maxlen=5),\n",
       "  '10': deque([3, 4, 5, 6, 7, 8, 9, 10, 11, 12], maxlen=10)},\n",
       " 'time_this_iter_s': {'5': deque([7.104964971542358,\n",
       "         7.098988056182861,\n",
       "         7.038610935211182,\n",
       "         3.4368948936462402,\n",
       "         0.33268213272094727],\n",
       "        maxlen=5),\n",
       "  '10': deque([7.166217088699341,\n",
       "         7.078835964202881,\n",
       "         7.066616058349609,\n",
       "         7.15451192855835,\n",
       "         7.054585933685303,\n",
       "         7.104964971542358,\n",
       "         7.098988056182861,\n",
       "         7.038610935211182,\n",
       "         3.4368948936462402,\n",
       "         0.33268213272094727],\n",
       "        maxlen=10)},\n",
       " 'time_total_s': {'5': deque([63.3712477684021,\n",
       "         70.47023582458496,\n",
       "         77.50884675979614,\n",
       "         80.94574165344238,\n",
       "         81.27842378616333],\n",
       "        maxlen=5),\n",
       "  '10': deque([27.9117329120636,\n",
       "         34.99056887626648,\n",
       "         42.05718493461609,\n",
       "         49.21169686317444,\n",
       "         56.26628279685974,\n",
       "         63.3712477684021,\n",
       "         70.47023582458496,\n",
       "         77.50884675979614,\n",
       "         80.94574165344238,\n",
       "         81.27842378616333],\n",
       "        maxlen=10)},\n",
       " 'time_since_restore': {'5': deque([63.3712477684021,\n",
       "         70.47023582458496,\n",
       "         77.50884675979614,\n",
       "         80.94574165344238,\n",
       "         81.27842378616333],\n",
       "        maxlen=5),\n",
       "  '10': deque([27.9117329120636,\n",
       "         34.99056887626648,\n",
       "         42.05718493461609,\n",
       "         49.21169686317444,\n",
       "         56.26628279685974,\n",
       "         63.3712477684021,\n",
       "         70.47023582458496,\n",
       "         77.50884675979614,\n",
       "         80.94574165344238,\n",
       "         81.27842378616333],\n",
       "        maxlen=10)},\n",
       " 'iterations_since_restore': {'5': deque([8, 9, 10, 11, 12], maxlen=5),\n",
       "  '10': deque([3, 4, 5, 6, 7, 8, 9, 10, 11, 12], maxlen=10)},\n",
       " 'fitness': {'5': deque([0.7878787815570831], maxlen=5),\n",
       "  '10': deque([0.7878787815570831], maxlen=10)}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results._experiment_analysis.get_best_trial(metric=\"metrics/accuracy_top1\", mode=\"max\").run_metadata.metric_n_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.39394,\n",
       " 0.45455,\n",
       " 0.48485,\n",
       " 0.48485,\n",
       " 0.54545,\n",
       " 0.54545,\n",
       " 0.54545,\n",
       " 0.57576,\n",
       " 0.5757575631141663,\n",
       " 0.5757575631141663]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(list(results._experiment_analysis.get_best_trial(metric=\"metrics/accuracy_top1\", mode=\"max\").run_metadata.metric_n_steps.get('metrics/accuracy_top1').values())[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metrics/accuracy_top1': 0.5757575631141663,\n",
       " 'metrics/accuracy_top5': 1.0,\n",
       " 'fitness': 0.7878787815570831,\n",
       " 'timestamp': 1727057730,\n",
       " 'checkpoint_dir_name': None,\n",
       " 'done': True,\n",
       " 'training_iteration': 12,\n",
       " 'trial_id': '83e4f_00000',\n",
       " 'date': '2024-09-23_10-15-30',\n",
       " 'time_this_iter_s': 0.33268213272094727,\n",
       " 'time_total_s': 81.27842378616333,\n",
       " 'pid': 3575,\n",
       " 'hostname': 'MacBook-Pro-2.local',\n",
       " 'node_ip': '127.0.0.1',\n",
       " 'config': {'lr0': 0.07805511233688268,\n",
       "  'lrf': 0.1270916816102439,\n",
       "  'momentum': 0.843169988104459,\n",
       "  'weight_decay': 0.0001433532874090464,\n",
       "  'warmup_epochs': 4.7233445852479194,\n",
       "  'warmup_momentum': 0.49575590566256805,\n",
       "  'box': 0.09463914919829426,\n",
       "  'cls': 1.2053113259975823,\n",
       "  'hsv_h': 0.07742336894342167,\n",
       "  'hsv_s': 0.4105352989948937,\n",
       "  'hsv_v': 0.5115905539817837,\n",
       "  'degrees': 0.8455410196359814,\n",
       "  'translate': 0.5558719473682894,\n",
       "  'scale': 0.5508861504501793,\n",
       "  'shear': 6.169339968747569,\n",
       "  'perspective': 0.0009437480785146242,\n",
       "  'flipud': 0.6818202991034834,\n",
       "  'fliplr': 0.359507900573786,\n",
       "  'bgr': 0.43703195379934145,\n",
       "  'mosaic': 0.6976311959272649,\n",
       "  'mixup': 0.06022547162926983,\n",
       "  'copy_paste': 0.6667667154456677,\n",
       "  'data': '/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification',\n",
       "  'epochs': 10,\n",
       "  'imgsz': 640,\n",
       "  'project': '/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2',\n",
       "  'plots': True,\n",
       "  'save_json': True,\n",
       "  'verbose': True},\n",
       " 'time_since_restore': 81.27842378616333,\n",
       " 'iterations_since_restore': 12,\n",
       " 'experiment_tag': '0_bgr=0.4370,box=0.0946,cls=1.2053,copy_paste=0.6668,degrees=0.8455,fliplr=0.3595,flipud=0.6818,hsv_h=0.0774,hsv_s=0.4105,hsv_v=0.5116,lr0=0.0781,lrf=0.1271,mixup=0.0602,momentum=0.8432,mosaic=0.6976,perspective=0.0009,scale=0.5509,shear=6.1693,translate=0.5559,warmup_epochs=4.7233,warmup_momentum=0.4958,weight_decay=0.0001'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results._experiment_analysis.get_best_trial(metric=\"metrics/accuracy_top1\", mode=\"max\").run_metadata.last_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start_time': 1727057649.292568,\n",
       " 'num_failures': 0,\n",
       " 'num_failures_after_restore': 0,\n",
       " 'error_filename': None,\n",
       " 'pickled_error_filename': None,\n",
       " 'last_result': {'metrics/accuracy_top1': 0.5757575631141663,\n",
       "  'metrics/accuracy_top5': 1.0,\n",
       "  'fitness': 0.7878787815570831,\n",
       "  'timestamp': 1727057730,\n",
       "  'checkpoint_dir_name': None,\n",
       "  'done': True,\n",
       "  'training_iteration': 12,\n",
       "  'trial_id': '83e4f_00000',\n",
       "  'date': '2024-09-23_10-15-30',\n",
       "  'time_this_iter_s': 0.33268213272094727,\n",
       "  'time_total_s': 81.27842378616333,\n",
       "  'pid': 3575,\n",
       "  'hostname': 'MacBook-Pro-2.local',\n",
       "  'node_ip': '127.0.0.1',\n",
       "  'config': {'lr0': 0.07805511233688268,\n",
       "   'lrf': 0.1270916816102439,\n",
       "   'momentum': 0.843169988104459,\n",
       "   'weight_decay': 0.0001433532874090464,\n",
       "   'warmup_epochs': 4.7233445852479194,\n",
       "   'warmup_momentum': 0.49575590566256805,\n",
       "   'box': 0.09463914919829426,\n",
       "   'cls': 1.2053113259975823,\n",
       "   'hsv_h': 0.07742336894342167,\n",
       "   'hsv_s': 0.4105352989948937,\n",
       "   'hsv_v': 0.5115905539817837,\n",
       "   'degrees': 0.8455410196359814,\n",
       "   'translate': 0.5558719473682894,\n",
       "   'scale': 0.5508861504501793,\n",
       "   'shear': 6.169339968747569,\n",
       "   'perspective': 0.0009437480785146242,\n",
       "   'flipud': 0.6818202991034834,\n",
       "   'fliplr': 0.359507900573786,\n",
       "   'bgr': 0.43703195379934145,\n",
       "   'mosaic': 0.6976311959272649,\n",
       "   'mixup': 0.06022547162926983,\n",
       "   'copy_paste': 0.6667667154456677,\n",
       "   'data': '/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification',\n",
       "   'epochs': 10,\n",
       "   'imgsz': 640,\n",
       "   'project': '/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2',\n",
       "   'plots': True,\n",
       "   'save_json': True,\n",
       "   'verbose': True},\n",
       "  'time_since_restore': 81.27842378616333,\n",
       "  'iterations_since_restore': 12,\n",
       "  'experiment_tag': '0_bgr=0.4370,box=0.0946,cls=1.2053,copy_paste=0.6668,degrees=0.8455,fliplr=0.3595,flipud=0.6818,hsv_h=0.0774,hsv_s=0.4105,hsv_v=0.5116,lr0=0.0781,lrf=0.1271,mixup=0.0602,momentum=0.8432,mosaic=0.6976,perspective=0.0009,scale=0.5509,shear=6.1693,translate=0.5559,warmup_epochs=4.7233,warmup_momentum=0.4958,weight_decay=0.0001'},\n",
       " 'last_result_time': 1727057730.593405,\n",
       " 'metric_analysis': {'metrics/accuracy_top1': {'max': 0.57576,\n",
       "   'min': 0.27273,\n",
       "   'avg': 0.4797979271856943,\n",
       "   'last': 0.5757575631141663,\n",
       "   'last-5-avg': 0.5636350252456666,\n",
       "   'last-10-avg': 0.5181815126228332},\n",
       "  'metrics/accuracy_top5': {'max': 1.0,\n",
       "   'min': 1.0,\n",
       "   'avg': 1.0,\n",
       "   'last': 1.0,\n",
       "   'last-5-avg': 1.0,\n",
       "   'last-10-avg': 1.0},\n",
       "  'val/loss': {'max': 1.149,\n",
       "   'min': 1.05169,\n",
       "   'avg': 1.0845169999999997,\n",
       "   'last': 1.05233,\n",
       "   'last-5-avg': 1.081578,\n",
       "   'last-10-avg': 1.084517},\n",
       "  'epoch': {'max': 9,\n",
       "   'min': 0,\n",
       "   'avg': 4.909090909090909,\n",
       "   'last': 9,\n",
       "   'last-5-avg': 7.8,\n",
       "   'last-10-avg': 5.4},\n",
       "  'done': {'max': False,\n",
       "   'min': False,\n",
       "   'avg': 0.0,\n",
       "   'last': False,\n",
       "   'last-5-avg': 0.0,\n",
       "   'last-10-avg': 0.0},\n",
       "  'training_iteration': {'max': 12,\n",
       "   'min': 1,\n",
       "   'avg': 6.5,\n",
       "   'last': 12,\n",
       "   'last-5-avg': 10.0,\n",
       "   'last-10-avg': 7.5},\n",
       "  'time_this_iter_s': {'max': 13.324280023574829,\n",
       "   'min': 0.33268213272094727,\n",
       "   'avg': 6.773201982180277,\n",
       "   'last': 0.33268213272094727,\n",
       "   'last-5-avg': 5.002428197860718,\n",
       "   'last-10-avg': 6.053290796279907},\n",
       "  'time_total_s': {'max': 81.27842378616333,\n",
       "   'min': 13.324280023574829,\n",
       "   'avg': 51.506813168525696,\n",
       "   'last': 81.27842378616333,\n",
       "   'last-5-avg': 74.71489915847778,\n",
       "   'last-10-avg': 58.40119621753693},\n",
       "  'time_since_restore': {'max': 81.27842378616333,\n",
       "   'min': 13.324280023574829,\n",
       "   'avg': 51.506813168525696,\n",
       "   'last': 81.27842378616333,\n",
       "   'last-5-avg': 74.71489915847778,\n",
       "   'last-10-avg': 58.40119621753693},\n",
       "  'iterations_since_restore': {'max': 12,\n",
       "   'min': 1,\n",
       "   'avg': 6.5,\n",
       "   'last': 12,\n",
       "   'last-5-avg': 10.0,\n",
       "   'last-10-avg': 7.5},\n",
       "  'fitness': {'max': 0.7878787815570831,\n",
       "   'min': 0.7878787815570831,\n",
       "   'avg': 0.7878787815570831,\n",
       "   'last': 0.7878787815570831,\n",
       "   'last-5-avg': 0.7878787815570831,\n",
       "   'last-10-avg': 0.7878787815570831}},\n",
       " '_n_steps': [5, 10],\n",
       " 'metric_n_steps': {'metrics/accuracy_top1': {'5': {'_type': 'CLOUDPICKLE_FALLBACK',\n",
       "    'value': '8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe174538ef34d6a473fe174538ef34d6a473fe26ca03c4b09ea473fe26c9b20000000473fe26c9b20000000652e'},\n",
       "   '10': {'_type': 'CLOUDPICKLE_FALLBACK',\n",
       "    'value': '8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd936501e2584f5473fdd1758e219652c473fdf07c84b5dcc64473fdf07c84b5dcc64473fe174538ef34d6a473fe174538ef34d6a473fe174538ef34d6a473fe26ca03c4b09ea473fe26c9b20000000473fe26c9b20000000652e'}},\n",
       "  'metrics/accuracy_top5': {'5': {'_type': 'CLOUDPICKLE_FALLBACK',\n",
       "    'value': '8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473ff0000000000000473ff0000000000000473ff0000000000000473ff0000000000000473ff0000000000000652e'},\n",
       "   '10': {'_type': 'CLOUDPICKLE_FALLBACK',\n",
       "    'value': '8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff0000000000000473ff0000000000000473ff0000000000000473ff0000000000000473ff0000000000000473ff0000000000000473ff0000000000000473ff0000000000000473ff0000000000000473ff0000000000000652e'}},\n",
       "  'val/loss': {'5': {'_type': 'CLOUDPICKLE_FALLBACK',\n",
       "    'value': '8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473ff14692f6e8294a473ff18a32f4491299473ff1abc947064ecf473ff133d07c84b5dd473ff0d657fb69984a652e'},\n",
       "   '10': {'_type': 'CLOUDPICKLE_FALLBACK',\n",
       "    'value': '8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff0d3b8e4b87bdd473ff2624dd2f1a9fc473ff149c4da9003ef473ff16a550870110a473ff114f8b588e369473ff14692f6e8294a473ff18a32f4491299473ff1abc947064ecf473ff133d07c84b5dd473ff0d657fb69984a652e'}},\n",
       "  'epoch': {'5': {'_type': 'CLOUDPICKLE_FALLBACK',\n",
       "    'value': '8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b064b074b084b094b09652e'},\n",
       "   '10': {'_type': 'CLOUDPICKLE_FALLBACK',\n",
       "    'value': '80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b084b094b09652e'}},\n",
       "  'done': {'5': {'_type': 'CLOUDPICKLE_FALLBACK',\n",
       "    'value': '80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e'},\n",
       "   '10': {'_type': 'CLOUDPICKLE_FALLBACK',\n",
       "    'value': '8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e'}},\n",
       "  'training_iteration': {'5': {'_type': 'CLOUDPICKLE_FALLBACK',\n",
       "    'value': '8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b084b094b0a4b0b4b0c652e'},\n",
       "   '10': {'_type': 'CLOUDPICKLE_FALLBACK',\n",
       "    'value': '80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b034b044b054b064b074b084b094b0a4b0b4b0c652e'}},\n",
       "  'time_this_iter_s': {'5': {'_type': 'CLOUDPICKLE_FALLBACK',\n",
       "    'value': '8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847401c6b7bf000000047401c655d2000000047401c2789a000000047400b7ec2c0000000473fd54aaa00000000652e'},\n",
       "   '10': {'_type': 'CLOUDPICKLE_FALLBACK',\n",
       "    'value': '8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847401caa34d000000047401c50ba6000000047401c44370000000047401c9e386000000047401c37e56000000047401c6b7bf000000047401c655d2000000047401c2789a000000047400b7ec2c0000000473fd54aaa00000000652e'}},\n",
       "  'time_total_s': {'5': {'_type': 'CLOUDPICKLE_FALLBACK',\n",
       "    'value': '8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404faf850c0000004740519e18580000004740536090f20000004740543c870800000047405451d1b2000000652e'},\n",
       "   '10': {'_type': 'CLOUDPICKLE_FALLBACK',\n",
       "    'value': '8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403be967540000004740417ecaf60000004740450751d60000004740489b18e200000047404c22158e00000047404faf850c0000004740519e18580000004740536090f20000004740543c870800000047405451d1b2000000652e'}},\n",
       "  'time_since_restore': {'5': {'_type': 'CLOUDPICKLE_FALLBACK',\n",
       "    'value': '8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404faf850c0000004740519e18580000004740536090f20000004740543c870800000047405451d1b2000000652e'},\n",
       "   '10': {'_type': 'CLOUDPICKLE_FALLBACK',\n",
       "    'value': '8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403be967540000004740417ecaf60000004740450751d60000004740489b18e200000047404c22158e00000047404faf850c0000004740519e18580000004740536090f20000004740543c870800000047405451d1b2000000652e'}},\n",
       "  'iterations_since_restore': {'5': {'_type': 'CLOUDPICKLE_FALLBACK',\n",
       "    'value': '8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b084b094b0a4b0b4b0c652e'},\n",
       "   '10': {'_type': 'CLOUDPICKLE_FALLBACK',\n",
       "    'value': '80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b034b044b054b064b074b084b094b0a4b0b4b0c652e'}},\n",
       "  'fitness': {'5': {'_type': 'CLOUDPICKLE_FALLBACK',\n",
       "    'value': '8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fe9364d90000000612e'},\n",
       "   '10': {'_type': 'CLOUDPICKLE_FALLBACK',\n",
       "    'value': '8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fe9364d90000000612e'}}},\n",
       " 'checkpoint_manager': {'_type': 'CLOUDPICKLE_FALLBACK',\n",
       "  'value': '80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e'}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json.loads(results._experiment_analysis.get_best_trial(metric=\"metrics/accuracy_top1\", mode=\"max\").run_metadata.get_json_state())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('{\\n  \"stub\": false,\\n  \"trainable_name\": \"_tune\",\\n  \"trial_id\": \"83e4f_00000\",\\n  \"storage\": {\\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n    \"value\": \"80059570030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c195f74756e655f323032342d30392d32335f31302d31342d3038948c0e747269616c5f6469725f6e616d65948c965f74756e655f38336534665f30303030305f305f6267723d302e343337302c626f783d302e303934362c636c733d312e323035332c636f70795f70617374653d302e363636382c646567726565733d302e383435352c666c69706c723d302e333539352c666c697075643d302e363831382c6873765f683d302e303737342c6873765f323032342d30392d32335f31302d31342d3038948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c512f55736572732f7472656173757265735f792f446f63756d656e74732f636f64652f48472f4175746f4d4c2f707974686f6e2f6175746f6d6c2f74657374732f72756e732f6465746563742f74756e653294681768008c115f46696c6573797374656d53796e6365729493942981947d94286819681f68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30392d32335f31302d31342d30389475622e\"\\n  },\\n  \"config\": {\\n    \"lr0\": 0.07805511233688268,\\n    \"lrf\": 0.1270916816102439,\\n    \"momentum\": 0.843169988104459,\\n    \"weight_decay\": 0.0001433532874090464,\\n    \"warmup_epochs\": 4.7233445852479194,\\n    \"warmup_momentum\": 0.49575590566256805,\\n    \"box\": 0.09463914919829426,\\n    \"cls\": 1.2053113259975823,\\n    \"hsv_h\": 0.07742336894342167,\\n    \"hsv_s\": 0.4105352989948937,\\n    \"hsv_v\": 0.5115905539817837,\\n    \"degrees\": 0.8455410196359814,\\n    \"translate\": 0.5558719473682894,\\n    \"scale\": 0.5508861504501793,\\n    \"shear\": 6.169339968747569,\\n    \"perspective\": 0.0009437480785146242,\\n    \"flipud\": 0.6818202991034834,\\n    \"fliplr\": 0.359507900573786,\\n    \"bgr\": 0.43703195379934145,\\n    \"mosaic\": 0.6976311959272649,\\n    \"mixup\": 0.06022547162926983,\\n    \"copy_paste\": 0.6667667154456677,\\n    \"data\": \"/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification\"\\n  },\\n  \"_Trial__unresolved_config\": {\\n    \"lr0\": 0.07805511233688268,\\n    \"lrf\": 0.1270916816102439,\\n    \"momentum\": 0.843169988104459,\\n    \"weight_decay\": 0.0001433532874090464,\\n    \"warmup_epochs\": 4.7233445852479194,\\n    \"warmup_momentum\": 0.49575590566256805,\\n    \"box\": 0.09463914919829426,\\n    \"cls\": 1.2053113259975823,\\n    \"hsv_h\": 0.07742336894342167,\\n    \"hsv_s\": 0.4105352989948937,\\n    \"hsv_v\": 0.5115905539817837,\\n    \"degrees\": 0.8455410196359814,\\n    \"translate\": 0.5558719473682894,\\n    \"scale\": 0.5508861504501793,\\n    \"shear\": 6.169339968747569,\\n    \"perspective\": 0.0009437480785146242,\\n    \"flipud\": 0.6818202991034834,\\n    \"fliplr\": 0.359507900573786,\\n    \"bgr\": 0.43703195379934145,\\n    \"mosaic\": 0.6976311959272649,\\n    \"mixup\": 0.06022547162926983,\\n    \"copy_paste\": 0.6667667154456677,\\n    \"data\": \"/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification\"\\n  },\\n  \"evaluated_params\": {\\n    \"lr0\": 0.07805511233688268,\\n    \"lrf\": 0.1270916816102439,\\n    \"momentum\": 0.843169988104459,\\n    \"weight_decay\": 0.0001433532874090464,\\n    \"warmup_epochs\": 4.7233445852479194,\\n    \"warmup_momentum\": 0.49575590566256805,\\n    \"box\": 0.09463914919829426,\\n    \"cls\": 1.2053113259975823,\\n    \"hsv_h\": 0.07742336894342167,\\n    \"hsv_s\": 0.4105352989948937,\\n    \"hsv_v\": 0.5115905539817837,\\n    \"degrees\": 0.8455410196359814,\\n    \"translate\": 0.5558719473682894,\\n    \"scale\": 0.5508861504501793,\\n    \"shear\": 6.169339968747569,\\n    \"perspective\": 0.0009437480785146242,\\n    \"flipud\": 0.6818202991034834,\\n    \"fliplr\": 0.359507900573786,\\n    \"bgr\": 0.43703195379934145,\\n    \"mosaic\": 0.6976311959272649,\\n    \"mixup\": 0.06022547162926983,\\n    \"copy_paste\": 0.6667667154456677\\n  },\\n  \"experiment_tag\": \"0_bgr=0.4370,box=0.0946,cls=1.2053,copy_paste=0.6668,degrees=0.8455,fliplr=0.3595,flipud=0.6818,hsv_h=0.0774,hsv_s=0.4105,hsv_v=0.5116,lr0=0.0781,lrf=0.1271,mixup=0.0602,momentum=0.8432,mosaic=0.6976,perspective=0.0009,scale=0.5509,shear=6.1693,translate=0.5559,warmup_epochs=4.7233,warmup_momentum=0.4958,weight_decay=0.0001\",\\n  \"stopping_criterion\": {},\\n  \"_setup_default_resource\": true,\\n  \"_default_placement_group_factory\": \"80054e2e\",\\n  \"placement_group_factory\": \"800595aa000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c034350559447402000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\\n  \"log_to_file\": [\\n    null,\\n    null\\n  ],\\n  \"max_failures\": 0,\\n  \"_default_result_or_future\": null,\\n  \"export_formats\": [],\\n  \"status\": \"TERMINATED\",\\n  \"relative_logdir\": \"_tune_83e4f_00000_0_bgr=0.4370,box=0.0946,cls=1.2053,copy_paste=0.6668,degrees=0.8455,fliplr=0.3595,flipud=0.6818,hsv_h=0.0774,hsv_2024-09-23_10-14-08\",\\n  \"trial_name_creator\": null,\\n  \"trial_dirname_creator\": null,\\n  \"custom_trial_name\": null,\\n  \"custom_dirname\": null,\\n  \"restore_path\": null,\\n  \"_restore_checkpoint_result\": null,\\n  \"_state_json\": null,\\n  \"results\": \"80054e2e\",\\n  \"extra_arg\": \"80054e2e\",\\n  \"_resources\": \"80054e2e\"\\n}',\n",
       " '{\\n  \"start_time\": 1727057649.292568,\\n  \"num_failures\": 0,\\n  \"num_failures_after_restore\": 0,\\n  \"error_filename\": null,\\n  \"pickled_error_filename\": null,\\n  \"last_result\": {\\n    \"metrics/accuracy_top1\": 0.5757575631141663,\\n    \"metrics/accuracy_top5\": 1.0,\\n    \"fitness\": 0.7878787815570831,\\n    \"timestamp\": 1727057730,\\n    \"checkpoint_dir_name\": null,\\n    \"done\": true,\\n    \"training_iteration\": 12,\\n    \"trial_id\": \"83e4f_00000\",\\n    \"date\": \"2024-09-23_10-15-30\",\\n    \"time_this_iter_s\": 0.33268213272094727,\\n    \"time_total_s\": 81.27842378616333,\\n    \"pid\": 3575,\\n    \"hostname\": \"MacBook-Pro-2.local\",\\n    \"node_ip\": \"127.0.0.1\",\\n    \"config\": {\\n      \"lr0\": 0.07805511233688268,\\n      \"lrf\": 0.1270916816102439,\\n      \"momentum\": 0.843169988104459,\\n      \"weight_decay\": 0.0001433532874090464,\\n      \"warmup_epochs\": 4.7233445852479194,\\n      \"warmup_momentum\": 0.49575590566256805,\\n      \"box\": 0.09463914919829426,\\n      \"cls\": 1.2053113259975823,\\n      \"hsv_h\": 0.07742336894342167,\\n      \"hsv_s\": 0.4105352989948937,\\n      \"hsv_v\": 0.5115905539817837,\\n      \"degrees\": 0.8455410196359814,\\n      \"translate\": 0.5558719473682894,\\n      \"scale\": 0.5508861504501793,\\n      \"shear\": 6.169339968747569,\\n      \"perspective\": 0.0009437480785146242,\\n      \"flipud\": 0.6818202991034834,\\n      \"fliplr\": 0.359507900573786,\\n      \"bgr\": 0.43703195379934145,\\n      \"mosaic\": 0.6976311959272649,\\n      \"mixup\": 0.06022547162926983,\\n      \"copy_paste\": 0.6667667154456677,\\n      \"data\": \"/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification\",\\n      \"epochs\": 10,\\n      \"imgsz\": 640,\\n      \"project\": \"/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2\",\\n      \"plots\": true,\\n      \"save_json\": true,\\n      \"verbose\": true\\n    },\\n    \"time_since_restore\": 81.27842378616333,\\n    \"iterations_since_restore\": 12,\\n    \"experiment_tag\": \"0_bgr=0.4370,box=0.0946,cls=1.2053,copy_paste=0.6668,degrees=0.8455,fliplr=0.3595,flipud=0.6818,hsv_h=0.0774,hsv_s=0.4105,hsv_v=0.5116,lr0=0.0781,lrf=0.1271,mixup=0.0602,momentum=0.8432,mosaic=0.6976,perspective=0.0009,scale=0.5509,shear=6.1693,translate=0.5559,warmup_epochs=4.7233,warmup_momentum=0.4958,weight_decay=0.0001\"\\n  },\\n  \"last_result_time\": 1727057730.593405,\\n  \"metric_analysis\": {\\n    \"metrics/accuracy_top1\": {\\n      \"max\": 0.57576,\\n      \"min\": 0.27273,\\n      \"avg\": 0.4797979271856943,\\n      \"last\": 0.5757575631141663,\\n      \"last-5-avg\": 0.5636350252456666,\\n      \"last-10-avg\": 0.5181815126228332\\n    },\\n    \"metrics/accuracy_top5\": {\\n      \"max\": 1.0,\\n      \"min\": 1.0,\\n      \"avg\": 1.0,\\n      \"last\": 1.0,\\n      \"last-5-avg\": 1.0,\\n      \"last-10-avg\": 1.0\\n    },\\n    \"val/loss\": {\\n      \"max\": 1.149,\\n      \"min\": 1.05169,\\n      \"avg\": 1.0845169999999997,\\n      \"last\": 1.05233,\\n      \"last-5-avg\": 1.081578,\\n      \"last-10-avg\": 1.084517\\n    },\\n    \"epoch\": {\\n      \"max\": 9,\\n      \"min\": 0,\\n      \"avg\": 4.909090909090909,\\n      \"last\": 9,\\n      \"last-5-avg\": 7.8,\\n      \"last-10-avg\": 5.4\\n    },\\n    \"done\": {\\n      \"max\": false,\\n      \"min\": false,\\n      \"avg\": 0.0,\\n      \"last\": false,\\n      \"last-5-avg\": 0.0,\\n      \"last-10-avg\": 0.0\\n    },\\n    \"training_iteration\": {\\n      \"max\": 12,\\n      \"min\": 1,\\n      \"avg\": 6.5,\\n      \"last\": 12,\\n      \"last-5-avg\": 10.0,\\n      \"last-10-avg\": 7.5\\n    },\\n    \"time_this_iter_s\": {\\n      \"max\": 13.324280023574829,\\n      \"min\": 0.33268213272094727,\\n      \"avg\": 6.773201982180277,\\n      \"last\": 0.33268213272094727,\\n      \"last-5-avg\": 5.002428197860718,\\n      \"last-10-avg\": 6.053290796279907\\n    },\\n    \"time_total_s\": {\\n      \"max\": 81.27842378616333,\\n      \"min\": 13.324280023574829,\\n      \"avg\": 51.506813168525696,\\n      \"last\": 81.27842378616333,\\n      \"last-5-avg\": 74.71489915847778,\\n      \"last-10-avg\": 58.40119621753693\\n    },\\n    \"time_since_restore\": {\\n      \"max\": 81.27842378616333,\\n      \"min\": 13.324280023574829,\\n      \"avg\": 51.506813168525696,\\n      \"last\": 81.27842378616333,\\n      \"last-5-avg\": 74.71489915847778,\\n      \"last-10-avg\": 58.40119621753693\\n    },\\n    \"iterations_since_restore\": {\\n      \"max\": 12,\\n      \"min\": 1,\\n      \"avg\": 6.5,\\n      \"last\": 12,\\n      \"last-5-avg\": 10.0,\\n      \"last-10-avg\": 7.5\\n    },\\n    \"fitness\": {\\n      \"max\": 0.7878787815570831,\\n      \"min\": 0.7878787815570831,\\n      \"avg\": 0.7878787815570831,\\n      \"last\": 0.7878787815570831,\\n      \"last-5-avg\": 0.7878787815570831,\\n      \"last-10-avg\": 0.7878787815570831\\n    }\\n  },\\n  \"_n_steps\": [\\n    5,\\n    10\\n  ],\\n  \"metric_n_steps\": {\\n    \"metrics/accuracy_top1\": {\\n      \"5\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe174538ef34d6a473fe174538ef34d6a473fe26ca03c4b09ea473fe26c9b20000000473fe26c9b20000000652e\"\\n      },\\n      \"10\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd936501e2584f5473fdd1758e219652c473fdf07c84b5dcc64473fdf07c84b5dcc64473fe174538ef34d6a473fe174538ef34d6a473fe174538ef34d6a473fe26ca03c4b09ea473fe26c9b20000000473fe26c9b20000000652e\"\\n      }\\n    },\\n    \"metrics/accuracy_top5\": {\\n      \"5\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473ff0000000000000473ff0000000000000473ff0000000000000473ff0000000000000473ff0000000000000652e\"\\n      },\\n      \"10\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff0000000000000473ff0000000000000473ff0000000000000473ff0000000000000473ff0000000000000473ff0000000000000473ff0000000000000473ff0000000000000473ff0000000000000473ff0000000000000652e\"\\n      }\\n    },\\n    \"val/loss\": {\\n      \"5\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473ff14692f6e8294a473ff18a32f4491299473ff1abc947064ecf473ff133d07c84b5dd473ff0d657fb69984a652e\"\\n      },\\n      \"10\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff0d3b8e4b87bdd473ff2624dd2f1a9fc473ff149c4da9003ef473ff16a550870110a473ff114f8b588e369473ff14692f6e8294a473ff18a32f4491299473ff1abc947064ecf473ff133d07c84b5dd473ff0d657fb69984a652e\"\\n      }\\n    },\\n    \"epoch\": {\\n      \"5\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b064b074b084b094b09652e\"\\n      },\\n      \"10\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b084b094b09652e\"\\n      }\\n    },\\n    \"done\": {\\n      \"5\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\\n      },\\n      \"10\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\\n      }\\n    },\\n    \"training_iteration\": {\\n      \"5\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b084b094b0a4b0b4b0c652e\"\\n      },\\n      \"10\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b034b044b054b064b074b084b094b0a4b0b4b0c652e\"\\n      }\\n    },\\n    \"time_this_iter_s\": {\\n      \"5\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847401c6b7bf000000047401c655d2000000047401c2789a000000047400b7ec2c0000000473fd54aaa00000000652e\"\\n      },\\n      \"10\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847401caa34d000000047401c50ba6000000047401c44370000000047401c9e386000000047401c37e56000000047401c6b7bf000000047401c655d2000000047401c2789a000000047400b7ec2c0000000473fd54aaa00000000652e\"\\n      }\\n    },\\n    \"time_total_s\": {\\n      \"5\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404faf850c0000004740519e18580000004740536090f20000004740543c870800000047405451d1b2000000652e\"\\n      },\\n      \"10\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403be967540000004740417ecaf60000004740450751d60000004740489b18e200000047404c22158e00000047404faf850c0000004740519e18580000004740536090f20000004740543c870800000047405451d1b2000000652e\"\\n      }\\n    },\\n    \"time_since_restore\": {\\n      \"5\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404faf850c0000004740519e18580000004740536090f20000004740543c870800000047405451d1b2000000652e\"\\n      },\\n      \"10\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403be967540000004740417ecaf60000004740450751d60000004740489b18e200000047404c22158e00000047404faf850c0000004740519e18580000004740536090f20000004740543c870800000047405451d1b2000000652e\"\\n      }\\n    },\\n    \"iterations_since_restore\": {\\n      \"5\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b084b094b0a4b0b4b0c652e\"\\n      },\\n      \"10\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b034b044b054b064b074b084b094b0a4b0b4b0c652e\"\\n      }\\n    },\\n    \"fitness\": {\\n      \"5\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fe9364d90000000612e\"\\n      },\\n      \"10\": {\\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fe9364d90000000612e\"\\n      }\\n    }\\n  },\\n  \"checkpoint_manager\": {\\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\\n  }\\n}')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results._experiment_analysis.get_best_trial(metric=\"metrics/accuracy_top1\", mode=\"max\").get_json_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### metricsconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Result(\n",
       "   metrics={'metrics/accuracy_top1': 0.5757575631141663, 'metrics/accuracy_top5': 1.0, 'fitness': 0.7878787815570831},\n",
       "   path='/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/runs/detect/tune2/_tune_2024-09-23_10-14-08/_tune_83e4f_00000_0_bgr=0.4370,box=0.0946,cls=1.2053,copy_paste=0.6668,degrees=0.8455,fliplr=0.3595,flipud=0.6818,hsv_h=0.0774,hsv_2024-09-23_10-14-08',\n",
       "   filesystem='local',\n",
       "   checkpoint=None\n",
       " ),\n",
       " Result(\n",
       "   metrics={'metrics/accuracy_top1': 0.5757575631141663, 'metrics/accuracy_top5': 1.0, 'fitness': 0.7878787815570831},\n",
       "   path='/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/runs/detect/tune2/_tune_2024-09-23_10-14-08/_tune_83e4f_00001_1_bgr=0.1966,box=0.1979,cls=0.5878,copy_paste=0.0971,degrees=11.3981,fliplr=0.1382,flipud=0.6563,hsv_h=0.0209,hs_2024-09-23_10-14-08',\n",
       "   filesystem='local',\n",
       "   checkpoint=None\n",
       " )]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results._results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results._results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********metrics\n",
      "83e4f_00000\n",
      "*********metrics\n",
      "83e4f_00001\n"
     ]
    }
   ],
   "source": [
    "for trial in results._results:\n",
    "    print(f\"*********metrics\")\n",
    "    print(trial.metrics.get('trial_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metrics/accuracy_top1': 0.5757575631141663,\n",
       " 'metrics/accuracy_top5': 1.0,\n",
       " 'fitness': 0.7878787815570831,\n",
       " 'timestamp': 1727057730,\n",
       " 'checkpoint_dir_name': None,\n",
       " 'done': True,\n",
       " 'training_iteration': 12,\n",
       " 'trial_id': '83e4f_00000',\n",
       " 'date': '2024-09-23_10-15-30',\n",
       " 'time_this_iter_s': 0.33268213272094727,\n",
       " 'time_total_s': 81.27842378616333,\n",
       " 'pid': 3575,\n",
       " 'hostname': 'MacBook-Pro-2.local',\n",
       " 'node_ip': '127.0.0.1',\n",
       " 'config': {'lr0': 0.07805511233688268,\n",
       "  'lrf': 0.1270916816102439,\n",
       "  'momentum': 0.843169988104459,\n",
       "  'weight_decay': 0.0001433532874090464,\n",
       "  'warmup_epochs': 4.7233445852479194,\n",
       "  'warmup_momentum': 0.49575590566256805,\n",
       "  'box': 0.09463914919829426,\n",
       "  'cls': 1.2053113259975823,\n",
       "  'hsv_h': 0.07742336894342167,\n",
       "  'hsv_s': 0.4105352989948937,\n",
       "  'hsv_v': 0.5115905539817837,\n",
       "  'degrees': 0.8455410196359814,\n",
       "  'translate': 0.5558719473682894,\n",
       "  'scale': 0.5508861504501793,\n",
       "  'shear': 6.169339968747569,\n",
       "  'perspective': 0.0009437480785146242,\n",
       "  'flipud': 0.6818202991034834,\n",
       "  'fliplr': 0.359507900573786,\n",
       "  'bgr': 0.43703195379934145,\n",
       "  'mosaic': 0.6976311959272649,\n",
       "  'mixup': 0.06022547162926983,\n",
       "  'copy_paste': 0.6667667154456677,\n",
       "  'data': '/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification',\n",
       "  'epochs': 10,\n",
       "  'imgsz': 640,\n",
       "  'project': '/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2',\n",
       "  'plots': True,\n",
       "  'save_json': True,\n",
       "  'verbose': True},\n",
       " 'time_since_restore': 81.27842378616333,\n",
       " 'iterations_since_restore': 12,\n",
       " 'experiment_tag': '0_bgr=0.4370,box=0.0946,cls=1.2053,copy_paste=0.6668,degrees=0.8455,fliplr=0.3595,flipud=0.6818,hsv_h=0.0774,hsv_s=0.4105,hsv_v=0.5116,lr0=0.0781,lrf=0.1271,mixup=0.0602,momentum=0.8432,mosaic=0.6976,perspective=0.0009,scale=0.5509,shear=6.1693,translate=0.5559,warmup_epochs=4.7233,warmup_momentum=0.4958,weight_decay=0.0001'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results._results[0].metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr0': 0.07805511233688268,\n",
       " 'lrf': 0.1270916816102439,\n",
       " 'momentum': 0.843169988104459,\n",
       " 'weight_decay': 0.0001433532874090464,\n",
       " 'warmup_epochs': 4.7233445852479194,\n",
       " 'warmup_momentum': 0.49575590566256805,\n",
       " 'box': 0.09463914919829426,\n",
       " 'cls': 1.2053113259975823,\n",
       " 'hsv_h': 0.07742336894342167,\n",
       " 'hsv_s': 0.4105352989948937,\n",
       " 'hsv_v': 0.5115905539817837,\n",
       " 'degrees': 0.8455410196359814,\n",
       " 'translate': 0.5558719473682894,\n",
       " 'scale': 0.5508861504501793,\n",
       " 'shear': 6.169339968747569,\n",
       " 'perspective': 0.0009437480785146242,\n",
       " 'flipud': 0.6818202991034834,\n",
       " 'fliplr': 0.359507900573786,\n",
       " 'bgr': 0.43703195379934145,\n",
       " 'mosaic': 0.6976311959272649,\n",
       " 'mixup': 0.06022547162926983,\n",
       " 'copy_paste': 0.6667667154456677,\n",
       " 'data': '/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification',\n",
       " 'epochs': 10,\n",
       " 'imgsz': 640,\n",
       " 'project': '/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx2',\n",
       " 'plots': True,\n",
       " 'save_json': True,\n",
       " 'verbose': True}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results._results[0].config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification/test/angular_leaf_spot/angular_leaf_spot_val.0.jpg: 640x640 angular_leaf_spot 0.41, healthy 0.35, bean_rust 0.24, 52.5ms\n",
      "Speed: 22.5ms preprocess, 52.5ms inference, 0.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "{0: 'angular_leaf_spot', 1: 'bean_rust', 2: 'healthy'}\n",
      "ultralytics.engine.results.Probs object with attributes:\n",
      "\n",
      "data: tensor([0.4053, 0.2444, 0.3503])\n",
      "orig_shape: None\n",
      "shape: torch.Size([3])\n",
      "top1: 0\n",
      "top1conf: tensor(0.4053)\n",
      "top5: [0, 2, 1]\n",
      "top5conf: tensor([0.4053, 0.3503, 0.2444])\n",
      "angular_leaf_spot\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model_path = \"/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/yjx3/yolov8-image-classification/weights/best.pt\"\n",
    "\n",
    "model = YOLO(model=model_path)\n",
    "results = model.predict(source=\"/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification/test/angular_leaf_spot/angular_leaf_spot_val.0.jpg\")\n",
    "for r in results:\n",
    "    print(r.names)\n",
    "    print(r.probs)\n",
    "    print(r.names[r.probs.top1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.91  Python-3.9.18 torch-2.4.1 CPU (Apple M3 Pro)\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification/train... found 33 images in 3 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification/val... found 33 images in 3 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification/test... found 33 images in 3 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification/val... 33 images, 0 corrupt: 100%|| 33/33 [00:00<?, ?it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|| 3/3 [00:03<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.576          1\n",
      "Speed: 0.0ms preprocess, 86.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/classify/val8\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results2 = model.val(\n",
    "    save_dir=\"/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification\",\n",
    "    data=\"/Users/treasures_y/Documents/code/HG/AutoML/python/automl/tests/datasets/image-classification\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
      "\n",
      "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x14b9e41c0>\n",
      "curves: []\n",
      "curves_results: []\n",
      "fitness: 0.7878787815570831\n",
      "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
      "results_dict: {'metrics/accuracy_top1': 0.5757575631141663, 'metrics/accuracy_top5': 1.0, 'fitness': 0.7878787815570831}\n",
      "save_dir: PosixPath('runs/classify/val8')\n",
      "speed: {'preprocess': 0.003056092695756392, 'inference': 86.12918131279224, 'loss': 0.0001806201356830019, 'postprocess': 0.00020229455196496212}\n",
      "task: 'classify'\n",
      "top1: 0.5757575631141663\n",
      "top5: 1.0\n",
      "0.5757575631141663\n"
     ]
    }
   ],
   "source": [
    "print(results2)\n",
    "print(results2.top1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "asyncio.get_event_loop().run_in_executor\n",
    "asyncio.cre"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
